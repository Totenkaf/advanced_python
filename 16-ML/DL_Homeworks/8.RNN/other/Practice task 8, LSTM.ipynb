{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Семинар 9: \"LSTM\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ФИО:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import optim\n",
    "import torch\n",
    "from torch import nn\n",
    "import pandas\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from torch.autograd import Variable\n",
    "%matplotlib inline"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Этот семинар посвящен реализации RNN в pyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите свою реализацию LSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn-images-1.medium.com/max/1600/1*hl9UVtgIcQkDIGD8VFykdw.png\" width=\"640\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gate_size = 4 * self.hidden_size\n",
    "        \n",
    "        self.W_i = nn.Parameter(torch.Tensor(input_size, self.gate_size).zero_())\n",
    "        self.W_h = nn.Parameter(torch.Tensor(hidden_size, self.gate_size).zero_())\n",
    "        self.b = nn.Parameter(torch.Tensor(self.gate_size).zero_())\n",
    "        \n",
    "        \n",
    "    def forward(self, inputs, hidden):\n",
    "        \"\"\"\n",
    "        inputs: (seq_len, batch_size, input_size)\n",
    "        hidden: (batch_size, hidden_size) x 2. (no layers)\n",
    "        \"\"\"\n",
    "        \n",
    "        h, c = hidden\n",
    "        bs = h.size(0)\n",
    "        \n",
    "        seq_length = inputs.size(0)\n",
    "        out = Variable(torch.Tensor(seq_length, bs, self.hidden_size))\n",
    "        \n",
    "        for i, inp in enumerate(inputs):\n",
    "            S = (torch.matmul(inp, self.W_i) + torch.matmul(h, self.W_h) + self.b)\n",
    "            #print('shape:', S.shape)\n",
    "            S = S.view(bs, 4, self.hidden_size)\n",
    "            \n",
    "            i_1 = torch.sigmoid(S[:,0,:])\n",
    "            f_1 = torch.sigmoid(S[:,1,:])\n",
    "            g_1 = torch.tanh(S[:,2,:])\n",
    "            o_1 = torch.sigmoid(S[:,3,:])\n",
    "            \n",
    "            c = f_1 * c + i_1 * g_1\n",
    "            h = o_1 * torch.tanh(c)\n",
    "            out[i] = h\n",
    "        \n",
    "        return out, (h, c)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Задание 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используя свою реализацию LSTM и torch.nn.LSTM (torch.nn.GRU) решить задачу предсказания временного ряда.\n",
    "Попробуйте разные длины входной и выходной последовательности.\n",
    "С помощью обученной сети получить из train-части временного ряда test-часть."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные о количестве пассажиров\n",
    "https://datamarket.com/data/set/22u3/international-airline-passengers-monthly-totals-in-thousands-jan-49-dec-60#!ds=22u3&display=line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "scrolled": true
   },
   "source": [
    "%matplotlib inline\n",
    "dataset = pandas.read_csv('international-airline-passengers.csv', usecols=[1], delimiter=\";\", engine='python', skipfooter=3)\n",
    "plt.plot(dataset)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "source": [
    "# подготовливаем данные\n",
    "\n",
    "dataset = dataset.values\n",
    "dataset = dataset.astype('float32')\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "source": [
    "# разбиваем данные на train / test\n",
    "train_size = int(len(dataset) * 0.67)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "print(len(train), len(test))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "source": [
    "def create_dataset(dataset, look_back=1, look_forward=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1-look_forward):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back : (i + look_back + look_forward), 0])\n",
    "\n",
    "    return np.array(dataX), np.array(dataY)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "source": [
    "look_back = 30 # 5\n",
    "look_forward=1"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "source": [
    "trainX, trainY = create_dataset(train, look_back, look_forward)\n",
    "testX, testY = create_dataset(test, look_back, look_forward)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "source": [
    "plt.plot(range(0, len(trainY)), trainY)\n",
    "plt.plot(range(len(trainY), len(trainY) + len(testY)), testY)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "source": [
    "trainX.shape, testX.shape, trainY.shape, testY.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "source": [
    "train_dataset = TensorDataset(torch.from_numpy(trainX), torch.from_numpy(trainY))\n",
    "test_dataset = TensorDataset(torch.from_numpy(testX), torch.from_numpy(testY))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "source": [
    "def MAPE(y_pred, y_true):\n",
    "    loss = (y_pred - y_true).abs() / (y_true.abs() + 1e-8)\n",
    "    return loss.mean() #loss.mean(axis=0)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "source": [
    "class LSTM_seq(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim) :\n",
    "        super().__init__()\n",
    "        self.lstm = LSTM(input_dim, hidden_dim)\n",
    "        self.linear1 = nn.Linear(hidden_dim, 100)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(100, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        hidden = (torch.randn(batch_size, hidden_size),\n",
    "                    torch.randn(batch_size, hidden_size))\n",
    "        #hidden = (torch.zeros_like(hidden[0]), torch.zeros_like(hidden[1]))\n",
    "        #out, hidden = network(X, hidden)\n",
    "        out, (h_t, c_t) = self.lstm(x, hidden)\n",
    "        x = self.linear1(h_t)\n",
    "        x = self.relu1(x)\n",
    "        x = self.linear2(h_t)\n",
    "        return x"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "source": [
    "def train(network, epochs, learning_rate, train_loader, test_loader=None):\n",
    "    loss = MAPE\n",
    "    optimizer = torch.optim.Adam(network.parameters(), lr=learning_rate)\n",
    "    train_loss_epochs = []\n",
    "    test_loss_epochs = []\n",
    "    \n",
    "    try:\n",
    "        for epoch in range(epochs):\n",
    "            losses = []\n",
    "            for X, y in train_loader:\n",
    "                network.zero_grad()\n",
    "                \n",
    "                X = X.T\n",
    "                X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "                prediction = network(X)\n",
    "                loss_batch = loss(prediction, y)\n",
    "                losses.append(loss_batch.item())\n",
    "                loss_batch.backward()\n",
    "                optimizer.step()\n",
    "           \n",
    "            train_loss_epochs.append(np.mean(losses))\n",
    "            \n",
    "            if test_loader is not None:\n",
    "                losses = []\n",
    "                with torch.no_grad():\n",
    "                    for X, y in test_loader:\n",
    "\n",
    "                        X = X.T\n",
    "                        X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "                        prediction = network(X)\n",
    "                        loss_batch = loss(prediction, y)\n",
    "                        losses.append(loss_batch.item())\n",
    "\n",
    "                    test_loss_epochs.append(np.mean(losses))\n",
    "            \n",
    "                #clear_output(True)\n",
    "                if epoch % 10 == 0:\n",
    "                    print('\\rEpoch {0}... (Train/Test) MAPE: {1:.3f}/{2:.3f}'.format(\n",
    "                                epoch, train_loss_epochs[-1], test_loss_epochs[-1]))\n",
    "            else:\n",
    "                if epoch % 10 == 0:\n",
    "                    print('\\rEpoch {0}... (Train) MAPE: {1:.3f}'.format(\n",
    "                                epoch, train_loss_epochs[-1]))\n",
    "        \n",
    "        if len(train_loss_epochs) > 0:        \n",
    "            print('Total loss:', train_loss_epochs[-1])\n",
    "#             plt.figure(figsize=(12, 5))\n",
    "#             plt.subplot(1, 2, 1)\n",
    "#             plt.plot(train_loss_epochs, label='Train')\n",
    "#             plt.plot(test_loss_epochs, label='Test')\n",
    "#             plt.xlabel('Epochs', fontsize=16)\n",
    "#             plt.ylabel('Loss', fontsize=16)\n",
    "#             plt.legend(loc=0, fontsize=16)\n",
    "#             plt.grid()\n",
    "#             plt.subplot(1, 2, 2)\n",
    "#             plt.plot(train_accuracy_epochs, label='Train accuracy')\n",
    "#             plt.plot(test_accuracy_epochs, label='Test accuracy')\n",
    "#             plt.xlabel('Epochs', fontsize=16)\n",
    "#             plt.ylabel('Loss', fontsize=16)\n",
    "#             plt.legend(loc=0, fontsize=16)\n",
    "#             plt.grid()\n",
    "#             plt.show()\n",
    "    except KeyboardInterrupt:\n",
    "        pass"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "source": [
    "input_size = 1\n",
    "batch_size = 1\n",
    "hidden_size = 100\n",
    "epochs = 50\n",
    "lr = 0.01"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "source": [
    "train_dataloader =  DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_dataloader =  DataLoader(test_dataset, batch_size=batch_size)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "scrolled": true
   },
   "source": [
    "network = LSTM_seq(input_size, hidden_size) # \n",
    "train(network, epochs, lr, train_dataloader) # test_dataloader"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Предсказание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "source": [
    "train_values = []\n",
    "test_values = []\n",
    "target_values = []\n",
    "\n",
    "for _, y in train_dataloader:\n",
    "    train_values += y.flatten().tolist()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X, y in test_dataloader:\n",
    "        X = X.T\n",
    "        X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "        test_values += network(X).flatten().tolist()\n",
    "        target_values += y.flatten().tolist()\n",
    "        \n",
    "\n",
    "train_values = scaler.inverse_transform( np.array(train_values).reshape(-1, 1) )\n",
    "test_values = scaler.inverse_transform( np.array(test_values).reshape(-1, 1) )\n",
    "target_values = scaler.inverse_transform( np.array(target_values).reshape(-1, 1) )\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "plt.plot(range(len(train_values)), train_values)\n",
    "plt.plot(range(len(train_values), len(train_values) + len(test_values)), test_values)\n",
    "plt.plot(range(len(train_values), len(train_values) + len(target_values)), target_values)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3 \n",
    "\n",
    "Поучаствуйте в соревновании https://www.kaggle.com/t/374fc477c4744b009a837153ce135cfb \n",
    "\n",
    "Для зачета задания нужно получить значение MAPE меньше 0.2\n",
    "\n",
    "До 1 мая 2021 можно получить 3,2,1 дополнительных балла за 1, 2 и 3 место соответственно.\n",
    "\n",
    "\n",
    "Опиционально: сравните классические подходы (ARIMA, gradient boosting trees и RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "source": [
    "dataset = pandas.read_csv('train.csv')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "source": [
    "plt.figure(figsize=(20, 7))\n",
    "plt.plot(range(len(dataset['hits'])), dataset['hits'])\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "source": [
    "dataset = dataset['hits'].values.reshape(-1, 1) \n",
    "dataset = dataset.astype('float32')\n",
    "scaler = MinMaxScaler(feature_range=(0, 1)) # TODO: standard / (-1;1)\n",
    "dataset = scaler.fit_transform(dataset)\n",
    "\n",
    "train_size = int(len(dataset) * 0.67)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "\n",
    "print(len(train), len(test))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "source": [
    "look_back = 365 # по какому-то периоду, 30 дней например\n",
    "look_forward=1\n",
    "\n",
    "input_size = 1\n",
    "batch_size = 1\n",
    "hidden_size = 100\n",
    "epochs = 20\n",
    "lr = 0.001"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "source": [
    "trainX, trainY = create_dataset(train, look_back, look_forward)\n",
    "testX, testY = create_dataset(test, look_back, look_forward)\n",
    "\n",
    "trainX = trainX.T.reshape(trainX.shape + (1,))\n",
    "testX = testX.T.reshape(testX.shape + (1,))\n",
    "\n",
    "train_dataset = TensorDataset(torch.from_numpy(trainX), torch.from_numpy(trainY))\n",
    "test_dataset = TensorDataset(torch.from_numpy(testX), torch.from_numpy(testY))\n",
    "\n",
    "train_dataloader =  DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_dataloader =  DataLoader(test_dataset, batch_size=batch_size)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "source": [
    "trainX.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "source": [
    "class LSTM_comp(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim) :\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True) # TODO: еще много параметров\n",
    "        self.linear1 = nn.Linear(hidden_dim, 100) # мб одного слоя достаточно, либо наоборот усложнить\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(100, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out, (h_t, c_t) = self.lstm(x)\n",
    "        x = self.linear1(h_t)\n",
    "        x = self.relu1(x)\n",
    "        x = self.linear2(h_t)\n",
    "        return x"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "source": [
    "def train(network, epochs, learning_rate, train_loader, test_loader=None):\n",
    "    \n",
    "    loss = MAPE\n",
    "    optimizer = torch.optim.Adam(network.parameters(), lr=learning_rate)\n",
    "    train_loss_epochs = []\n",
    "    test_loss_epochs = []\n",
    "    \n",
    "    try:\n",
    "        for epoch in range(epochs):\n",
    "            losses = []\n",
    "            for X, y in train_loader:\n",
    "                network.zero_grad()\n",
    "\n",
    "                prediction = network(X)\n",
    "                loss_batch = loss(prediction, y)\n",
    "                losses.append(loss_batch.item())\n",
    "                loss_batch.backward()\n",
    "                optimizer.step()\n",
    "           \n",
    "            train_loss_epochs.append(np.mean(losses))\n",
    "            \n",
    "            if test_loader is not None:\n",
    "                losses = []\n",
    "                with torch.no_grad():\n",
    "                    for X, y in test_loader:\n",
    "\n",
    "                        prediction = network(X)\n",
    "                        loss_batch = loss(prediction, y)\n",
    "                        losses.append(loss_batch.item())\n",
    "\n",
    "                    test_loss_epochs.append(np.mean(losses))\n",
    "            \n",
    "                if epoch % 10 == 0:\n",
    "                    print('\\rEpoch {0}... (Train/Test) MAPE: {1:.3f}/{2:.3f}'.format(\n",
    "                                epoch, train_loss_epochs[-1], test_loss_epochs[-1]))\n",
    "            else:\n",
    "                if epoch % 10 == 0:\n",
    "                    print('\\rEpoch {0}... (Train) MAPE: {1:.3f}'.format(\n",
    "                                epoch, train_loss_epochs[-1]))\n",
    "        \n",
    "        if len(train_loss_epochs) > 0:    \n",
    "            print('Total loss: {} for {} epochs'.format( train_loss_epochs[-1], epochs) )\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        pass"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "source": [
    "network = LSTM_comp(input_size, hidden_size)\n",
    "# loss mse, metric MAPE? "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "source": [
    "train(network, epochs, lr, train_dataloader, test_dataloader)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "source": [
    "def plot_prediction(train_dataloader, test_dataloader):\n",
    "    train_values = []\n",
    "    test_values = []\n",
    "    target_values = []\n",
    "\n",
    "    for _, y in train_dataloader:\n",
    "        train_values += y.flatten().tolist()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_dataloader:\n",
    "            X = X.T\n",
    "            X = X.reshape(X.shape[0], X.shape[1], 1)\n",
    "            test_values += network(X).flatten().tolist()\n",
    "            target_values += y.flatten().tolist()\n",
    "\n",
    "\n",
    "    train_values = scaler.inverse_transform( np.array(train_values).reshape(-1, 1) )\n",
    "    test_values = scaler.inverse_transform( np.array(test_values).reshape(-1, 1) )\n",
    "    target_values = scaler.inverse_transform( np.array(target_values).reshape(-1, 1) )\n",
    "\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    plt.plot(range(len(train_values)), train_values)\n",
    "    plt.plot(range(len(train_values), len(train_values) + len(test_values)), test_values)\n",
    "    plt.plot(range(len(train_values), len(train_values) + len(target_values)), target_values)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "source": [
    "plot_prediction(train_dataloader, test_dataloader)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
