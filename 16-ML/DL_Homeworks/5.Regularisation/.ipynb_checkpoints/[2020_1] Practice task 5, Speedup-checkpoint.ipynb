{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bn27NI7zaf9Z"
   },
   "source": [
    "## Семинар 5: \"Улучшение сходимости нейросетей\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kY9vse7waf9b"
   },
   "source": [
    "ФИО: Усцов Артем Алексеевич"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 1357,
     "status": "ok",
     "timestamp": 1602204244049,
     "user": {
      "displayName": "Данила Байгушев",
      "photoUrl": "",
      "userId": "06862651594233453127"
     },
     "user_tz": -180
    },
    "id": "JdEAkdunaf9d"
   },
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "%matplotlib inline"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iIgr4r2Haf9l"
   },
   "source": [
    "На этом семинаре мы попробуем улучшить результаты, полученные на предыдущем занятии\n",
    "Для этого нам понадобятся следующие вещи:\n",
    "* Dropout\n",
    "* Batch Normalization\n",
    "* Инициализация весов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CZHtxmbUaf9m"
   },
   "source": [
    "### Часть 1: Инициализация весов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W8dhNr-faf9n"
   },
   "source": [
    "На лекции доказывалось, что при инициализации He и Glorot дисперсия активаций градиентов в каждом слое будут примерно равны. Давайте проверим это. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 638,
     "status": "ok",
     "timestamp": 1602204245453,
     "user": {
      "displayName": "Данила Байгушев",
      "photoUrl": "",
      "userId": "06862651594233453127"
     },
     "user_tz": -180
    },
    "id": "216zZRJAaf9o"
   },
   "source": [
    "# Dataloader\n",
    "to_numpy = lambda x: x.numpy()\n",
    "transform = transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                    ])\n",
    "train_dataset = MNIST('.', train=True, download=True, transform=transform)\n",
    "test_dataset = MNIST('.', train=False, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 1044,
     "status": "ok",
     "timestamp": 1602204248730,
     "user": {
      "displayName": "Данила Байгушев",
      "photoUrl": "",
      "userId": "06862651594233453127"
     },
     "user_tz": -180
    },
    "id": "EqpqV_pVaf9t"
   },
   "source": [
    "images_train, labels_train = next(iter(train_loader))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 8672,
     "status": "ok",
     "timestamp": 1602204258260,
     "user": {
      "displayName": "Данила Байгушев",
      "photoUrl": "",
      "userId": "06862651594233453127"
     },
     "user_tz": -180
    },
    "id": "agAN6Tyfaf9x"
   },
   "source": [
    "## Usage example:\n",
    "for X, y in train_loader:\n",
    "    X = X.view(X.size(0), -1)\n",
    "    X = X.numpy() ### Converts torch.Tensor to numpy array\n",
    "    y = y.numpy()\n",
    "    pass"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "executionInfo": {
     "elapsed": 8767,
     "status": "ok",
     "timestamp": 1602204259023,
     "user": {
      "displayName": "Данила Байгушев",
      "photoUrl": "",
      "userId": "06862651594233453127"
     },
     "user_tz": -180
    },
    "id": "71k9eU4Caf91",
    "outputId": "d056f30d-d7cf-4128-8736-5a83d5511445"
   },
   "source": [
    "plt.figure(figsize=(6, 7))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.imshow(X[i].reshape(28, 28), cmap=plt.cm.Greys_r)\n",
    "    plt.title(y[i])\n",
    "    plt.axis('off')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CjxGvxs8af98"
   },
   "source": [
    "<i> 1.1 </i> Инициализируйте полносвязную сеть нормальным шумом N(0, 0.1) с архитектурой 784 -> 500 x (10 раз) -> 10. В качестве активации возьмите tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 6511,
     "status": "ok",
     "timestamp": 1602204259025,
     "user": {
      "displayName": "Данила Байгушев",
      "photoUrl": "",
      "userId": "06862651594233453127"
     },
     "user_tz": -180
    },
    "id": "DgCP_qclaf99"
   },
   "source": [
    "def init_layer(layer, mean=0, std=1):\n",
    "    # Тут надо быть аккуратным — можно случайно создать копию и менять значения у копии\n",
    "    weight = layer.state_dict()['weight']\n",
    "    bias = layer.state_dict()['bias']\n",
    "    bias.zero_()\n",
    "    #1 - веса сети\n",
    "    #2 - нули ...\n",
    "    #bias = torch.zeros_like(bias)\n",
    "    weight.normal_(mean=0, std=std)\n",
    "\n",
    "def forward_hook(self, input_, output):\n",
    "    std = input_[0].std().item()\n",
    "    print('forward', std)\n",
    "\n",
    "def backward_hook(self, grad_input, grad_output):\n",
    "    std = grad_input[0].std().item()\n",
    "    print('backward', std)\n",
    "\n",
    "    \n",
    "# пример:\n",
    "layer = nn.Linear(28*28, 10)\n",
    "layer.register_forward_hook(forward_hook)\n",
    "layer.register_backward_hook(backward_hook)\n",
    "init_layer(layer, 0.0, 0.1) # сюда надо подставить другие параметры"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 5647,
     "status": "ok",
     "timestamp": 1602204259027,
     "user": {
      "displayName": "Данила Байгушев",
      "photoUrl": "",
      "userId": "06862651594233453127"
     },
     "user_tz": -180
    },
    "id": "roslMRZRaf-C",
    "outputId": "868e8bb3-e2bb-4ebc-da96-31021f57beb1"
   },
   "source": [
    "sizes = [28*28, 64, 32] + [16] * 30 + [10]\n",
    "layers = []\n",
    "\n",
    "def normal(size_input, size_output):\n",
    "    return 0.1\n",
    "    #return 1\n",
    "\n",
    "def xavier(size_input, size_output):\n",
    "    d = 2 / (size_input + size_output)\n",
    "    return np.sqrt(d)\n",
    "\n",
    "def good_grad(size_input, size_output):\n",
    "    d = 1 / size_output\n",
    "    return np.sqrt(d)\n",
    "\n",
    "#init_func = normal\n",
    "init_func = xavier\n",
    "#init_func = good_grad\n",
    "\n",
    "for size_input, size_output in zip(sizes, sizes[1:]):\n",
    "    \n",
    "    layer = nn.Linear(size_input, size_output)\n",
    "    layer.register_forward_hook(forward_hook)\n",
    "    layer.register_backward_hook(backward_hook)\n",
    "    init_layer(layer, 0.0, init_func(size_input, size_output)) # сюда надо подставить другие параметры\n",
    "    \n",
    "    layers.append(layer)\n",
    "    #layers.append(nn.Tanh())\n",
    "    #layers.append(nn.Sigmoid())\n",
    "    layers.append(nn.ReLU())\n",
    "    \n",
    "print(len(layers))\n",
    "del layers[-1]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SsjtA7N_af-G"
   },
   "source": [
    "<i>1.2 Пропустите батч изображений через нейронную сеть и вычислите дисперсию активаций. Затем вычислите градиент и получите дисперсию градиентов. Сравните эти значения между собой для разных слоев.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 3872,
     "status": "ok",
     "timestamp": 1602204259406,
     "user": {
      "displayName": "Данила Байгушев",
      "photoUrl": "",
      "userId": "06862651594233453127"
     },
     "user_tz": -180
    },
    "id": "7Ri1Tvuyaf-K",
    "outputId": "e668298a-0f3e-4dbb-bbe5-84ab7346b44d",
    "scrolled": true
   },
   "source": [
    "network = nn.Sequential(*layers)\n",
    "\n",
    "#пример:\n",
    "n_objects = 100\n",
    "X = images_train[:n_objects].view(n_objects, -1).data\n",
    "y = labels_train[:n_objects].data\n",
    "activations = network(X)\n",
    "loss_fn = torch.nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=0.001) \n",
    "loss = loss_fn(activations, y)\n",
    "loss.backward()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aUJG1Dbqaf-R"
   },
   "source": [
    "<i>1.3 Повторите эксперимент для инициализаций He и Xavier (формулы есть в лекции).</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FyD1lPKwaf-T"
   },
   "source": [
    "##### YOUR CODE HERE #####"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7U2YSSw5af-Y"
   },
   "source": [
    "<i> 1.4 Сделайте выводы по первой части </i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NBQ7o-hjaf-a"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4kYx-hwLaf-b"
   },
   "source": [
    "### Часть 2: Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDoy5_yEaf-c"
   },
   "source": [
    "Другим полезным слоем является Dropout. В нем с вероятностью 1-p зануляется выход каждого нейрона. Этот слой уже реализован в pyTorch, поэтому вновь реализовывать его не интересно. Давайте реализуем DropConnect — аналог Dropout. В нем с вероятностью 1-p зануляется каждый вес слоя."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hxi77m72af-d"
   },
   "source": [
    "<i> 2.1 Реализуйте линейный слой с DropConnect </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 903,
     "status": "ok",
     "timestamp": 1602204261440,
     "user": {
      "displayName": "Данила Байгушев",
      "photoUrl": "",
      "userId": "06862651594233453127"
     },
     "user_tz": -180
    },
    "id": "Ee2ljeNCaf-f"
   },
   "source": [
    "# полезная функция: .bernoulli_(p)\n",
    "# не забывайте делать requires_grad=False у маски\n",
    "# помните, что в вычислениях должны участвовать Variable, а не тензоры\n",
    "\n",
    "class DropConnect(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, p=0.5):\n",
    "        super(DropConnect, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        self.p = p\n",
    "\n",
    "    def forward(self, x):    \n",
    "        mask = torch.zeros_like(self.linear.weight) + self.p\n",
    "        if self.training:          \n",
    "            mask.bernoulli_()\n",
    "\n",
    "        mask = mask.data\n",
    "        output = F.linear(x, self.linear.weight * mask, self.linear.bias)\n",
    "        return output"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CCv4jdyoaf-k"
   },
   "source": [
    "<i> \n",
    "2.2 Сравните графики обучения нейроных сетей:\n",
    "1. Свертки из TestNetwork -> 128 -> 128 -> 10 с ReLU и Dropout между всеми слоями \n",
    "2. Свертки из TestNetwork -> 128 -> 128 -> 10 с ReLU DropConnect вместо всех линейных слоев\n",
    "</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 1160,
     "status": "ok",
     "timestamp": 1602204263658,
     "user": {
      "displayName": "Данила Байгушев",
      "photoUrl": "",
      "userId": "06862651594233453127"
     },
     "user_tz": -180
    },
    "id": "uC3EYVlraf-m"
   },
   "source": [
    "class TestNetwork(nn.Module):\n",
    "    def __init__(self, final_part):\n",
    "        super().__init__()    \n",
    "        \n",
    "        channels = 1\n",
    "        \n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(channels, 2, 3, padding=1),    \n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(2, 4, 3, padding=1),            \n",
    "            nn.MaxPool2d(2),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "        #input_size = 7 * 7 * 4 = 196\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.final_part = final_part\n",
    "        \n",
    "        self.log_softmax = nn.LogSoftmax(1)        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.final_part(x)\n",
    "        return self.log_softmax(x)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 787,
     "status": "ok",
     "timestamp": 1602205245257,
     "user": {
      "displayName": "Данила Байгушев",
      "photoUrl": "",
      "userId": "06862651594233453127"
     },
     "user_tz": -180
    },
    "id": "5Euv1Alyaf-5"
   },
   "source": [
    "sizes = [196, 256, 128, 10]\n",
    "layers = []\n",
    "for size_input, size_output in zip(sizes, sizes[1:]):\n",
    "    layer = nn.Linear(size_input, size_output)\n",
    "    layer = DropConnect(size_input, size_output, 0.9)\n",
    "    \n",
    "    layers.append(layer)\n",
    "    #layers.append(nn.Dropout(0.3))\n",
    "    layers.append(nn.ReLU())\n",
    "\n",
    "del layers[-1]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "executionInfo": {
     "elapsed": 116811,
     "status": "ok",
     "timestamp": 1602204419849,
     "user": {
      "displayName": "Данила Байгушев",
      "photoUrl": "",
      "userId": "06862651594233453127"
     },
     "user_tz": -180
    },
    "id": "QRoKM7rtbGXr",
    "outputId": "5249c849-429c-4c8b-b32a-ef7680da6d4d"
   },
   "source": [
    "%%time\n",
    "\n",
    "#blank\n",
    "from train_utils import train\n",
    "\n",
    "network = TestNetwork(nn.Sequential(*layers))\n",
    "\n",
    "train(network, train_loader, test_loader, 10, 0.001, device='cuda')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "executionInfo": {
     "elapsed": 112696,
     "status": "ok",
     "timestamp": 1602204552249,
     "user": {
      "displayName": "Данила Байгушев",
      "photoUrl": "",
      "userId": "06862651594233453127"
     },
     "user_tz": -180
    },
    "id": "yTnTgiInaf--",
    "outputId": "73a19917-8e54-474b-a151-1c0426b39a9b",
    "scrolled": true
   },
   "source": [
    "%%time\n",
    "\n",
    "#dropout\n",
    "from train_utils import train\n",
    "\n",
    "network = TestNetwork(nn.Sequential(*layers))\n",
    "\n",
    "train(network, train_loader, test_loader, 10, 0.001, device='cuda')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 393
    },
    "executionInfo": {
     "elapsed": 116065,
     "status": "ok",
     "timestamp": 1602205363911,
     "user": {
      "displayName": "Данила Байгушев",
      "photoUrl": "",
      "userId": "06862651594233453127"
     },
     "user_tz": -180
    },
    "id": "ZXDSZ5xNbQFw",
    "outputId": "cb82cb87-5bac-45a0-84b9-92e0a65ec917"
   },
   "source": [
    "%%time\n",
    "\n",
    "#dropconnect\n",
    "from train_utils import train\n",
    "\n",
    "network = TestNetwork(nn.Sequential(*layers))\n",
    "\n",
    "train(network, train_loader, test_loader, 10, 0.001, device='cuda')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pooEVZFbaf_L"
   },
   "source": [
    "В test-time стохастичность Dropout убирают и заменяют все веса на их ожидаемое значение: $\\mathbb{E}w = pw + (1-p)0 = pw$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yfBC8qS4af_K"
   },
   "source": [
    "<i> 2.3 Сделайте выводы по третьей части. </i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "if-VP-I4af_M"
   },
   "source": [
    "### Часть 3: Batch Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vba0rSy-af_N"
   },
   "source": [
    "Наконец, давайте рассмотрим Batch Normalization. Этот слой вычитает среднее и делит на стандартное отклонение. Среднее и дисперсия вычисляются по батчу независимо для каждого нейрона. У этого слоя есть две важные проблемы: его нельзя использовать при обучении с размером батча 1 и он делает элементы батча зависимыми. Давайте реализуем аналог батч нормализации: <a href=https://arxiv.org/pdf/1607.06450.pdf>Layer normalization</a>. В layer normalization среднее и дисперсия вычисляются по активациям нейронов, независимо для каждого объекта."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqUTAtjIaf_O"
   },
   "source": [
    "<i> 3.1 Реализуйте Layer Normalization </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e2H4VX4_af_O"
   },
   "source": [
    "# полезные функции: .std(dim), .mean(dim)\n",
    "\n",
    "class LayerNormalization(nn.Module):\n",
    "    def forward(self, x):\n",
    "        output = ##### YOUR CODE HERE #####\n",
    "        return output"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g2sTZ7h5af_T"
   },
   "source": [
    "<i> \n",
    "3.2 Сравните графики обучения нейроных сетей:\n",
    "1. Свертки из TestNetwork -> 128 -> 128 -> 10 с ReLU и Batch normalization между всеми слоями \n",
    "2. Свертки из TestNetwork -> 128 -> 128 -> 10 с ReLU и Layer normalization между всеми слоями \n",
    "</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q1PPqKRZaf_U"
   },
   "source": [
    "##### YOUR CODE HERE #####"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CudyBOIgaf_X"
   },
   "source": [
    "<i> 3.3 Сделайте выводы по третьей части </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "[2020] Practice task 5, Speedup.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
