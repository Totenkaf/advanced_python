{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "colab": {
   "name": "GAN.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "id": "hMKltmGGOMpl"
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from torch.autograd import Variable"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "No-UYAaSOMpn"
   },
   "source": [
    "### Creating config object (argparse workaround)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "id": "BeCsViCWOMpo"
   },
   "source": [
    "class Config:\n",
    "    pass\n",
    "\n",
    "config = Config()\n",
    "config.mnist_path = None\n",
    "config.batch_size = 16\n",
    "config.num_workers = 3\n",
    "config.num_epochs = 10\n",
    "config.noise_size = 50\n",
    "config.print_freq = 100\n"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sYo4yQunOMpp"
   },
   "source": [
    "### Create dataloder"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FJsJcNevOMpp"
   },
   "source": [
    "train = torchvision.datasets.FashionMNIST(\"fashion_mnist\", train=True, transform=torchvision.transforms.ToTensor(), download=True)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SaOJ4M1ROMpq"
   },
   "source": [
    "dataloader = DataLoader(train, batch_size=16, shuffle=True)"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YndoFdV2OMpq",
    "outputId": "825f4f98-3ae3-458c-ae1f-cd87501cba5d"
   },
   "source": [
    "len(dataloader)"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "id": "tV4idIGzOMpr"
   },
   "source": [
    "for image, cat in dataloader:\n",
    "    break"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-hkIXdLFOMps",
    "outputId": "418f0249-5f27-42d8-eb47-c6ef558ad65d"
   },
   "source": [
    "image.size()"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a564K8omOMpt",
    "outputId": "deb7a911-d229-4e10-c0f7-e46a2918cc28"
   },
   "source": [
    "28*28"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HGNXfyMcOMpv"
   },
   "source": [
    "### Create generator and discriminator"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "id": "FXiVn2orOMpv"
   },
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential( \n",
    "            nn.Linear(config.noise_size, 200),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(200, 28*28),\n",
    "            nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(28*28, 200),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(200, 50),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(50, 1), \n",
    "            nn.Sigmoid())\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ],
   "execution_count": 212,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "id": "PtdZyiHOOMpw"
   },
   "source": [
    "generator = Generator()\n",
    "discriminator = Discriminator()"
   ],
   "execution_count": 213,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7WN-TbkIgGGa"
   },
   "source": [
    ""
   ],
   "execution_count": 213,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NoW5lvW5OMpx"
   },
   "source": [
    "### Create optimizers and loss"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "id": "IcojWX38OMpx"
   },
   "source": [
    "optim_G = optim.Adam(params=generator.parameters(), lr=0.0001)\n",
    "optim_D = optim.Adam(params=discriminator.parameters(), lr=0.0001)\n",
    "\n",
    "criterion = nn.BCELoss()"
   ],
   "execution_count": 214,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IBhz_CLnOMpx"
   },
   "source": [
    "### Create necessary variables"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "id": "uQRhH5PhOMpy"
   },
   "source": [
    "input = Variable(torch.FloatTensor(config.batch_size, 28*28))\n",
    "noise = Variable(torch.FloatTensor(config.batch_size, config.noise_size))\n",
    "fixed_noise = Variable(torch.FloatTensor(config.batch_size, config.noise_size).normal_(0, 1))\n",
    "label = Variable(torch.FloatTensor(config.batch_size, 1))\n",
    "real_label = 1\n",
    "fake_label = 0"
   ],
   "execution_count": 215,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q3EI5Bz2OMpy"
   },
   "source": [
    "### Задание\n",
    "\n",
    "1) Посмотрите на реализацию GAN. Постройте интерполяцию между какими-нибудь двумя сгенерированными картинками.\n",
    "\n",
    "2) Поменяйте ее, чтобы получился LSGAN https://arxiv.org/pdf/1611.04076v2.pdf\n",
    "\n",
    "3) Добавьте к обучению GAN условие на метку, продемонстрируйте условную генерацию. https://arxiv.org/pdf/1411.1784.pdf\n",
    "\n",
    "4) Напишите отчет что попробовали, какие результаты получили, как вам кажется надо обучать GAN, чтобы добиться сходимости?\n",
    "\n",
    "В каждом пункте постройте графики функций потерь."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gAkhmznNOMpz"
   },
   "source": [
    "### GAN"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OwJSkxj5OMpz",
    "outputId": "94ed624b-fb03-4914-f5b7-19137457d2d9"
   },
   "source": [
    "ERRD_x = np.zeros(config.num_epochs)\n",
    "ERRD_z = np.zeros(config.num_epochs)\n",
    "ERRG = np.zeros(config.num_epochs)\n",
    "N = len(dataloader)\n",
    "\n",
    "for epoch in range(config.num_epochs):\n",
    "    for iteration, (images, cat) in enumerate(dataloader):\n",
    "        ####### \n",
    "        # Discriminator stage: maximize log(D(x)) + log(1 - D(G(z))) \n",
    "        #######\n",
    "        discriminator.zero_grad()\n",
    "        \n",
    "        # real\n",
    "        label.data.fill_(real_label)\n",
    "        input_data = images.view(images.shape[0], -1)\n",
    "        output = discriminator(input_data)\n",
    "        errD_x = criterion(output, label)\n",
    "        ERRD_x[epoch] += errD_x.item()\n",
    "        errD_x.backward()\n",
    "        \n",
    "        # fake \n",
    "        noise.data.normal_(0, 1)\n",
    "        fake = generator(noise)\n",
    "        label.data.fill_(fake_label)\n",
    "        output = discriminator(fake.detach())\n",
    "        errD_z = criterion(output, label)\n",
    "        ERRD_z[epoch] += errD_z.item()\n",
    "        errD_z.backward()\n",
    "        \n",
    "        optim_D.step()\n",
    "        \n",
    "        ####### \n",
    "        # Generator stage: maximize log(D(G(x))\n",
    "        #######\n",
    "        generator.zero_grad()\n",
    "        label.data.fill_(real_label)\n",
    "        output = discriminator(fake)\n",
    "        errG = criterion(output, label)\n",
    "        ERRG[epoch] += errG.item()\n",
    "        errG.backward()\n",
    "        \n",
    "        optim_G.step()\n",
    "        \n",
    "        if (iteration+1) % config.print_freq == 0:\n",
    "            print('Epoch:{} Iter: {} errD_x: {:.2f} errD_z: {:.2f} errG: {:.2f}'.format(epoch+1,\n",
    "                                                                                            iteration+1, \n",
    "                                                                                            errD_x.item(),\n",
    "                                                                                            errD_z.item(), \n",
    "                                                                                            errG.item()))"
   ],
   "execution_count": 216,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "a-DbmCCcVryi"
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "PyuaYHmeOMp0",
    "outputId": "b269bf56-51ae-49e4-a473-133d2a1e9d15"
   },
   "source": [
    "noise.data.normal_(0, 1)\n",
    "fake = generator(noise)\n",
    "\n",
    "plt.figure(figsize=(6, 7))\n",
    "for i in range(16):\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    plt.imshow(fake[i].detach().numpy().reshape(28, 28), cmap=plt.cm.Greys_r)\n",
    "    plt.axis('off')"
   ],
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "JwyizC4eVtwp",
    "outputId": "272104e6-c164-4986-dd02-2152be5d16e1"
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(14,7))\n",
    "plt.plot(ERRD_x, label='errD_x')\n",
    "plt.plot(ERRD_z, label='errD_z')\n",
    "plt.plot(ERRG, label='errG')"
   ],
   "execution_count": 217,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vM8laCK1b_q_"
   },
   "source": [
    "### Интерполяция"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "UlUOyFLXPu8p",
    "outputId": "76ba6ace-74f1-4f84-ad55-e74b7c0dcbb8"
   },
   "source": [
    "plt.figure(figsize=(6, 7))\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    while True:\n",
    "        noise.data.normal_(0, 1)\n",
    "        noise_v1 = noise.clone()\n",
    "        noise.data.normal_(0, 1)\n",
    "        noise_v2 = noise.clone()\n",
    "        eps = 1e-6\n",
    "        norm = torch.norm( noise_v2 - noise_v1, p=2)\n",
    "        if norm > eps:\n",
    "            break\n",
    "\n",
    "\n",
    "    v0 = noise_v1\n",
    "    r = (noise_v2 - noise_v1) / norm\n",
    "    fakes = []\n",
    "\n",
    "    for t in np.linspace(0, norm, 100):\n",
    "        noise_v = v0 + t * r\n",
    "        fake = generator(noise_v)\n",
    "        fakes.append( fake.detach().numpy().reshape(16, 28, 28) )\n",
    "\n",
    "    result = np.mean(fakes, axis=0)\n",
    "\n",
    "    for i in range(16):\n",
    "\n",
    "        plt.subplot(4, 4, i + 1)\n",
    "        plt.imshow(result[i], cmap=plt.cm.Greys_r)\n",
    "        plt.axis('off')\n"
   ],
   "execution_count": 42,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KNlpZGWzQMhN"
   },
   "source": [
    "Sampling points from segment:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "--SMLy7wP8o1"
   },
   "source": [
    "\n",
    "l^ = a^ + t * r^\n",
    "\n",
    "a^ = p1\n",
    "\n",
    "r^ = (p2 - p1) / || p2 - p1 ||\n",
    "\n",
    "t in [0; ||p2 - p1|| ]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3AviFnnjcyM"
   },
   "source": [
    "### LSGAN"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "id": "o-dV0s-zje6k",
    "outputId": "339edc72-f01c-4f5a-b4b4-3206082365f5"
   },
   "source": [
    "x = torch.cat([x2, x1], dim=1)"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4X2ektnKkWLC"
   },
   "source": [
    "class Config:\n",
    "    pass\n",
    "\n",
    "config = Config()\n",
    "config.mnist_path = None\n",
    "config.batch_size = 16\n",
    "config.num_workers = 3\n",
    "config.num_epochs = 10\n",
    "config.noise_size = 1024\n",
    "config.print_freq = 100"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "9syZ0H77jitN"
   },
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.linear_part = nn.Sequential( \n",
    "            nn.Linear(config.noise_size, 7 * 7 * 128),\n",
    "            nn.BatchNorm1D(7 * 7 * 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        shape_2d = (-1, 7, 7, 128)\n",
    "\n",
    "        self.deconv1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 128, kernel_size=5, stride=2), \n",
    "            nn.BatchNorm2D(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.deconv2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(128, 1, kernel_size=5, stride=2), \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        z = self.linear_part(x)\n",
    "        z = z.view(shape_2d)\n",
    "\n",
    "        z = self.deconv1(z)\n",
    "        z = self.deconv2(z)\n",
    "\n",
    "        return z\n",
    "\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        # 1 28 28\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "\n",
    "            nn.Conv2D(1, 256, kernel_size=5, stride=2), \n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2D(256, 320, kernel_size=5, stride=2),\n",
    "            nn.BatchNorm2D(320),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.linear = nn.Sequential(\n",
    "            nn.Linear(320 * 20 * 20, 1024),\n",
    "            nn.BatchNorm1D(1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Linear(1024, 1), \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        z = self.conv(x)\n",
    "        z = z.view(batch_size, -1)\n",
    "        z = self.linear(z)\n",
    "        return z\n",
    "        "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "G3JScExv-bOu"
   },
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential( \n",
    "            nn.ConvTranspose2d(config.noise_size, 256, kernel_size=2, stride=2, padding=0),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.ConvTranspose2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.ConvTranspose2d(256, 256, kernel_size=6, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.ConvTranspose2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "\n",
    "            nn.ConvTranspose2d(256, 256 // 2, kernel_size=6, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256 // 2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "\n",
    "            nn.ConvTranspose2d(256 // 2, 256 // 4, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256 // 4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.ConvTranspose2d(256 // 4, 1, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = x.view(-1, config.noise_size, 1, 1)\n",
    "        return self.model(z)\n",
    "\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        # 1 28 28\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(1, 64, kernel_size=5, stride=2, padding=2), \n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=5, stride=2, padding=2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=5, stride=2, padding=2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.Conv2d(256, 512, kernel_size=5, stride=2, padding=2),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "\n",
    "        self.linear = nn.Linear(512 * 2 * 2, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        z = self.conv(x)\n",
    "        z = z.view(batch_size, -1)\n",
    "        z = self.linear(z)\n",
    "        return z"
   ],
   "execution_count": 140,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "J4RtqeKOjijp"
   },
   "source": [
    "generator = Generator()\n",
    "discriminator = Discriminator()"
   ],
   "execution_count": 141,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fEeFV4OMjiaf"
   },
   "source": [
    "optim_G = optim.Adam(params=generator.parameters(), lr=0.0001)\n",
    "optim_D = optim.Adam(params=discriminator.parameters(), lr=0.0001)\n",
    "\n",
    "criterion = nn.MSELoss()"
   ],
   "execution_count": 142,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7KuNqsFAjiVA"
   },
   "source": [
    "input = Variable(torch.FloatTensor(config.batch_size, 28*28))\n",
    "noise = Variable(torch.FloatTensor(config.batch_size, config.noise_size))\n",
    "fixed_noise = Variable(torch.FloatTensor(config.batch_size, config.noise_size).normal_(0, 1))\n",
    "label = Variable(torch.FloatTensor(config.batch_size, 1))\n",
    "real_label = 1\n",
    "fake_label = 0"
   ],
   "execution_count": 143,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "CtAliZHcjiME",
    "outputId": "ebbb7f93-c87f-4d60-aedb-17be182f23a3"
   },
   "source": [
    "ERRD_x = np.zeros(config.num_epochs)\n",
    "ERRD_z = np.zeros(config.num_epochs)\n",
    "ERRG = np.zeros(config.num_epochs)\n",
    "N = len(dataloader)\n",
    "\n",
    "for epoch in range(5):\n",
    "    for iteration, (images, cat) in enumerate(dataloader):\n",
    "        ####### \n",
    "        # Discriminator stage: maximize log(D(x)) + log(1 - D(G(z))) \n",
    "        #######\n",
    "        discriminator.zero_grad()\n",
    "        \n",
    "        # real\n",
    "        label.data.fill_(real_label)\n",
    "        input_data = images#.view(images.shape[0], -1)\n",
    "        output = discriminator(input_data)\n",
    "        errD_x = 0.5 * criterion( output, label )\n",
    "\n",
    "        ERRD_x[epoch] += errD_x.item()\n",
    "        errD_x.backward()\n",
    "        \n",
    "        # fake \n",
    "        noise.data.normal_(0, 1)\n",
    "        fake = generator(noise)\n",
    "\n",
    "        label.data.fill_(fake_label)\n",
    "        output = discriminator(fake.detach())\n",
    "        errD_z = 0.5 * torch.square( output - label ).mean()\n",
    "\n",
    "        ERRD_z[epoch] += errD_z.item()\n",
    "        errD_z.backward()\n",
    "        \n",
    "        optim_D.step()\n",
    "        \n",
    "        ####### \n",
    "        # Generator stage: maximize log(D(G(x))\n",
    "        #######\n",
    "        generator.zero_grad()\n",
    "        label.data.fill_(real_label)\n",
    "        output = discriminator(fake)\n",
    "        errG = 0.5 * criterion( output, label )\n",
    "        ERRG[epoch] += errG.item()\n",
    "        errG.backward()\n",
    "        \n",
    "        optim_G.step()\n",
    "        \n",
    "        if (iteration+1) % config.print_freq == 0:\n",
    "            print('Epoch:{} Iter: {} errD_x: {:.2f} errD_z: {:.2f} errG: {:.2f}'.format(epoch+1,\n",
    "                                                                                            iteration+1, \n",
    "                                                                                            errD_x.item(),\n",
    "                                                                                            errD_z.item(), \n",
    "                                                                                            errG.item()))"
   ],
   "execution_count": 145,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5imfGNJkbcwE"
   },
   "source": [
    "1.5 эпохи за 1.5 часа"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "F5tF8wSjjh1b",
    "outputId": "719d1ad0-15a5-4e4d-80c8-c31b4615b02e"
   },
   "source": [
    "noise.data.normal_(0, 1)\n",
    "fake = generator(noise)\n",
    "\n",
    "plt.figure(figsize=(6, 7))\n",
    "for i in range(16):\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    plt.imshow(fake[i].detach().numpy().reshape(28, 28), cmap=plt.cm.Greys_r)\n",
    "    plt.axis('off')"
   ],
   "execution_count": 147,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wKf-cpmRb5uG"
   },
   "source": [
    "import copy\n",
    "generator_t = copy.deepcopy(generator)\n",
    "discriminator_t = copy.deepcopy(discriminator)"
   ],
   "execution_count": 150,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3GS5Izu6rmk"
   },
   "source": [
    "### Условная генерация"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "E-LOLfUlQjcx"
   },
   "source": [
    "class Config:\n",
    "    pass\n",
    "\n",
    "config = Config()\n",
    "config.mnist_path = None\n",
    "config.batch_size = 16\n",
    "config.num_workers = 3\n",
    "config.num_epochs = 10\n",
    "config.noise_size = 1024\n",
    "config.print_freq = 100\n",
    "config.emb_size = 256\n",
    "config.num_classes = 10"
   ],
   "execution_count": 163,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ejUkl4fe6q7L"
   },
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Linear(config.num_classes, config.emb_size)\n",
    "\n",
    "        self.model = nn.Sequential( \n",
    "            nn.Linear(config.noise_size + config.emb_size, 200),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(200, 28*28),\n",
    "            nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        \n",
    "        emb = self.embedding(y)\n",
    "        z = torch.cat([x, emb], 1)\n",
    "        return self.model(z)\n",
    "\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Linear(config.num_classes, config.emb_size)\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(28*28 + config.emb_size, 200),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(200, 50),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(50, 1), \n",
    "            nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "\n",
    "        emb = self.embedding(y)\n",
    "        im = torch.cat([x, emb], 1)\n",
    "\n",
    "        return self.model(im)"
   ],
   "execution_count": 185,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "e1372UIHP6D8"
   },
   "source": [
    "generator = Generator()\n",
    "discriminator = Discriminator()"
   ],
   "execution_count": 186,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mnl11eYgP-qn"
   },
   "source": [
    "optim_G = optim.Adam(params=generator.parameters(), lr=0.0001)\n",
    "optim_D = optim.Adam(params=discriminator.parameters(), lr=0.0001)\n",
    "\n",
    "criterion = nn.BCELoss()"
   ],
   "execution_count": 187,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mKHw5SssQA0J"
   },
   "source": [
    "input = Variable(torch.FloatTensor(config.batch_size, 28*28))\n",
    "noise = Variable(torch.FloatTensor(config.batch_size, config.noise_size))\n",
    "fixed_noise = Variable(torch.FloatTensor(config.batch_size, config.noise_size).normal_(0, 1))\n",
    "label = Variable(torch.FloatTensor(config.batch_size, 1))\n",
    "real_label = 1\n",
    "fake_label = 0"
   ],
   "execution_count": 188,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0O50fj8EQO-V",
    "outputId": "6b7f34b7-8405-4e1a-da21-3acb76d78524"
   },
   "source": [
    "ERRD_x = np.zeros(config.num_epochs)\n",
    "ERRD_z = np.zeros(config.num_epochs)\n",
    "ERRG = np.zeros(config.num_epochs)\n",
    "N = len(dataloader)\n",
    "\n",
    "for epoch in range(config.num_epochs):\n",
    "    for iteration, (images, cat) in enumerate(dataloader):\n",
    "        ####### \n",
    "        # Discriminator stage: maximize log(D(x)) + log(1 - D(G(z))) \n",
    "        #######\n",
    "        discriminator.zero_grad()\n",
    "\n",
    "        one_hot_cat = Variable(torch.zeros(config.batch_size, config.num_classes))\n",
    "        one_hot_cat[:, cat] = 1.0\n",
    "        \n",
    "\n",
    "        #one_hot_cat[cat] = 1\n",
    "\n",
    "        # real\n",
    "        label.data.fill_(real_label)\n",
    "        input_data = images.view(images.shape[0], -1)\n",
    "        output = discriminator(input_data, one_hot_cat)\n",
    "        errD_x = criterion(output, label)\n",
    "        ERRD_x[epoch] += errD_x.item()\n",
    "        errD_x.backward()\n",
    "        \n",
    "        # fake \n",
    "        noise.data.normal_(0, 1)\n",
    "        fake = generator(noise, one_hot_cat)\n",
    "        label.data.fill_(fake_label)\n",
    "        output = discriminator(fake.detach(), one_hot_cat)\n",
    "        errD_z = criterion(output, label)\n",
    "        ERRD_z[epoch] += errD_z.item()\n",
    "        errD_z.backward()\n",
    "        \n",
    "        optim_D.step()\n",
    "        \n",
    "        ####### \n",
    "        # Generator stage: maximize log(D(G(x))\n",
    "        #######\n",
    "        generator.zero_grad()\n",
    "        label.data.fill_(real_label)\n",
    "        output = discriminator(fake, one_hot_cat)\n",
    "        errG = criterion(output, label)\n",
    "        ERRG[epoch] += errG.item()\n",
    "        errG.backward()\n",
    "        \n",
    "        optim_G.step()\n",
    "        \n",
    "        if (iteration+1) % config.print_freq == 0:\n",
    "            print('Epoch:{} Iter: {} errD_x: {:.2f} errD_z: {:.2f} errG: {:.2f}'.format(epoch+1,\n",
    "                                                                                            iteration+1, \n",
    "                                                                                            errD_x.item(),\n",
    "                                                                                            errD_z.item(), \n",
    "                                                                                            errG.item()))"
   ],
   "execution_count": 190,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qH5VCEDjfkSP",
    "outputId": "6285a62d-1545-40fb-a911-2b2ddeede26e"
   },
   "source": [
    ""
   ],
   "execution_count": 200,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "fBYu2htjQWPf",
    "outputId": "4dc7b588-3e04-4c7e-c377-905ed1e224ff"
   },
   "source": [
    "noise.data.normal_(0, 1)\n",
    "one_hot_cat = torch.zeros(config.batch_size, config.num_classes )\n",
    "one_hot_cat[ torch.randint(0, 9, (config.batch_size,) ) ] = 1.0\n",
    "\n",
    "fake = generator(noise, one_hot_cat)\n",
    "\n",
    "plt.figure(figsize=(6, 7))\n",
    "for i in range(16):\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    plt.imshow(fake[i].detach().numpy().reshape(28, 28), cmap=plt.cm.Greys_r)\n",
    "    plt.axis('off')"
   ],
   "execution_count": 205,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "TMrMAsOvQXg9",
    "outputId": "fe2ed9a0-592c-418a-a12f-a11f90598a0a"
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(14,7))\n",
    "plt.plot(ERRD_x, label='errD_x')\n",
    "plt.plot(ERRD_z, label='errD_z')\n",
    "plt.plot(ERRG, label='errG')"
   ],
   "execution_count": 211,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "m4OKwKMuekPc"
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mUlZpWfqi8jD"
   },
   "source": [
    "GAN, интерполяцию с GAN, LSGAN, условную генерацию. Лучше всего себя показал LSGAN, генерируя правдоподобные изображения одежды. Он же дольше всего обучается. Кажется, что лучше всего обучать LSGAN, имея много GPU + добавить условную генерацию."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3L0D19OVjwNl"
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}
