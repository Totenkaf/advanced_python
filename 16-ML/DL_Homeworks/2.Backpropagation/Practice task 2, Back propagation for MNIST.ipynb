{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Семинар 2 \"Распознавание рукописных цифр\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ФИО: Усцов Артем Алексеевич"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом задании мы используем нейронную сеть из предыдущего семинара для распознавания рукописных цифр. Также мы исследуем как влияет выбор нелинейности и предобработка данных на качество классификации. \n",
    "\n",
    "Чтобы не тратить время на подготовку данных, мы прилагаем готовый код с примером использования для получения обучающей и тестовой выборок. Для запуска скрипта вам понадобится библиотека PyTorch (инструкции по установке можно найти на сайте <a href=\"http://pytorch.org\">pytorch.org</a>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-29T18:21:06.022980Z",
     "start_time": "2022-09-29T18:21:06.016563Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from layers import Linear, Sigmoid, NLLLoss, NeuralNetwork # Results from Seminar 1\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-29T17:16:00.750166Z",
     "start_time": "2022-09-29T17:16:00.648666Z"
    }
   },
   "source": [
    "transform = transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                    ])\n",
    "train_dataset = MNIST('.', train=True, download=True, transform=transform)\n",
    "test_dataset = MNIST('.', train=False, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-29T17:16:10.219892Z",
     "start_time": "2022-09-29T17:16:01.257065Z"
    }
   },
   "source": [
    "## Usage example:\n",
    "for X, y in train_loader:\n",
    "    X = X.view(X.shape[0], -1)\n",
    "    X = X.numpy() ### Converts torch.Tensor to numpy array\n",
    "    y = y.numpy()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-29T17:16:52.066510Z",
     "start_time": "2022-09-29T17:16:52.063867Z"
    }
   },
   "source": [
    "print(f\"{X.shape=}\", f\"{y.shape=}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-29T17:16:11.030161Z",
     "start_time": "2022-09-29T17:16:10.237355Z"
    }
   },
   "source": [
    "plt.figure(figsize=(6, 7))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.imshow(X[i].reshape(28, 28), cmap=plt.cm.Greys_r)\n",
    "    plt.title(y[i])\n",
    "    plt.axis('off')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 1: MNIST\n",
    "Обучите полносвязную нейронную сеть с архитектурой 784-100-100-10 и сигмоидой в качестве нелинейности. Какую точность классификации удалось получить? Нарисуйте график сходимости на обучающей и тестовой выборках. В качестве темпа обучения (learning rate) возьмите 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "NUM_EPOCHS = 20"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-29T17:17:23.944833Z",
     "start_time": "2022-09-29T17:17:23.930790Z"
    }
   },
   "source": [
    "def train(network, train_loader, test_loader, epochs, learning_rate, plot=True, \n",
    "          verbose=True, loss=NLLLoss()):\n",
    "    train_loss_epochs = []\n",
    "    test_loss_epochs = []\n",
    "    train_accuracy_epochs = []\n",
    "    test_accuracy_epochs = []\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        for epoch in tqdm(range(epochs)): # цикл по эпохам\n",
    "            losses = []\n",
    "            accuracies = []\n",
    "            \n",
    "            # обучаемся на каждом объекте из трейн-датасета\n",
    "            for X, y in train_loader:\n",
    "                X = X.view(X.shape[0], -1).numpy()\n",
    "                y = y.numpy()\n",
    "                prediction = network.forward(X)\n",
    "                loss_batch = loss.forward(prediction, y)\n",
    "                losses.append(loss_batch)\n",
    "                dLdx = loss.backward()\n",
    "                network.backward(dLdx)\n",
    "                network.step(learning_rate)\n",
    "                accuracies.append((np.argmax(prediction, axis=1)==y).mean())\n",
    "\n",
    "            train_loss_epochs.append(np.mean(losses))\n",
    "            train_accuracy_epochs.append(np.mean(accuracies))\n",
    "            losses = []\n",
    "            accuracies = []\n",
    "\n",
    "            # обучаемся на каждом объекте из тестового-датасета\n",
    "            for X, y in test_loader:\n",
    "                X = X.view(X.shape[0], -1).numpy()\n",
    "                y = y.numpy()\n",
    "                prediction = network.forward(X)\n",
    "                loss_batch = loss.forward(prediction, y)\n",
    "                losses.append(loss_batch)\n",
    "                accuracies.append((np.argmax(prediction, axis=1)==y).mean())\n",
    "            test_loss_epochs.append(np.mean(losses))\n",
    "            test_accuracy_epochs.append(np.mean(accuracies))\n",
    "\n",
    "            clear_output(wait=True) # для динамического обновления графиков, wait - очищает вывод\n",
    "\n",
    "            if verbose: # детализация выводимой информации\n",
    "                print(\n",
    "                      f'Network: <{type(network).__name__}>\\n'\n",
    "                      f'Loss type: <{type(loss).__name__}>\\n\\n'\n",
    "                      f'Epoch: {epoch+1}/{epochs}\\n'\n",
    "                      f'<Train/Test>\\n'\n",
    "                      f'Loss: {np.round(train_loss_epochs[-1], 3)}/{np.round(test_loss_epochs[-1], 3)} '\n",
    "                      f'| Accuracy: {np.round(train_accuracy_epochs[-1], 3)}/{np.round(test_accuracy_epochs[-1], 3)}'\n",
    "                     )\n",
    "    \n",
    "            if plot:\n",
    "                plt.figure(figsize=(12, 5))\n",
    "                \n",
    "                # Отображение изменения ошибки\n",
    "                plt.subplot(1, 2, 1)\n",
    "                plt.plot(train_loss_epochs, label='Train')\n",
    "                plt.plot(test_loss_epochs, label='Test')\n",
    "                plt.xlabel('Epochs', fontsize=14)\n",
    "                plt.ylabel('Loss', fontsize=14)\n",
    "                plt.legend(fontsize=14)\n",
    "                plt.grid('on')\n",
    "\n",
    "                # Отображение изменения accuracy\n",
    "                plt.subplot(1, 2, 2)\n",
    "                plt.plot(train_accuracy_epochs, label='Train accuracy')\n",
    "                plt.plot(test_accuracy_epochs, label='Test accuracy')\n",
    "                plt.xlabel('Epochs', fontsize=14)\n",
    "                plt.ylabel('Accuracy', fontsize=14)\n",
    "                plt.legend(fontsize=14)\n",
    "                plt.grid('on')\n",
    "                plt.show()\n",
    "    \n",
    "    except KeyboardInterrupt as KI:\n",
    "        print(KI)\n",
    "\n",
    "    return train_loss_epochs, \\\n",
    "           test_loss_epochs, \\\n",
    "           train_accuracy_epochs, \\\n",
    "           test_accuracy_epochs"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-29T17:17:24.984417Z",
     "start_time": "2022-09-29T17:17:24.975963Z"
    }
   },
   "source": [
    "network = NeuralNetwork([\n",
    "    Linear(784, 100), Sigmoid(), # 28 * 28\n",
    "    Linear(100, 100), Sigmoid(),\n",
    "    Linear(100, 10)\n",
    "])\n",
    "loss = NLLLoss()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-29T17:23:44.352134Z",
     "start_time": "2022-09-29T17:17:25.425095Z"
    }
   },
   "source": [
    "tr_s, ts_s, tr_ac_s, ts_ac_s = train(network, train_loader, test_loader, NUM_EPOCHS, 0.01)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 2: Нелинейности"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите нейронную сеть с другими нелинейностями: ReLU и ELU. Сравните скорости сходимости и качество классификации с различными функциями активации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-29T17:23:48.915792Z",
     "start_time": "2022-09-29T17:23:48.911799Z"
    }
   },
   "source": [
    "class ReLU:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, X):\n",
    "        '''\n",
    "        Passes objects through this layer.\n",
    "        X is np.array of size (N, d)\n",
    "        '''\n",
    "        self.X = X\n",
    "        return np.maximum(X, 0)\n",
    "\n",
    "    def backward(self, dLdy):\n",
    "        '''\n",
    "        1. Compute dLdx.\n",
    "        2. Return dLdx\n",
    "        '''\n",
    "        dydX = self.X > 0\n",
    "        return dydX * dLdy\n",
    "\n",
    "    def step(self, learning_rate):\n",
    "        pass"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-29T17:23:49.819014Z",
     "start_time": "2022-09-29T17:23:49.797174Z"
    }
   },
   "source": [
    "class ELU:\n",
    "    '''\n",
    "    ELU(x) = x, x > 0; a*(e^x - 1), x <= 0\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, a=1):\n",
    "        self.a = a\n",
    "\n",
    "    def forward(self, X):\n",
    "        '''\n",
    "        Passes objects through this layer.\n",
    "        X is np.array of size (N, d)\n",
    "        '''\n",
    "        self.X = X\n",
    "        return X * (X > 0) + self.a * (np.exp(X) - 1) * (X <= 0)\n",
    "    \n",
    "    def backward(self, dLdy):\n",
    "        '''\n",
    "        1. Compute dLdx.\n",
    "        2. Return dLdx\n",
    "        '''\n",
    "        X = self.X\n",
    "        dydX = (X > 0) + self.a * np.exp(X) * (X <= 0)\n",
    "        return dLdy*dydX\n",
    "\n",
    "    def step(self, learning_rate):\n",
    "        pass"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель с ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-29T17:31:07.599398Z",
     "start_time": "2022-09-29T17:23:51.118793Z"
    }
   },
   "source": [
    "network = NeuralNetwork([\n",
    "    Linear(784, 100), ReLU(),\n",
    "    Linear(100, 100), ReLU(),\n",
    "    Linear(100, 10)\n",
    "])\n",
    "loss = NLLLoss()\n",
    "tr_r, ts_r, tr_ac_r, ts_ac_r = train(network,train_loader, test_loader, NUM_EPOCHS, 0.01, plot=True, verbose=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-28T19:49:51.406970Z",
     "start_time": "2022-09-28T19:49:51.401083Z"
    }
   },
   "source": [
    "Модель с ELU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-29T17:36:46.514144Z",
     "start_time": "2022-09-29T17:31:07.617257Z"
    }
   },
   "source": [
    "network = NeuralNetwork([Linear(784, 100), ELU(),\n",
    "               Linear(100, 100), ELU(),\n",
    "               Linear(100, 10)])\n",
    "loss = NLLLoss()\n",
    "tr_e, ts_e, tr_ac_e, ts_ac_e = train(network,train_loader, test_loader, NUM_EPOCHS, 0.01, plot=True, verbose=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим динамику ошибки и accuracy на всех активационных функциях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-29T17:36:46.539524Z",
     "start_time": "2022-09-29T17:36:46.534546Z"
    }
   },
   "source": [
    "def compare_activation_func(loss_results: list, acc_results: list, labels: list) -> None:\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title('Loss')\n",
    "    for loss_result, label in zip(loss_results, labels):\n",
    "        plt.plot(loss_result, label=label)\n",
    "\n",
    "    plt.xlabel('Epochs', fontsize=16)\n",
    "    plt.ylabel('Loss', fontsize=16)\n",
    "    plt.legend(loc=0, fontsize=16)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title('Accuracy')\n",
    "    for acc_result, label in zip(acc_results, labels):\n",
    "        plt.plot(acc_result, label=label)\n",
    "\n",
    "    plt.xlabel('Epochs', fontsize=16)\n",
    "    plt.ylabel('Loss', fontsize=16)\n",
    "    plt.legend(loc=0, fontsize=16)\n",
    "    plt.grid()\n",
    "    plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-29T17:36:46.813434Z",
     "start_time": "2022-09-29T17:36:46.558377Z"
    }
   },
   "source": [
    "compare_activation_func(loss_results=[ts_s, ts_r, ts_e], acc_results=[ts_ac_s, ts_ac_r, ts_ac_e],\n",
    "                       labels=[\"Sigmoid\", \"ReLU\", \"ELU\"])"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW1 (1 балл): Реализовать Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-29T17:36:46.836471Z",
     "start_time": "2022-09-29T17:36:46.832728Z"
    }
   },
   "source": [
    "class Tanh:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, X):\n",
    "        '''\n",
    "        Passes objects through this layer.\n",
    "        X is np.array of size (N, d)\n",
    "        '''\n",
    "        self.X = X\n",
    "        return (2. / (1 + np.exp(-2 * X))) - 1.\n",
    "\n",
    "    def backward(self, dLdy):\n",
    "        '''\n",
    "        1. Compute dLdx.\n",
    "        2. Return dLdx\n",
    "        '''\n",
    "        dydX = 4 / ((np.exp(self.X) + np.exp(-self.X)) ** 2)\n",
    "        return dLdy * dydX\n",
    "\n",
    "    def step(self, learning_rate):\n",
    "        pass"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-29T17:42:23.408479Z",
     "start_time": "2022-09-29T17:36:46.852833Z"
    }
   },
   "source": [
    "network = NeuralNetwork([Linear(784, 100), Tanh(),\n",
    "               Linear(100, 100), Tanh(),\n",
    "               Linear(100, 10)])\n",
    "loss = NLLLoss()\n",
    "tr_th, ts_th, tr_ac_th, ts_ac_th = train(network, train_loader, test_loader, NUM_EPOCHS, 0.01, \n",
    "                                         plot=True, verbose=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним все 4-е активационные функции на нашем датасете "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-29T17:42:23.691243Z",
     "start_time": "2022-09-29T17:42:23.434616Z"
    }
   },
   "source": [
    "compare_activation_func(loss_results=[ts_s, ts_r, ts_e, ts_th], \n",
    "                        acc_results=[ts_ac_s, ts_ac_r, ts_ac_e, ts_ac_th],\n",
    "                        labels=[\"Sigmoid\", \"ReLU\", \"ELU\", \"Tanh\"])"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 3: Анализ ошибок\n",
    "На каких объектах сеть ошибается больше всего?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-29T17:45:07.922168Z",
     "start_time": "2022-09-29T17:45:04.591639Z"
    }
   },
   "source": [
    "wrong_X = []\n",
    "correct_y = []\n",
    "predicted_y = []\n",
    "logits = []\n",
    "\n",
    "for X, y in test_loader:\n",
    "    X = X.view(X.shape[0], -1).numpy()\n",
    "    y = y.numpy()\n",
    "    \n",
    "    prediction = network.forward(X)\n",
    "    # Softmax трансформация данных\n",
    "    prediction = np.exp(prediction)\n",
    "    prediction /= prediction.sum(1, keepdims=True)\n",
    "    \n",
    "    for i in range(len(prediction)):\n",
    "        if np.argmax(prediction[i]) != y[i]:\n",
    "            wrong_X.append(X[i])\n",
    "            correct_y.append(y[i])\n",
    "            predicted_y.append(np.argmax(prediction[i]))\n",
    "            logits.append(prediction[i][y[i]])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-29T17:47:02.378576Z",
     "start_time": "2022-09-29T17:47:02.366630Z"
    }
   },
   "source": [
    "wrong_X = np.row_stack(wrong_X)\n",
    "correct_y = np.row_stack(correct_y)[:, 0]\n",
    "predicted_y = np.row_stack(predicted_y)[:, 0]\n",
    "logits = np.row_stack(logits)[:, 0]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-29T17:43:32.365677Z",
     "start_time": "2022-09-29T17:43:31.717191Z"
    }
   },
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "order = np.argsort(logits)\n",
    "for i in range(21):\n",
    "    plt.subplot(3, 7, i+1)\n",
    "    plt.imshow(wrong_X[order[i]].reshape(28, 28), cmap=plt.cm.Greys_r)\n",
    "    plt.title('{}({})'.format(correct_y[order[i]], predicted_y[order[i]]), fontsize=20)\n",
    "    plt.axis('off')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Налицо проблемы с определением 1, 7, 3 и 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 4: Аугментация (HW, 2 балла)\n",
    "* Небольшие вращения (-15, 15)\n",
    "* Случайные сдвиги\n",
    "* Шум\n",
    "\n",
    "Какой прирост дают эти аугментации вместе и по отдельности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-29T18:51:53.878582Z",
     "start_time": "2022-09-29T18:51:53.869865Z"
    }
   },
   "source": [
    "network = NeuralNetwork([Linear(784, 100), Tanh(),\n",
    "               Linear(100, 100), Tanh(),\n",
    "               Linear(100, 10)])"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Аугментация вращением рандомного элемента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-29T18:11:34.667205Z",
     "start_time": "2022-09-29T18:02:38.066033Z"
    }
   },
   "source": [
    "# !pip install scikit-image\n",
    "from skimage.transform import rotate\n",
    "degrees = 15\n",
    "transform_rotation = transforms.Compose([\n",
    "                     transforms.RandomRotation(degrees),\n",
    "                     transforms.ToTensor(),\n",
    "                     transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])\n",
    "train_dataset = MNIST('.', train=True, download=True, transform=transform_rotation)\n",
    "test_dataset = MNIST('.', train=False, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "network = NeuralNetwork([Linear(784, 100), ReLU(),\n",
    "           Linear(100, 100), ReLU(),\n",
    "           Linear(100, 10)])\n",
    "\n",
    "tr_l_r, t_l_r, tr_a_r, t_a_r = train(network, train_loader, test_loader, NUM_EPOCHS, 0.01)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Аугментация рандомным сдвигом, без поворота"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "source": [
    "network = NeuralNetwork([Linear(784, 100), Tanh(),\n",
    "               Linear(100, 100), Tanh(),\n",
    "               Linear(100, 10)])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-29T18:19:54.915272Z",
     "start_time": "2022-09-29T18:11:34.730869Z"
    }
   },
   "source": [
    "transform_tr = transforms.Compose([\n",
    "                   transforms.RandomAffine(degrees=0, translate=(0.05,0.05)),\n",
    "                   transforms.ToTensor(),\n",
    "                   transforms.Normalize((0.1307,), (0.3081,))\n",
    "                ])\n",
    "train_dataset = MNIST('.', train=True, download=True, transform=transform_tr)\n",
    "test_dataset = MNIST('.', train=False, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "network = NeuralNetwork([Linear(784, 100), ReLU(),\n",
    "           Linear(100, 100), ReLU(),\n",
    "           Linear(100, 10)])\n",
    "\n",
    "tr_l_a, t_l_a, tr_a_a, t_a_a = train(network, train_loader, test_loader, NUM_EPOCHS, 0.01)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Аугментация нормально распределенным шумом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "source": [
    "network = NeuralNetwork([Linear(784, 100), Tanh(),\n",
    "               Linear(100, 100), Tanh(),\n",
    "               Linear(100, 10)])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-29T18:27:05.798970Z",
     "start_time": "2022-09-29T18:21:09.816710Z"
    }
   },
   "source": [
    "transform_tr = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x : x + torch.normal(0, 0.01, size=tuple(x.data.shape))),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "train_dataset = MNIST('.', train=True, download=True, transform=transform_tr)\n",
    "test_dataset = MNIST('.', train=False, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "network = NeuralNetwork([Linear(784, 100), ReLU(),\n",
    "           Linear(100, 100), ReLU(),\n",
    "           Linear(100, 10)])\n",
    "\n",
    "tr_l_n, t_l_n, tr_a_n, t_a_n = train(network, train_loader, test_loader, NUM_EPOCHS, 0.01)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-29T17:57:36.233256Z",
     "start_time": "2022-09-29T17:57:36.233232Z"
    }
   },
   "source": [
    "### Аугментация с вращением, афинными преобразованиями и добавлением нормально распределенного шума"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "source": [
    "network = NeuralNetwork([Linear(784, 100), Tanh(),\n",
    "               Linear(100, 100), Tanh(),\n",
    "               Linear(100, 10)])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-29T18:35:37.268074Z",
     "start_time": "2022-09-29T18:27:05.846525Z"
    }
   },
   "source": [
    "transform_tr = transforms.Compose([\n",
    "    transforms.RandomAffine(15, (0.1, 0.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x : x + torch.normal(0, 0.01, size=tuple(x.data.shape))),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "train_dataset = MNIST('.', train=True, download=True, transform=transform_tr)\n",
    "test_dataset = MNIST('.', train=False, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "network = NeuralNetwork([Linear(784, 100), ReLU(),\n",
    "           Linear(100, 100), ReLU(),\n",
    "           Linear(100, 10)])\n",
    "\n",
    "tr_l_all, t_l_all, tr_a_all, t_a_all = train(network, train_loader, test_loader, NUM_EPOCHS, 0.01)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-29T18:35:37.472721Z",
     "start_time": "2022-09-29T18:35:37.323383Z"
    }
   },
   "source": [
    "plt.figure(figsize=(6, 5))\n",
    "plt.title('Augmentation Impact on Train Loss')\n",
    "\n",
    "\n",
    "plt.plot(t_l_r, label='Rotation')\n",
    "plt.plot(t_l_a, label='Affinity')\n",
    "plt.plot(t_l_n, label='Gauss Noise')\n",
    "plt.plot(t_l_all, label='All')\n",
    "\n",
    "plt.xlabel('Epochs', fontsize=16)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.legend(loc=0, fontsize=16)\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 5: Выводы\n",
    "Опишите полученные результаты: как влияют выбор нелинейности и предобработка данных на скорость сходимости и итоговое качество?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- __Нелинейности:__  \n",
    "Tanh быстрее остальных сходится позволяет достичь лучшего качества.  \n",
    "\n",
    "Activation Func | Train_Loss   | Test_Loss | Train_Acc | Test_Acc | Learning Time\n",
    ":---------------|:-----------: |:--------: | :-------: | :------: | :-----------:\n",
    "Sigmoid         | 0.295        | 0.288     | 0.922     | 0.924    | 5 min 36 sec\n",
    "ReLU            | 0.034        | 0.081     | 0.991     | 0.975    | <b>5 min 26 sec\n",
    "ELU             | 0.044        | <b>0.079     | 0.988     | 0.975    | 6 min 33 sec\n",
    "<b>Tanh         | <b>0.031        | 0.080     | <b>0.994     | <b>0.976    | 5 min 56 sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Предобработка:__  \n",
    "Случайные сдвиги и повороты даже улучшают качество модели на тестовой выборке, что ожидаемо для данного вида аугментаций.  \n",
    "Случайный шум существенно ухудшает качество модели при значениях дисперсии больше 0.5, что опять же очевидно.  \n",
    "При выставлении дисперсии в 0.01 качество так же улучшилось  \n",
    "Интересно, что композиции всех аугментаций не удалось получить качества выше, чем в том случае, когда аугментации применялись индивидуально  \n",
    "\n",
    "__Все измерения выполнены на NLLLoss, а также Tanh как функции активации__\n",
    "\n",
    "Augmentation Type| Train_Loss   | Test_Loss | Train_Acc | Test_Acc | Learning Time\n",
    ":--------------- |:-----------: |:--------: | :-------: | :------: | :-----------:\n",
    "Raw         | 0.031        | 0.080     | 0.994     | 0.976    | 6 min 53 sec\n",
    "w/Rotation         | 0.072        | 0.067     | 0.978     | 0.979    | 6 min 53 sec\n",
    "w/Affinity         | 0.071        | <b>0.061     | 0.979     | <b>0.980    | 7 min 13 sec\n",
    "w/Gaussian Noise   | <b>0.035        | 0.081     | <b>0.990     | 0.976    | <b>5 min 33 sec\n",
    "All              | 0.147        | 0.071     | 0.955     | 0.977    | 7 min 12 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
