{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Семинар 2 \"Распознавание рукописных цифр\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ФИО: Полыковский Даниил Александрович"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом задании мы используем нейронную сеть из предыдущего семинара для распознавания рукописных цифр. Также мы исследуем как влияет выбор нелинейности и предобработка данных на качество классификации. \n",
    "\n",
    "Чтобы не тратить время на подготовку данных, мы прилагаем готовый код с примером использования для получения обучающей и тестовой выборок. Для запуска скрипта вам понадобится библиотека PyTorch (инструкции по установке можно найти на сайте <a href=\"http://pytorch.org\">pytorch.org</a>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import sys\n",
    "from layers import Linear, Sigmoid, NLLLoss, NeuralNetwork # Results from Seminar 1\n",
    "from IPython.display import clear_output\n",
    "%matplotlib inline"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "source": [
    "transform = transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                    ])\n",
    "train_dataset = MNIST('.', train=True, download=True, transform=transform)\n",
    "test_dataset = MNIST('.', train=False, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "source": [
    "X, y = next(iter(train_loader))\n",
    "X = X.numpy()\n",
    "y = y.numpy()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "plt.figure(figsize=(6, 7))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.imshow(X[i].reshape(28, 28), cmap=plt.cm.Greys_r)\n",
    "    plt.title(y[i])\n",
    "    plt.axis('off')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 1: MNIST\n",
    "Обучите полносвязную нейронную сеть с архитектурой 784-100-100-10 и сигмоидой в качестве нелинейности. Какую точность классификации удалось получить? Нарисуйте график сходимости на обучающей и тестовой выборках. В качестве темпа обучения (learning rate) возьмите 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "def train(network, epochs, learning_rate, plot=True,\n",
    "          verbose=True, loss=None):\n",
    "    loss = loss or NLLLoss()\n",
    "    train_loss_epochs = []\n",
    "    test_loss_epochs = []\n",
    "    train_accuracy_epochs = []\n",
    "    test_accuracy_epochs = []\n",
    "    try:\n",
    "        for epoch in range(epochs):\n",
    "            losses = []\n",
    "            accuracies = []\n",
    "            for X, y in train_loader:\n",
    "                X = X.view(X.shape[0], -1).numpy()\n",
    "                y = y.numpy()\n",
    "                prediction = network.forward(X)\n",
    "                loss_batch = loss.forward(prediction, y)\n",
    "                losses.append(loss_batch)\n",
    "                dLdx = loss.backward()\n",
    "                network.backward(dLdx)\n",
    "                network.step(learning_rate)\n",
    "                accuracies.append((np.argmax(prediction, 1)==y).mean())\n",
    "            train_loss_epochs.append(np.mean(losses))\n",
    "            train_accuracy_epochs.append(np.mean(accuracies))\n",
    "            losses = []\n",
    "            accuracies = []    \n",
    "            for X, y in test_loader:\n",
    "                X = X.view(X.shape[0], -1).numpy()\n",
    "                y = y.numpy()\n",
    "                prediction = network.forward(X)\n",
    "                loss_batch = loss.forward(prediction, y)\n",
    "                losses.append(loss_batch)\n",
    "                accuracies.append((np.argmax(prediction, 1)==y).mean())\n",
    "            test_loss_epochs.append(np.mean(losses))\n",
    "            test_accuracy_epochs.append(np.mean(accuracies))\n",
    "            clear_output(True)\n",
    "            if verbose:\n",
    "                sys.stdout.write('\\rEpoch {0}... (Train/Test) NLL: {1:.3f}/{2:.3f}\\tAccuracy: {3:.3f}/{4:.3f}'.format(\n",
    "                            epoch, train_loss_epochs[-1], test_loss_epochs[-1],\n",
    "                            train_accuracy_epochs[-1], test_accuracy_epochs[-1]))\n",
    "            if plot:\n",
    "                plt.figure(figsize=(12, 5))\n",
    "                plt.subplot(1, 2, 1)\n",
    "                plt.plot(train_loss_epochs, label='Train')\n",
    "                plt.plot(test_loss_epochs, label='Test')\n",
    "                plt.xlabel('Epochs', fontsize=16)\n",
    "                plt.ylabel('Loss', fontsize=16)\n",
    "                plt.legend(loc=0, fontsize=16)\n",
    "                plt.grid('on')\n",
    "                plt.subplot(1, 2, 2)\n",
    "                plt.plot(train_accuracy_epochs, label='Train accuracy')\n",
    "                plt.plot(test_accuracy_epochs, label='Test accuracy')\n",
    "                plt.xlabel('Epochs', fontsize=16)\n",
    "                plt.ylabel('Accuracy', fontsize=16)\n",
    "                plt.legend(loc=0, fontsize=16)\n",
    "                plt.grid('on')\n",
    "                plt.show()\n",
    "    except KeyboardInterrupt:\n",
    "        pass\n",
    "    return train_loss_epochs, \\\n",
    "           test_loss_epochs, \\\n",
    "           train_accuracy_epochs, \\\n",
    "           test_accuracy_epochs"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "network = NeuralNetwork([\n",
    "    Linear(784, 100), Sigmoid(), # 28 * 28\n",
    "    Linear(100, 100), Sigmoid(),\n",
    "    Linear(100, 10)\n",
    "])\n",
    "loss = NLLLoss()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "tr_s, ts_s, tr_ac_s, ts_ac_s = train(network, 20, 0.01)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 2: Нелинейности"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите нейронную сеть с другими нелинейностями: ReLU и ELU. Сравните скорости сходимости и качество классификации с различными функциями активации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "source": [
    "class ReLU:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, X):\n",
    "        '''\n",
    "        Passes objects through this layer.\n",
    "        X is np.array of size (N, d)\n",
    "        '''\n",
    "        self.X = X\n",
    "        return np.maximum(X, 0)\n",
    "\n",
    "    def backward(self, dLdy):\n",
    "        '''\n",
    "        1. Compute dLdx.\n",
    "        2. Return dLdx\n",
    "        '''\n",
    "        return (self.X > 0) * dLdy\n",
    "\n",
    "    def step(self, learning_rate):\n",
    "        pass"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "source": [
    "# class ReLU:\n",
    "#     def __init__(self):\n",
    "#         pass\n",
    "\n",
    "#     def forward(self, X):\n",
    "#         '''\n",
    "#         Passes objects through this layer.\n",
    "#         X is np.array of size (N, d)\n",
    "#         '''\n",
    "#         self.X = X\n",
    "#         return np.maximum(X, 0)\n",
    "\n",
    "#     def backward(self, dLdy):\n",
    "#         '''\n",
    "#         1. Compute dLdx.\n",
    "#         2. Return dLdx\n",
    "#         '''\n",
    "#         dydX = (self.X >= 0).astype(float)\n",
    "#         return dLdy*dydX\n",
    "\n",
    "#     def step(self, learning_rate):\n",
    "#         pass"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "source": [
    "class ELU:\n",
    "    '''\n",
    "    ELU(x) = x, x > 0; a*(e^x - 1), x <= 0\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, a=1):\n",
    "        self.a = a\n",
    "\n",
    "    def forward(self, X):\n",
    "        '''\n",
    "        Passes objects through this layer.\n",
    "        X is np.array of size (N, d)\n",
    "        '''\n",
    "        self.X = X\n",
    "        return X * (X > 0) + self.a * (np.exp(X) - 1) * (X <= 0)\n",
    "    \n",
    "    def backward(self, dLdy):\n",
    "        '''\n",
    "        1. Compute dLdx.\n",
    "        2. Return dLdx\n",
    "        '''\n",
    "        X = self.X\n",
    "        dydX = (X > 0) + self.a * np.exp(X) * (X <= 0)\n",
    "        return dLdy*dydX\n",
    "\n",
    "    def step(self, learning_rate):\n",
    "        pass"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "source": [
    "network = NeuralNetwork([\n",
    "    Linear(784, 100), ReLU(),\n",
    "    Linear(100, 100), ReLU(),\n",
    "    Linear(100, 10)\n",
    "])\n",
    "loss = NLLLoss()\n",
    "tr_r, ts_r, tr_ac_r, ts_ac_r = train(network, 20, 0.01, plot=True, verbose=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "source": [
    "network = NeuralNetwork([Linear(784, 100), ELU(),\n",
    "               Linear(100, 100), ELU(),\n",
    "               Linear(100, 10)])\n",
    "loss = NLLLoss()\n",
    "tr_e, ts_e, tr_ac_e, ts_ac_e = train(network, 20, 0.01, plot=True, verbose=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Loss')\n",
    "plt.plot(ts_s, label='Sigmoid')\n",
    "plt.plot(ts_r, label='ReLU')\n",
    "plt.plot(ts_e, label='ELU')\n",
    "plt.xlabel('Epochs', fontsize=16)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.legend(loc=0, fontsize=16)\n",
    "plt.grid()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Accuracy')\n",
    "plt.plot(ts_ac_s, label='Sigmoid')\n",
    "plt.plot(ts_ac_r, label='ReLU')\n",
    "plt.plot(ts_ac_e, label='ELU')\n",
    "plt.xlabel('Epochs', fontsize=16)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.legend(loc=0, fontsize=16)\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW1 (1 балл): Реализовать Tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 3: Анализ ошибок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "source": [
    "wrong_X = []\n",
    "correct_y = []\n",
    "predicted_y = []\n",
    "logits = []\n",
    "for X, y in test_loader:\n",
    "    X = X.view(X.shape[0], -1).numpy()\n",
    "    y = y.numpy()\n",
    "    prediction = network.forward(X)\n",
    "    prediction = np.exp(prediction)\n",
    "    prediction /= prediction.sum(1, keepdims=True)\n",
    "    for i in range(len(prediction)):\n",
    "        if np.argmax(prediction[i]) != y[i]:\n",
    "            wrong_X.append(X[i])\n",
    "            correct_y.append(y[i])\n",
    "            predicted_y.append(np.argmax(prediction[i]))\n",
    "            logits.append(prediction[i][y[i]])\n",
    "wrong_X = np.row_stack(wrong_X)\n",
    "correct_y = np.row_stack(correct_y)[:, 0]\n",
    "predicted_y = np.row_stack(predicted_y)[:, 0]\n",
    "logits = np.row_stack(logits)[:, 0]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "order = np.argsort(logits)\n",
    "for i in range(21):\n",
    "    plt.subplot(3, 7, i+1)\n",
    "    plt.imshow(wrong_X[order[i]].reshape(28, 28), cmap=plt.cm.Greys_r)\n",
    "    plt.title('{}({})'.format(correct_y[order[i]], predicted_y[order[i]]), fontsize=20)\n",
    "    plt.axis('off')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 4: Аугментация (HW, 2 балла)\n",
    "* Небольшие вращения (-15, 15)\n",
    "* Случайные сдвиги\n",
    "* Шум\n",
    "\n",
    "Какой прирост дают эти аугментации вместе и по отдельности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "source": [
    "from skimage.transform import rotate"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 5: Выводы\n",
    "Опишите полученные результаты: как влияют выбор нелинейности и предобработка данных на скорость сходимости и итоговое качество?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
