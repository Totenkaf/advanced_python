{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ab59170",
   "metadata": {
    "id": "6ab59170"
   },
   "source": [
    "# Обучение модели FasterRCNN и YOLOv5 для детекции Helmet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f010ff7",
   "metadata": {
    "id": "2f010ff7"
   },
   "source": [
    "ФИО: Усцов Артем Алексеевич"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1980f61f",
   "metadata": {
    "id": "1980f61f",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668281809332,
     "user_tz": -180,
     "elapsed": 3343,
     "user": {
      "displayName": "Артём Усцов",
      "userId": "16141628694791373514"
     }
    }
   },
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import seaborn as sns\n",
    "import torchvision\n",
    "import torch\n",
    "# import PIL\n",
    "# from PIL import Image\n",
    "import json\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b27ebbcf",
   "metadata": {
    "id": "b27ebbcf",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668281809332,
     "user_tz": -180,
     "elapsed": 4,
     "user": {
      "displayName": "Артём Усцов",
      "userId": "16141628694791373514"
     }
    }
   },
   "source": [
    "def show_image(image, figsize=(16, 9), reverse=True):\n",
    "    plt.figure(figsize=figsize)\n",
    "    if reverse:\n",
    "        plt.imshow(image[...,::-1])\n",
    "    else:\n",
    "        plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def save_to_json(filename, data):\n",
    "    with open(filename, 'w') as f:\n",
    "        return json.dump(data, f)\n",
    "    \n",
    "def load_from_json(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        return json.load(f)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "615caecc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "615caecc",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668281810135,
     "user_tz": -180,
     "elapsed": 806,
     "user": {
      "displayName": "Артём Усцов",
      "userId": "16141628694791373514"
     }
    },
    "outputId": "b9ed6ae0-21ac-4edf-ed3b-0639b03a6f3b"
   },
   "source": [
    "# Пример изображения с детектируемым объектом\n",
    "!wget https://github.com/Totenkaf/DL_Homeworks/raw/main/HW_7/helmet.jpg -P data/"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "Image(filename='data/helmet.jpg')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "A96iBZabzlgL",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668281810970,
     "user_tz": -180,
     "elapsed": 837,
     "user": {
      "displayName": "Артём Усцов",
      "userId": "16141628694791373514"
     }
    },
    "outputId": "b1f61958-75cd-4470-b0d8-e0443395f5e2"
   },
   "id": "A96iBZabzlgL",
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "90d9470e",
   "metadata": {
    "id": "90d9470e"
   },
   "source": [
    "* Используем dataset LVIS [link](https://www.lvisdataset.org/)  \n",
    "* [Репозиторий YOLOv5](https://github.com/ultralytics/yolov5)  \n",
    "* [Конфигурационный файл](https://github.com/ultralytics/yolov5/blob/master/data/coco128.yaml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d11ee89",
   "metadata": {
    "id": "1d11ee89"
   },
   "source": [
    "## Обучение модели FasterRCNN"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1KbwPmpF4Gt4DR3a_SpSOInonnbm1xX33' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1KbwPmpF4Gt4DR3a_SpSOInonnbm1xX33\" -O cv_det.zip && rm -rf /tmp/cookies.txt && unzip cv_det.zip && rm -rf cv_det.zip"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "blz9gMBYJGY7",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668283055053,
     "user_tz": -180,
     "elapsed": 9754,
     "user": {
      "displayName": "Артём Усцов",
      "userId": "16141628694791373514"
     }
    },
    "outputId": "23945596-a7b7-4de9-b30b-ba3883e8d22a"
   },
   "id": "blz9gMBYJGY7",
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!wget http://images.cocodataset.org/zips/train2017.zip -P cv_det/ && unzip cv_det/train2017.zip && mv cv_det/train2017 cv_det/train"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7CIGh9390TC9",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668281770470,
     "user_tz": -180,
     "elapsed": 34014,
     "user": {
      "displayName": "Артём Усцов",
      "userId": "16141628694791373514"
     }
    },
    "outputId": "09b0d129-2385-4be8-b364-82be31b63e19"
   },
   "id": "7CIGh9390TC9",
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!unzip dataset/train2017.zip -d /dataset && mv dataset/train2017 dataset/train"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1kxLzraUGNAp",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668277905437,
     "user_tz": -180,
     "elapsed": 3367,
     "user": {
      "displayName": "Артём Усцов",
      "userId": "16141628694791373514"
     }
    },
    "outputId": "b08bc55c-ee7b-4acd-b005-cdfe327ea89a"
   },
   "id": "1kxLzraUGNAp",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "os.chdir('/content/cv_det')\n",
    "!git clone https://github.com/ultralytics/yolov5  # clone"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RHjNiabRcEny",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668283620344,
     "user_tz": -180,
     "elapsed": 2492,
     "user": {
      "displayName": "Артём Усцов",
      "userId": "16141628694791373514"
     }
    },
    "outputId": "728ec172-4ab7-46a7-f38d-f94ba34fa50c"
   },
   "id": "RHjNiabRcEny",
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "os.chdir('/content/cv_det/yolov5') \n",
    "!python train.py --data lvis.yaml --cfg yolov5s.yaml --weights '' --batch-size 64"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0hA4_7UjcEH5",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668283717252,
     "user_tz": -180,
     "elapsed": 3010,
     "user": {
      "displayName": "Артём Усцов",
      "userId": "16141628694791373514"
     }
    },
    "outputId": "fa388639-441f-4835-d941-e4bbacbaea71"
   },
   "id": "0hA4_7UjcEH5",
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "os.getcwd()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "ZxHeqP0vcEDV",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668283733461,
     "user_tz": -180,
     "elapsed": 7,
     "user": {
      "displayName": "Артём Усцов",
      "userId": "16141628694791373514"
     }
    },
    "outputId": "08578758-8534-4a0b-dc19-5f1bcc36809e"
   },
   "id": "ZxHeqP0vcEDV",
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "ww26Zz_NcD-l"
   },
   "id": "ww26Zz_NcD-l",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "C7dCADMNcD6C"
   },
   "id": "C7dCADMNcD6C",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "kUIifQeBcD1k"
   },
   "id": "kUIifQeBcD1k",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "0oWMHADecDw3"
   },
   "id": "0oWMHADecDw3",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "cnQ59OcWcDsX"
   },
   "id": "cnQ59OcWcDsX",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "bzei-L8pcDnh"
   },
   "id": "bzei-L8pcDnh",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "PNrU4QYBcDg6"
   },
   "id": "PNrU4QYBcDg6",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "cT03dfdNcDUz"
   },
   "id": "cT03dfdNcDUz",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'\n",
    "!pip install lvis"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mGm2DaKt8cJs",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1668276407001,
     "user_tz": -180,
     "elapsed": 16111,
     "user": {
      "displayName": "Артём Усцов",
      "userId": "16141628694791373514"
     }
    },
    "outputId": "9f9543ee-41ae-4edc-d60f-1d0397e5e834"
   },
   "id": "mGm2DaKt8cJs",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "import lvis\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "import seaborn as sns"
   ],
   "metadata": {
    "id": "GFA9w0eB8yas"
   },
   "id": "GFA9w0eB8yas",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb904e75",
   "metadata": {
    "id": "fb904e75"
   },
   "source": [
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "def val_transform(img):\n",
    "    img_tensor = to_tensor(img)\n",
    "    return img_tensor.unsqueeze(0)\n",
    "\n",
    "def visualize_prediction(file, model, device='cuda', verbose=True, thresh=0.0, n_colors=None):\n",
    "    img = Image.open(file)\n",
    "    img_tensor = val_transform(img)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(img_tensor.to(device)) # list of size 1\n",
    "    prediction = predictions[0]\n",
    "    \n",
    "    if n_colors is None:\n",
    "        n_colors = model.roi_heads.box_predictor.cls_score.out_features\n",
    "    \n",
    "    palette = sns.color_palette(None, n_colors)\n",
    "    \n",
    "    # visualize\n",
    "    img = cv2.imread(file, cv2.COLOR_BGR2RGB)\n",
    "    for i in range(len(prediction['boxes'])):\n",
    "        x1, x2, x3, x4 = map(int, prediction['boxes'][i].tolist())\n",
    "        label = int(prediction['labels'][i].cpu())\n",
    "        score = float(prediction['scores'][i].cpu())\n",
    "        name = coco_id_to_name[label]\n",
    "        color = palette[label]\n",
    "        if verbose:\n",
    "            if score > thresh:\n",
    "                print ('Class: {}, Confidence: {}'.format(name, score))\n",
    "        if score > thresh:\n",
    "            image = cv2.rectangle(img, (x1, x2), (x3, x4), np.array(color) * 255, 2)\n",
    "            cv2.putText(image, name, (x1, x2-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, np.array(color) * 255, 2)\n",
    "    show_image(image)\n",
    "    return prediction"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd994af",
   "metadata": {
    "id": "ddd994af"
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from PIL import Image\n",
    "import json\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "class DetectionDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_dict_file, images_path, transforms=None):\n",
    "        self.transforms = transforms\n",
    "        self.images_path = images_path\n",
    "        self.lvis_api_data = lvis.LVIS(data_dict_file)\n",
    "        # with open(data_dict_file, 'r') as f:\n",
    "        #     self.data_dict = json.load(f)\n",
    "        \n",
    "        self.imgs = self.lvis_api_data.load_imgs(list(set(self.lvis_api_data.cat_img_map[556])))\n",
    "        #list(set(lvis_train_dataset.cat_img_map[556]))\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        # load images ad masks\n",
    "        img_path = self.images_path + self.imgs[idx]['coco_url'].rpartition('/')[-1]\n",
    "        try:\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "        except FileNotFoundError as f:\n",
    "            self.lvis_api_data.download(self.images_path, self.imgs[idx]['id'])\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "        w, h = img.size\n",
    "\n",
    "        objs = []\n",
    "        for i in self.lvis_api_data.img_ann_map[self.imgs[idx]['id']]:\n",
    "            if i['category_id'] == 556:\n",
    "                objs.append(i)\n",
    "\n",
    "        num_objs = len(objs)\n",
    "        boxes = []\n",
    "        for i in objs:\n",
    "            bbox = i['bbox']\n",
    "            xmin = bbox[0]   # * w\n",
    "            ymin = bbox[1]   # * w\n",
    "            xdelt = bbox[2]  # * h\n",
    "            ydelt = bbox[3]  # * h\n",
    "            boxes.append([xmin, ymin, xmin+xdelt, ymin+ydelt])\n",
    "\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        # there is only one class\n",
    "        labels = torch.ones((num_objs,), dtype=torch.int64)\n",
    "        \n",
    "        # is crowd\n",
    "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "\n",
    "        image_id = torch.tensor([idx])\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        return img, target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "def visualize_from_dataset(dataset: DetectionDataset, idx):\n",
    "    file = img_path = dataset.images_path + dataset.imgs[idx]['coco_url'].rpartition('/')[-1]\n",
    "    img = cv2.imread(file, cv2.COLOR_BGR2RGB)\n",
    "    h, w = img.shape[:2]\n",
    "    objs = []\n",
    "    objs = dataset.lvis_api_data.img_ann_map[dataset.imgs[idx]['id']]\n",
    "    num_objs = len(objs)\n",
    "    for i in objs:\n",
    "        x_min, y_min, xdelt, ydelt = tuple(i['bbox'])\n",
    "        y_max = int(y_min+ydelt)\n",
    "        x_max = int(x_min+xdelt)\n",
    "        print(type(x_min))\n",
    "        image = cv2.rectangle(img, (int(x_min), int(y_min)), (int(x_max), int(y_max)), (0, 255, 0), 2)\n",
    "    show_image(image)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "img_transforms = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ],
   "metadata": {
    "id": "tow3ndjb83Im"
   },
   "id": "tow3ndjb83Im",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))"
   ],
   "metadata": {
    "id": "mwB7QkLZ83m7"
   },
   "id": "mwB7QkLZ83m7",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_dataset = DetectionDataset('datasets/LVIS/lvis_v1_train.json', 'datasets/LVIS/train/', img_transforms)\n",
    "val_dataset = DetectionDataset('datasets/LVIS/lvis_v1_val.json', 'datasets/LVIS/val/', img_transforms)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "id": "v-gwkGOg84DA",
    "executionInfo": {
     "status": "error",
     "timestamp": 1668276483628,
     "user_tz": -180,
     "elapsed": 424,
     "user": {
      "displayName": "Артём Усцов",
      "userId": "16141628694791373514"
     }
    },
    "outputId": "1269a191-f6fe-41ea-f661-8b341884bcbf"
   },
   "id": "v-gwkGOg84DA",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "visualize_from_dataset(val_dataset, 1)"
   ],
   "metadata": {
    "id": "-ghiKa_m84JT"
   },
   "id": "-ghiKa_m84JT",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# define training and validation data loaders\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=4, shuffle=True, num_workers=4,\n",
    "    collate_fn=collate_fn, drop_last=True)\n",
    "\n",
    "data_loader_val = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=4, shuffle=False, num_workers=1,\n",
    "    collate_fn=collate_fn, drop_last=False)"
   ],
   "metadata": {
    "id": "4C2OgrQr84eY"
   },
   "id": "4C2OgrQr84eY",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "# load a model pre-trained pre-trained on COCO\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True, pretrained_backbone=True)"
   ],
   "metadata": {
    "id": "c5YdyFnt84lx"
   },
   "id": "c5YdyFnt84lx",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "num_classes = 2\n",
    "in_channels = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_channels=in_channels, num_classes=num_classes)"
   ],
   "metadata": {
    "id": "c4iYIC6M84rQ"
   },
   "id": "c4iYIC6M84rQ",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "assert model.roi_heads.box_predictor.cls_score.in_features == 1024\n",
    "assert model.roi_heads.box_predictor.cls_score.out_features == 2\n",
    "assert model.roi_heads.box_predictor.bbox_pred.out_features == 8"
   ],
   "metadata": {
    "id": "jtdGtO6A9DbW"
   },
   "id": "jtdGtO6A9DbW",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# move model to the right device\n",
    "model.to(device)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "for param in model.roi_heads.box_predictor.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "# construct an optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005,\n",
    "                            momentum=0.9, weight_decay=0.0005)"
   ],
   "metadata": {
    "id": "-nVFRj_q9D23"
   },
   "id": "-nVFRj_q9D23",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "len(params)"
   ],
   "metadata": {
    "id": "MQfxGP7x9D9J"
   },
   "id": "MQfxGP7x9D9J",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                               step_size=30,\n",
    "                                               gamma=0.1)"
   ],
   "metadata": {
    "id": "AcTdJA7q9EC_"
   },
   "id": "AcTdJA7q9EC_",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from engine import evaluate"
   ],
   "metadata": {
    "id": "mlM_P_tT9EHQ"
   },
   "id": "mlM_P_tT9EHQ",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import math\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "\n",
    "from coco_utils import get_coco_api_from_dataset\n",
    "from coco_eval import CocoEvaluator\n",
    "import utils\n",
    "\n",
    "def train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq):\n",
    "    model.train()\n",
    "    metric_logger = utils.MetricLogger(delimiter=\"  \")\n",
    "    metric_logger.add_meter('lr', utils.SmoothedValue(window_size=1, fmt='{value:.6f}'))\n",
    "    header = 'Epoch: [{}]'.format(epoch)\n",
    "\n",
    "    lr_scheduler = None\n",
    "    if epoch == 0:\n",
    "        warmup_factor = 1. / 1000\n",
    "        warmup_iters = min(1000, len(data_loader) - 1)\n",
    "\n",
    "        lr_scheduler = utils.warmup_lr_scheduler(optimizer, warmup_iters, warmup_factor)\n",
    "\n",
    "    for images, targets in metric_logger.log_every(data_loader, print_freq, header):\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "\n",
    "        # получим предсказания сети (словарь)        \n",
    "        loss_dict = model(images, targets)\n",
    "        # cложим их\n",
    "        losses = sum(value for value in loss_dict.values())\n",
    "        loss_value = losses.item()\n",
    "\n",
    "        if not math.isfinite(loss_value):\n",
    "            print(\"Loss is {}, stopping training\".format(loss_value))\n",
    "            #print(loss_dict_reduced)\n",
    "            sys.exit(1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if lr_scheduler is not None:\n",
    "            lr_scheduler.step()\n",
    "\n",
    "        metric_logger.update(loss=losses, **loss_dict)\n",
    "        metric_logger.update(lr=optimizer.param_groups[0][\"lr\"])"
   ],
   "metadata": {
    "id": "npWvzqDP9EML"
   },
   "id": "npWvzqDP9EML",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(devices)"
   ],
   "metadata": {
    "id": "hugziZPV9QhC"
   },
   "id": "hugziZPV9QhC",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "num_epochs=50\n",
    "for epoch in range(num_epochs):\n",
    "    train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=50)\n",
    "    # update the learning rate\n",
    "    lr_scheduler.step()\n",
    "    # evaluate on the test dataset\n",
    "    evaluate(model, data_loader_val, device=device)\n",
    "    torch.save(model.state_dict(), 'helmet_fasterrcnn_model_final.pth')"
   ],
   "metadata": {
    "id": "YhH_H3-89OQU"
   },
   "id": "YhH_H3-89OQU",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "val_dataset = DetectionDataset('datasets/LVIS/lvis_v1_val.json', 'datasets/LVIS/val/', img_transforms)\n",
    "data_loader_val = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=4, shuffle=False, num_workers=1,\n",
    "    collate_fn=collate_fn, drop_last=False)"
   ],
   "metadata": {
    "id": "tS9s4dxw9OZf"
   },
   "id": "tS9s4dxw9OZf",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "# load a model pre-trained pre-trained on COCO\n",
    "faster_rcnn = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True, pretrained_backbone=True)"
   ],
   "metadata": {
    "id": "hy0YDPGx9OgH"
   },
   "id": "hy0YDPGx9OgH",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "num_classes = 2\n",
    "in_channels = faster_rcnn.roi_heads.box_predictor.cls_score.in_features\n",
    "faster_rcnn.roi_heads.box_predictor = FastRCNNPredictor(in_channels=in_channels, num_classes=num_classes)"
   ],
   "metadata": {
    "id": "jShgURJF9Omw"
   },
   "id": "jShgURJF9Omw",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "assert faster_rcnn.roi_heads.box_predictor.cls_score.in_features == 1024\n",
    "assert faster_rcnn.roi_heads.box_predictor.cls_score.out_features == 2\n",
    "assert faster_rcnn.roi_heads.box_predictor.bbox_pred.out_features == 8"
   ],
   "metadata": {
    "id": "fowi55Y49Wg0"
   },
   "id": "fowi55Y49Wg0",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "faster_rcnn.load_state_dict(torch.load('./helmet_fasterrcnn_model_final.pth', map_location=device))\n",
    "faster_rcnn.to(device)"
   ],
   "metadata": {
    "id": "tvd-LzDb9W6o"
   },
   "id": "tvd-LzDb9W6o",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def visualize_prediction_plate(file, model, device='cuda', verbose=True, thresh=0.0, \n",
    "                               n_colors=None, id_to_name=None):\n",
    "    img = Image.open(file)\n",
    "    img_tensor = val_transform(img)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = model(img_tensor.to(device)) # list of size 1\n",
    "    prediction = predictions[0]\n",
    "    \n",
    "    if n_colors is None:\n",
    "        n_colors = model.roi_heads.box_predictor.cls_score.out_features\n",
    "    \n",
    "    palette = sns.color_palette(None, n_colors)\n",
    "    \n",
    "    # visualize\n",
    "    img = cv2.imread(file, cv2.COLOR_BGR2RGB)\n",
    "    h, w = img.shape[:2]\n",
    "    image = img\n",
    "    for i in range(len(prediction['boxes'])):\n",
    "        x_min, y_min, x_max, y_max = map(int, prediction['boxes'][i].tolist())\n",
    "        label = int(prediction['labels'][i].cpu())\n",
    "        score = float(prediction['scores'][i].cpu())\n",
    "        name = id_to_name[label]\n",
    "        color = palette[label]\n",
    "        if verbose:\n",
    "            if score > thresh:\n",
    "                print ('Class: {}, Confidence: {}'.format(name, score))\n",
    "        if score > thresh:\n",
    "            image = cv2.rectangle(img, (x_min, y_min), (x_max, y_max), np.array(color) * 255, 2)\n",
    "            cv2.putText(image, name + f\": {round(score,2)}\", (x_min, y_min-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, np.array(color) * 255, 2)\n",
    "    show_image(image)\n",
    "    return prediction"
   ],
   "metadata": {
    "id": "yHbb3YYn9XAq"
   },
   "id": "yHbb3YYn9XAq",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "img = Image.open(\"datasets/LVIS/train/000000144795.jpg\")\n",
    "x_min = img.width*0.4407265-img.width*0.1250781/2\n",
    "y_min = img.height*0.1490281-img.height*0.2290632/2\n",
    "x_max = img.width*0.4407265+img.width*0.1250781/2\n",
    "y_max = img.height*0.1490281+img.height*0.2290632/2\n",
    "img = cv2.imread(\"datasets/LVIS/train/000000144795.jpg\", cv2.COLOR_BGR2RGB)\n",
    "palette = sns.color_palette(None, 1)\n",
    "color = palette[0]\n",
    "image = cv2.rectangle(img, (int(x_min), int(y_min)), (int(x_max),int(y_max)), np.array(color) * 255, 2)\n",
    "show_image(image)\n",
    "#cv2.putText(image, \"name\", (x_min, y_min-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, np.array(color) * 255, 2)\n",
    "print(x_min, y_min, x_max, y_max)"
   ],
   "metadata": {
    "id": "_7PWfPcF9XFV"
   },
   "id": "_7PWfPcF9XFV",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "file_name = \"datasets/LVIS/train/000000144795.jpg\"\n",
    "\n",
    "id_to_name = {\n",
    "    1: \"helmet\"\n",
    "    }\n",
    "\n",
    "visualize_prediction_plate(file_name, faster_rcnn, device=device, id_to_name=id_to_name, thresh=0.7)"
   ],
   "metadata": {
    "id": "JgxJfzdD9XJ3"
   },
   "id": "JgxJfzdD9XJ3",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "file_name = \"helmet_test.jpg\"\n",
    "visualize_prediction_plate(file_name, faster_rcnn, device=device, id_to_name=id_to_name, thresh=0.2)"
   ],
   "metadata": {
    "id": "jDASAQN39j5G"
   },
   "id": "jDASAQN39j5G",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "file_name = \"helmet_test2.jpg\"\n",
    "visualize_prediction_plate(file_name, faster_rcnn, device=device, id_to_name=id_to_name)"
   ],
   "metadata": {
    "id": "Lj7Sv_Er9kQG"
   },
   "id": "Lj7Sv_Er9kQG",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "img = np.random.choice(val_dataset.imgs)\n",
    "img_filename = val_dataset.images_path + img['coco_url'].rpartition('/')[-1]\n",
    "visualize_prediction_plate(img_filename, faster_rcnn, device=device, id_to_name=id_to_name, thresh=0.5)"
   ],
   "metadata": {
    "id": "Cv56Wg959m9_"
   },
   "id": "Cv56Wg959m9_",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "86222g3E9pE8"
   },
   "id": "86222g3E9pE8",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "ndpUItsM9pdi"
   },
   "id": "ndpUItsM9pdi",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "f5tpsqeJ9pkZ"
   },
   "id": "f5tpsqeJ9pkZ",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "colab": {
   "provenance": [],
   "collapsed_sections": []
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
