{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/kaggle/input/explicit-content-detection/train.csv\")\n",
    "test_df = pd.read_csv(\"/kaggle/input/explicit-content-detection/test.csv\")\n",
    "\n",
    "titles = train_df[\"title\"].values\n",
    "urls = train_df[\"url\"].values\n",
    "y = train_df[\"target\"].astype(int).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define symbols & words we don't need\n",
    "translator = {ord(c): ' ' for c in punctuation + '0123456789«»—–…✅№'}\n",
    "nltk.download('stopwords')\n",
    "stop_words = nltk.corpus.stopwords.words('russian') + nltk.corpus.stopwords.words('english')\n",
    "print(stop_words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Remove stop words\n",
    "'''\n",
    "def remove_stops(collection):\n",
    "    return [w for w in collection if w not in stop_words]\n",
    "\n",
    "\n",
    "'''\n",
    "Split titles array into tokens\n",
    "'''\n",
    "def split_into_tokens(X):\n",
    "    n_samples = X.size\n",
    "    tokens = []\n",
    "\n",
    "    print('Splitting...')\n",
    "    for i in range(n_samples):\n",
    "        tokens.append(remove_stops(X[i].translate(translator).lower().split()))\n",
    "\n",
    "        if i % 10000 == 0:\n",
    "            print(f'Done: {i}/{n_samples}')\n",
    "\n",
    "    print(f'Done: {n_samples}/{n_samples}\\n')\n",
    "    return tokens\n",
    "\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer \n",
    "\n",
    "'''\n",
    "Do stemming with splitted word tokens\n",
    "'''\n",
    "def do_stemming(X):\n",
    "    n_samples = len(X)\n",
    "    stemmer = SnowballStemmer(\"russian\")\n",
    "    stemmed = []\n",
    "\n",
    "    print('Stemming...')\n",
    "    for i in range(n_samples):\n",
    "        stemmed.append(list(map(stemmer.stem, X[i])))\n",
    "\n",
    "        if i % 10000 == 0:\n",
    "            print(f'Done: {i}/{n_samples}')\n",
    "\n",
    "    print(f'Done: {n_samples}/{n_samples}\\n')\n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into test and train sets\n",
    "train_titles, test_titles, train_urls, test_urls, train_y, test_y = train_test_split(titles, urls, y, test_size=0.33, stratify=y)\n",
    "n_samples = len(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_stemmed_tokens = do_stemming(split_into_tokens(train_titles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn on simple tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create corpus of all words\n",
    "'''\n",
    "def make_corpus(X, y):\n",
    "    corpus_all = []\n",
    "    corpus_porn = []\n",
    "\n",
    "    for sample, is_porn in zip(X, y):\n",
    "        corpus_all.extend(set(sample))\n",
    "\n",
    "        if is_porn:\n",
    "            corpus_porn.extend(set(sample))\n",
    "            \n",
    "    return corpus_all, corpus_porn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count words\n",
    "# We need to do this to calculate importance of each word\n",
    "corpus_titles_all, corpus_titles_porn = make_corpus(X_stemmed_tokens, train_y)\n",
    "count_titles_all = Counter(corpus_titles_all)\n",
    "count_titles_porn = Counter(corpus_titles_porn)\n",
    "\n",
    "# Count urls\n",
    "corpus_urls_porn = [train_urls[i] for i in range(n_samples) if train_y[i]]\n",
    "count_urls_all = Counter(train_urls)\n",
    "count_urls_porn = Counter(corpus_urls_porn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Entropy of word\n",
    "We have to estimate, how valuable deviation of given porn share from overall mean \n",
    "'''\n",
    "def word_porn_rate(porn_share, mean_share, penalize):\n",
    "    if porn_share > mean_share:\n",
    "        return (porn_share - mean_share) / (1 - mean_share)\n",
    "    \n",
    "    fine = mean_share / (1 - mean_share) if penalize else 1\n",
    "    return (porn_share - mean_share) * fine / mean_share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Define word score based on it's frequency and entropy\n",
    "'''\n",
    "def word_score(porn_rate, frequency, f_weight = 0.3):\n",
    "    return ((frequency * f_weight) + np.abs(porn_rate) * (1 - f_weight)) / 2\n",
    "\n",
    "'''\n",
    "Get n best words based on word_score\n",
    "'''\n",
    "def get_n_best_words(n, x_size, mean_share, counter_porn, counter_all, min_freq=0.001, f_weight=0.3, penalize=True):\n",
    "    word_scores = {}\n",
    "    word_weights = {}\n",
    "    \n",
    "    # Evaluate scores for each popular word\n",
    "    for word, count in counter_all.items():\n",
    "        if count/x_size >= min_freq:\n",
    "            porn_count = counter_porn[word]\n",
    "            porn_share = porn_count / count\n",
    "            frequency = count / x_size\n",
    "            porn_rate = word_porn_rate(porn_share, mean_share, penalize)\n",
    "            word_weights[word] = porn_rate\n",
    "            word_scores[word] = word_score(porn_rate, frequency, f_weight)\n",
    "            \n",
    "    # Get n best words (or all words we have, if n is too big)\n",
    "    best_words, best_weights = [], []\n",
    "    \n",
    "    for word in sorted(word_scores.keys(), key=lambda w: word_scores[w], reverse=True)[:n]:\n",
    "        best_words.append(word)\n",
    "        best_weights.append(word_weights[word])\n",
    "            \n",
    "    return best_words, np.array(best_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get most valuable words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(train_y)\n",
    "best_words, best_word_weights = get_n_best_words(100, n_samples, mean, count_titles_porn, count_titles_all, min_freq=0.001, f_weight=0.3)\n",
    "best_urls, best_url_weights = get_n_best_words(100000, n_samples, mean, count_urls_porn, count_urls_all, min_freq=0.0001, f_weight=0.3, penalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best words:')\n",
    "for i in range(70, 100):\n",
    "    word = best_words[i]\n",
    "    print(f'{word} : {best_word_weights[i]}, {count_titles_all[word]}')\n",
    "    \n",
    "print('\\nBest urls:')\n",
    "for i in range(30):\n",
    "    url = best_urls[i]\n",
    "    print(f'{url} : {best_url_weights[i]}, {count_urls_all[url]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Transform the tokens array into vectors\n",
    "'''\n",
    "def tokens_to_vecs(tokens_X, n_samples, words, n_words):\n",
    "    vectors_X = np.empty((n_samples, n_words))\n",
    "    \n",
    "    print('Vectorising...')\n",
    "    for i in range(n_samples):\n",
    "        tokens = tokens_X[i]\n",
    "        vectors_X[i] = [int(word in tokens) for word in words]\n",
    "        \n",
    "        if i % 10000 == 0:\n",
    "            print(f'Done: {i}/{n_samples}')\n",
    "        \n",
    "    print(f'Done: {n_samples}/{n_samples}')\n",
    "    return vectors_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Make target prediction based on valuable words\n",
    "'''\n",
    "def vec_to_predict(tokens_vec, best_weights):\n",
    "    return int(np.mean(tokens_vec * best_weights) > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test predictor based on simple tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_X_vecs = tokens_to_vecs(test_X, len(test_X), best_words, len(best_words))\n",
    "# train_X_vecs = tokens_to_vecs(train_X, len(train_X), best_words, len(best_words))\n",
    "\n",
    "# test_accuracies = []\n",
    "# train_accuracies = []\n",
    "# always_false = [0 for _ in test_X_vecs]\n",
    "# xs = np.arange(10, 210, 10)\n",
    "# const_accuracies = [1 - mean for i in xs]\n",
    "\n",
    "# for i in xs:\n",
    "#     test_predictions = [vec_to_predict(vec[:i], best_weights[:i]) for vec in test_X_vecs]\n",
    "#     test_accuracies.append(accuracy_score(test_y, test_predictions))\n",
    "    \n",
    "# plt.plot(xs, test_accuracies, 'r', xs, const_accuracies, 'g')\n",
    "# plt.plot(max(xs, key=lambda x: test_accuracies[int(x/10 - 1)]), max(test_accuracies), 'r^')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_predictions = [vec_to_predict(vec[:70], best_weights[:70]) for vec in test_X_vecs]\n",
    "# print(f'Accuracy: {accuracy_score(test_y, test_predictions)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict with urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_urls = train_df[\"url\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split data into test and train sets\n",
    "train_X_urls, test_X_urls, train_y_urls, test_y_urls = train_test_split(X_urls, y_train, test_size=0.33, stratify=y_train)\n",
    "porn_urls = [url for i, url in enumerate(train_X_urls) if train_y_urls[i]]\n",
    "\n",
    "# Count urls\n",
    "count_urls = Counter(train_X_urls)\n",
    "count_urls_porn = Counter(porn_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get valuable urls\n",
    "mean = np.mean(train_y_urls)\n",
    "x_size = len(train_X_urls)\n",
    "best_urls, best_urls_weights = get_n_best_words(25000, x_size, mean, count_urls_porn, count_urls, min_freq=0.00001, f_weight=0.3, penalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(best_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    url = best_urls[i]\n",
    "    print(f'{url}  count: {count_urls[url]}  share: {count_urls_porn[url]/count_urls[url]}  weight: {best_urls_weights[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def url_to_predict(url, urls, weights):\n",
    "    try:\n",
    "        return int(weights[urls.index(url)] > 0)\n",
    "    except ValueError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test predictor based on urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_accuracies_urls = []\n",
    "# xs = np.arange(10000, 25500, 500)\n",
    "\n",
    "# for x in xs:\n",
    "#     urls, weights = best_urls[:x], best_urls_weights[:x]\n",
    "#     predictions = [url_to_predict(url, urls, weights) for url in test_X_urls]\n",
    "#     test_accuracies_urls.append(accuracy_score(test_y_urls, predictions))\n",
    "    \n",
    "# plt.plot(xs, test_accuracies_urls, 'r')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [url_to_predict(url, best_urls, best_urls_weights) for url in test_X_urls]\n",
    "accuracy_score(test_y_urls, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_urls = test_df[\"url\"].values\n",
    "# n_samples = X_test_urls.size\n",
    "# validate_predictions = [bool(url_to_predict(url, best_urls, best_urls_weights)) for url in X_test_urls]\n",
    "\n",
    "# data = {\n",
    "#     'id': [i for i in range(135309, 135309 + n_samples)],\n",
    "#     'target': validate_predictions\n",
    "# }\n",
    "\n",
    "# validate_df = pd.DataFrame(data)\n",
    "# validate_df.to_csv('simple_urls.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
