{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2a1c4fa",
   "metadata": {},
   "source": [
    "# Main libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# import keras as ks\n",
    "import keras as ks\n",
    "import nltk\n",
    "import re\n",
    "import codecs\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "%matplotlib inline"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3d5d971",
   "metadata": {},
   "source": [
    "def load_data_from_arrays(strings, labels, train_test_split=0.9):\n",
    "    data_size = len(strings)\n",
    "    test_size = int(data_size - round(data_size * train_test_split))\n",
    "    print(\"Test size: {}\".format(test_size))\n",
    "    \n",
    "    print(\"\\nTraining set:\")\n",
    "    x_train = strings[test_size:]\n",
    "    print(\"\\t - x_train: {}\".format(len(x_train)))\n",
    "    y_train = labels[test_size:]\n",
    "    print(\"\\t - y_train: {}\".format(len(y_train)))\n",
    "    \n",
    "    print(\"\\nTesting set:\")\n",
    "    x_test = strings[:test_size]\n",
    "    print(\"\\t - x_test: {}\".format(len(x_test)))\n",
    "    y_test = labels[:test_size]\n",
    "    print(\"\\t - y_test: {}\".format(len(y_test)))\n",
    "\n",
    "    return x_train, y_train, x_test, y_test"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1053aeef",
   "metadata": {},
   "source": [
    "descriptions = clean_train_df['title_clean']\n",
    "categories = clean_train_df['target']\n",
    "\n",
    "descriptions_test = clean_test_df['title_clean']"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a91cb538",
   "metadata": {},
   "source": [
    "descriptions_encoded = clean_train_encoded_df['title_clean']\n",
    "categories_encoded = clean_train_encoded_df['target']"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ac6aab8",
   "metadata": {},
   "source": [
    "descriptions_test_encoded = clean_test_encoded_df['title_clean']"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2810da04",
   "metadata": {},
   "source": [
    "descriptions[:5]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e076e99",
   "metadata": {},
   "source": [
    "categories[:5]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75c74dd0",
   "metadata": {},
   "source": [
    "descriptions_encoded[:5]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1255d2b2",
   "metadata": {},
   "source": [
    "categories_encoded[:5]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eea2c43b",
   "metadata": {},
   "source": [
    "descriptions_test[:5]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef7fdc8d",
   "metadata": {},
   "source": [
    "descriptions_test_encoded[:5]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6532c109",
   "metadata": {},
   "source": [
    "# создаем единый словарь (слово -> число) для преобразования\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(descriptions.tolist())\n",
    "\n",
    "# Преобразуем все описания в числовые последовательности, заменяя слова на числа по словарю.\n",
    "textSequences = tokenizer.texts_to_sequences(descriptions.tolist())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0fe7e5a3",
   "metadata": {},
   "source": [
    "# # создаем единый словарь (слово -> число) для преобразования\n",
    "# tokenizer = Tokenizer()\n",
    "# tokenizer.fit_on_texts(descriptions_encoded.tolist())\n",
    "\n",
    "# # Преобразуем все описания в числовые последовательности, заменяя слова на числа по словарю.\n",
    "# textSequences = tokenizer.texts_to_sequences(descriptions_encoded.tolist())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "77e551dc",
   "metadata": {},
   "source": [
    "X_train, y_train, X_test, y_test = load_data_from_arrays(textSequences, categories, train_test_split=0.8)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b264f0a5",
   "metadata": {},
   "source": [
    "# X_train, y_train, X_test, y_test = load_data_from_arrays(textSequences, categories_encoded, train_test_split=0.8)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd861e21",
   "metadata": {},
   "source": [
    "total_words = len(tokenizer.word_index)\n",
    "print('В словаре {} слов'.format(total_words))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5416be17",
   "metadata": {},
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "# количество наиболее часто используемых слов\n",
    "num_words = 5000"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65c5c4f5",
   "metadata": {},
   "source": [
    "print(u'Преобразуем описания заявок в векторы чисел...')\n",
    "tokenizer = Tokenizer(num_words=num_words)\n",
    "X_train = tokenizer.sequences_to_matrix(X_train, mode='binary')\n",
    "X_test = tokenizer.sequences_to_matrix(X_test, mode='binary')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3cc885f9",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "y_train = encoder.transform(y_train)\n",
    "y_test = encoder.transform(y_test)\n",
    "\n",
    "num_classes = np.max(y_train) + 1\n",
    "print('Количество категорий для классификации: {}'.format(num_classes))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "815e11e9",
   "metadata": {},
   "source": [
    "print('Размерность X_train:', X_train.shape)\n",
    "print('Размерность X_test:', X_test.shape)\n",
    "\n",
    "print(u'Преобразуем категории в матрицу двоичных чисел '\n",
    "      u'(для использования categorical_crossentropy)')\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de6e5a10",
   "metadata": {},
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "\n",
    "# количество эпох\\итераций для обучения\n",
    "epochs = 7\n",
    "\n",
    "print(u'Собираем модель...')\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(num_words,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de16c41c",
   "metadata": {},
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=32,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8fafb4de",
   "metadata": {},
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "\n",
    "with open(\"model_normal.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_normal.h5\")\n",
    "print(\"Saved model to disk\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1840c1c",
   "metadata": {},
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "# load json and create model\n",
    "json_file = open('model_normal.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model_normal.h5\")\n",
    "print(\"Loaded model from disk\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "842e7699",
   "metadata": {},
   "source": [
    "loaded_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e0533be",
   "metadata": {},
   "source": [
    "score = loaded_model.evaluate(X_test, y_test,\n",
    "                       batch_size=32, verbose=1)\n",
    "print()\n",
    "print(u'Оценка теста: {}'.format(score[0]))\n",
    "print(u'Оценка точности модели: {}'.format(score[1]))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97b761fa",
   "metadata": {},
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # График точности модели\n",
    "# plt.plot(history.history['accuracy'])\n",
    "# # plt.plot(history.history['val_acc'])\n",
    "# plt.title('model accuracy')\n",
    "# plt.ylabel('accuracy')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()\n",
    "# # График оценки loss\n",
    "# plt.plot(history.history['loss'])\n",
    "# # plt.plot(history.history['val_loss'])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('loss')\n",
    "# plt.xlabel('epoch')\n",
    "# plt.legend(['train', 'test'], loc='upper left')\n",
    "# plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dcc56562",
   "metadata": {},
   "source": [
    "# score = model.evaluate(X_test, y_test,\n",
    "#                        batch_size=32, verbose=1)\n",
    "# print()d\n",
    "# print(u'Оценка теста: {}'.format(score[0]))\n",
    "# print(u'Оценка точности модели: {}'.format(score[1]))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7820725e",
   "metadata": {},
   "source": [
    "descriptions_test = clean_test_df['title_clean']"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "06e4d147",
   "metadata": {},
   "source": [
    "# создаем единый словарь (слово -> число) для преобразования\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(descriptions_test.tolist())\n",
    "\n",
    "# Преобразуем все описания в числовые последовательности, заменяя слова на числа по словарю.\n",
    "textSequences = tokenizer.texts_to_sequences(descriptions_test.tolist())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0ce08867",
   "metadata": {},
   "source": [
    "# X_train_, y_train_, X_test_, y_test_ = load_data_from_arrays(textSequences, categories, train_test_split=.8)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "35b7b1d6",
   "metadata": {},
   "source": [
    "tokenizer = Tokenizer(num_words=num_words)\n",
    "X_test_ = tokenizer.sequences_to_matrix(textSequences, mode='binary')\n",
    "# X_train_ = tokenizer.sequences_to_matrix(X_train_, mode='binary')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "30e5fac8",
   "metadata": {},
   "source": [
    "y_NN_predict_1 = loaded_model.predict(X_test_)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "711aecb3",
   "metadata": {},
   "source": [
    "predicted_lablels = []\n",
    "for i in range(len(y_NN_predict_1)):\n",
    "    predicted_lablels.append(np.argmax(y_NN_predict_1[i]))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6ac1aad4",
   "metadata": {},
   "source": [
    "predicted_lablels = np.array(predicted_lablels)\n",
    "predicted_lablels = np.where(predicted_lablels == 0, False, True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b681401d",
   "metadata": {},
   "source": [
    "import collections\n",
    "c = collections.Counter()\n",
    "for label in predicted_lablels:\n",
    "    c[label] += 1"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "daddc5c3",
   "metadata": {},
   "source": [
    "clean_test_df[\"target\"] = predicted_lablels\n",
    "\n",
    "\n",
    "# Create file and read in stdout\n",
    "clean_test_df[[\"id\", \"target\"]].to_csv(\"ml_network.csv\", index=False)\n",
    "!cat ml_baseline.csv | head"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "049cd4c8",
   "metadata": {},
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# создаем единый словарь (слово -> число) для преобразования\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(descriptions.tolist())\n",
    "\n",
    "# Преобразуем все описания в числовые последовательности, заменяя слова на числа по словарю.\n",
    "textSequences = tokenizer.texts_to_sequences(descriptions.tolist())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6f0b77b8",
   "metadata": {},
   "source": [
    "X_train, y_train, X_test, y_test = load_data_from_arrays(textSequences, categories, train_test_split=0.8)\n",
    "# Максимальное количество слов в самом длинном описании заявки\n",
    "max_words = 0\n",
    "for desc in descriptions.tolist():\n",
    "    words = len(desc.split())\n",
    "    if words > max_words:\n",
    "        max_words = words\n",
    "print('Максимальное количество слов в самом длинном описании заявки: {} слов'.format(max_words))\n",
    "\n",
    "total_unique_words = len(tokenizer.word_counts)\n",
    "print('Всего уникальных слов в словаре: {}'.format(total_unique_words))\n",
    "\n",
    "maxSequenceLength = max_words"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eda0108d",
   "metadata": {},
   "source": [
    "vocab_size = round(total_unique_words/10)\n",
    "vocab_size"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0115c9b1",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "y_train = encoder.transform(y_train)\n",
    "y_test = encoder.transform(y_test)\n",
    "\n",
    "num_classes = np.max(y_train) + 1\n",
    "print('Количество категорий для классификации: {}'.format(num_classes))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "70266be8",
   "metadata": {},
   "source": [
    "print(u'Преобразуем описания заявок в векторы чисел...')\n",
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(descriptions.tolist())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bf0f52b1",
   "metadata": {},
   "source": [
    "X_train = tokenizer.sequences_to_matrix(X_train, mode='binary')\n",
    "X_test = tokenizer.sequences_to_matrix(X_test, mode='binary')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "04540085",
   "metadata": {},
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "X_train = pad_sequences(X_train, maxlen=maxSequenceLength)\n",
    "X_test = pad_sequences(X_test, maxlen=maxSequenceLength)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5b41c905",
   "metadata": {},
   "source": [
    "print('Размерность X_train:', X_train.shape)\n",
    "print('Размерность X_test:', X_test.shape)\n",
    "\n",
    "print(u'Преобразуем категории в матрицу двоичных чисел '\n",
    "      u'(для использования categorical_crossentropy)')\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7c57c3f2",
   "metadata": {},
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "\n",
    "# максимальное количество слов для анализа\n",
    "max_features = vocab_size\n",
    "\n",
    "print(u'Собираем модель...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, maxSequenceLength))\n",
    "model.add(LSTM(32, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(num_classes, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print (model.summary())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "51d5feeb",
   "metadata": {},
   "source": [
    "batch_size = 32\n",
    "epochs = 3\n",
    "\n",
    "print(u'Тренируем модель...')\n",
    "history = model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_data=(X_test, y_test))\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067ee9a2",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
