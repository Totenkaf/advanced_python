{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1370e53",
   "metadata": {},
   "source": [
    "# Домашнее задание №6.\n",
    "Основы машинного обучения. Г.Господинов  \n",
    "Группа ML-11. __Студент - Усцов Артем Алексеевич__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "076b72f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T22:39:18.957205Z",
     "start_time": "2022-05-10T22:39:18.941931Z"
    }
   },
   "source": [
    "# Для функционирования watermark - раскомментируйте строку ниже, либо установите библиотеку в консоли вручную\n",
    "# !pip install watermark\n",
    "%load_ext watermark"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f6dbb7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T22:39:19.979039Z",
     "start_time": "2022-05-10T22:39:19.121355Z"
    }
   },
   "source": [
    "%watermark -v -m -p numpy,scipy,matplotlib,pandas,sklearn,seaborn,tqdm -g"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28b3d010",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T22:39:20.130644Z",
     "start_time": "2022-05-10T22:39:19.993969Z"
    }
   },
   "source": [
    "!lscpu"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "e55f34a3",
   "metadata": {},
   "source": [
    "# Service function declaration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71935560",
   "metadata": {},
   "source": [
    "Uncomment if you are using Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e03a1434",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T22:39:20.154056Z",
     "start_time": "2022-05-10T22:39:20.151282Z"
    }
   },
   "source": [
    "# !pip install crowd-kit==1.0.0"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9939078d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T22:39:22.605203Z",
     "start_time": "2022-05-10T22:39:20.738682Z"
    }
   },
   "source": [
    "# Future Python versions compatibility\n",
    "from __future__ import division\n",
    "\n",
    "# Warnings Ignore\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# System libraries\n",
    "import os\n",
    "\n",
    "# Object libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Iterable libraries\n",
    "import hashlib\n",
    "from typing import Iterable, Tuple, List, Dict, Set\n",
    "from functools import lru_cache\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Graphical libraries\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import IPython.display as ipd\n",
    "\n",
    "# Word preprocessing\n",
    "import nltk\n",
    "from crowdkit.aggregation import ROVER\n",
    "\n",
    "# Status Bar\n",
    "from tqdm.auto import tqdm"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "cfa9a5e5",
   "metadata": {},
   "source": [
    "Uncomment if you are using Colab.  \n",
    "Audio files downloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbc7ab78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T22:39:22.622419Z",
     "start_time": "2022-05-10T22:39:22.619882Z"
    }
   },
   "source": [
    "# %%bash\n",
    "# mkdir -p ./data/audio\n",
    "# wget -q https://raw.githubusercontent.com/vadim0912/MLIntro2022_Spring/main/lecture08/data/noisy_text_aggregation_test.jsonl -P data/\n",
    "# wget -q https://raw.githubusercontent.com/vadim0912/MLIntro2022_Spring/main/lecture08/data/noisy_text_aggregation_train.jsonl -P data/\n",
    "# wget -q https://raw.githubusercontent.com/vadim0912/MLIntro2022_Spring/main/lecture08/data/noisy_text_aggregation_text_only.csv -P data/\n",
    "\n",
    "# declare -a files=(\n",
    "#   \"98962310d56cd7095d9893f5ed657f81.wav\"\n",
    "#   \"3c2875271fb918da312865549d444653.wav\"\n",
    "#   \"b4f6a8d9e2eba8085d25d4122b52d55a.wav\"\n",
    "#   \"ed0f6706f75681a7915fec15d336aca5.wav\"\n",
    "#   \"f3dba379c6280536aaa65a56c4358268.wav\"\n",
    "# )\n",
    "\n",
    "# for file in \"${files[@]}\"; do\n",
    "#    wget -q https://raw.githubusercontent.com/vadim0912/MLIntro2022_Spring/main/lecture08/data/audio/$file -P data/audio\n",
    "# done"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "e6e59615",
   "metadata": {},
   "source": [
    "# Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a39a5b",
   "metadata": {},
   "source": [
    "Дано:\n",
    "* три модели распознавания речи:\n",
    "    * `qnet`: [QuartzNet](https://arxiv.org/abs/1910.10261)\n",
    "    * `w2v`: [wav2vec XLS-R](https://arxiv.org/pdf/2111.09296.pdf)\n",
    "    * `w2v-tts`: тот же [wav2vec XLS-R](https://arxiv.org/pdf/2111.09296.pdf), но в дообучении использовались синтезированные (Text-To-Speech) данные\n",
    "   \n",
    "   \n",
    " * модели имеют разную структуру (QuartzNet — сверточная, wav2vec — Трансформер) и обучались на разных данных => из их предсказаний можно построить композицию, которая сильнее любого кандидата в отдельности\n",
    " * В тренировочном наборе данных ~ 60 тысяч примеров с референсной транскрипцией `text` (ground truth) и гипотезой каждой из моделей\n",
    " * В тестовом наборе данных ~ 20 тысяч примеров с гипотезами от каждой из моделей, но без референсной транскрипции (ее нужно предсказать)\n",
    " * Также доступен миллион референсных фраз из того же домена (запросы к ассистентам), но без предсказаний моделей\n",
    "\n",
    "Задача: улучшить распознавание речи с помощью:\n",
    " * агрегации транскрипций\n",
    " * выбора лучшей транскрипции\n",
    " * исправления ошибок в транскрипциях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dcd29f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T22:39:24.054356Z",
     "start_time": "2022-05-10T22:39:23.575285Z"
    }
   },
   "source": [
    "train_df = pd.read_json(\"data/noisy_text_aggregation_train.jsonl\", lines=True)\n",
    "train_df.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b1f1c82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T22:39:24.618479Z",
     "start_time": "2022-05-10T22:39:24.610653Z"
    }
   },
   "source": [
    "MODEL_LIST = [\"qnet\", \"w2v\", \"w2v_tts\"]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "269062f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T22:39:25.254499Z",
     "start_time": "2022-05-10T22:39:25.062322Z"
    }
   },
   "source": [
    "for i,row in train_df.head(5).iterrows():\n",
    "    \n",
    "    labels = [ row[model] == row[\"text\"] for model in MODEL_LIST ]\n",
    "\n",
    "    row_df = (\n",
    "        train_df\n",
    "        .drop({\"task\", \"text\"}, axis=1)\n",
    "        .iloc[[i]]\n",
    "        .style.set_properties(\n",
    "            **{'background-color': '#aaffaa'},\n",
    "            subset=[model for model, label in zip(MODEL_LIST, labels) if label]\n",
    "        )\n",
    "        .set_properties(\n",
    "            **{'background-color': '#ffaaaa'}, \n",
    "            subset=[model for model, label in zip(MODEL_LIST, labels) if not label]\n",
    "        )\n",
    "        .set_properties(width=\"150px\")\n",
    "    )\n",
    "    ipd.display(row_df)\n",
    "    ipd.display(ipd.Audio(f\"data/audio/{row['task']}.wav\"))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d79bce3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T22:39:25.595323Z",
     "start_time": "2022-05-10T22:39:25.515222Z"
    }
   },
   "source": [
    "test_df = pd.read_json(\"data/noisy_text_aggregation_test.jsonl\", lines=True)\n",
    "test_df.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd5978f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T22:39:27.837351Z",
     "start_time": "2022-05-10T22:39:26.384926Z"
    }
   },
   "source": [
    "# Референсные фразы из того же домена (запросы к ассистентам), но без предсказаний моделей\n",
    "text_data = pd.read_csv(\"data/noisy_text_aggregation_text_only.csv\", header=None)\n",
    "text_data.head(10)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "207730f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T22:39:27.984184Z",
     "start_time": "2022-05-10T22:39:27.895114Z"
    }
   },
   "source": [
    "# Получение хэша от хэша, по-уму, для разделения на train и test. Перемешивание выборки\n",
    "def hash_reminder(str_, base: int=10) -> int:\n",
    "    return int(hashlib.md5(str_.encode()).hexdigest(), 16) % base\n",
    "\n",
    "train_mask = train_df['task'].apply(lambda x: hash_reminder(x, 10) <= 7)\n",
    "\n",
    "val_df = train_df[~train_mask]\n",
    "train_df = train_df[train_mask]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db91ccc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T22:39:27.993832Z",
     "start_time": "2022-05-10T22:39:27.985514Z"
    }
   },
   "source": [
    "val_df.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b45b7a81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T22:39:28.120097Z",
     "start_time": "2022-05-10T22:39:28.112245Z"
    }
   },
   "source": [
    "train_df.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "0f37da24",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "В качестве меры близости фраз используется расстояние Левенштейна.  \n",
    "Вычисление производилось путем динамического программирования"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a8471d",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathrm{L}(a, b) = \n",
    "\\begin{cases}\n",
    "    |a|,& \\text{if } |b| = 0, ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ \\text{# second sequence is empty} \\\\\n",
    "    |b|,& \\text{if } |a| = 0, ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ \\text{# first sequence is empty} \\\\\n",
    "    \\mathrm{L}(\\mathrm{tail}(a), \\mathrm{tail}(b)),& \\text{if } \\mathrm{head}(a) = \\mathrm{head}(b), ~ ~ \\text{# first elements of two sequencies are equal} \\\\\n",
    "    1 + min \n",
    "    \\begin{cases} \n",
    "        \\mathrm{L}(\\mathrm{tail}(a), b), ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ \\text{# deletion from first sequence} \\\\ \n",
    "        \\mathrm{L}(a, \\mathrm{tail}(b)), ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ \\text{# insertion into first sequence} \\\\ \n",
    "        \\mathrm{L}(\\mathrm{tail}(a), \\mathrm{tail}(b)); ~ ~ ~ ~ \\text{# substitution}\n",
    "    \\end{cases} & \\text{, otherwise.}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14181a52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T22:39:29.844612Z",
     "start_time": "2022-05-10T22:39:29.837317Z"
    }
   },
   "source": [
    "def edit_distance(ref: Iterable, hyp: Iterable) -> int:\n",
    "    \"\"\"\n",
    "    dummy levenshtein implementation O(3^n)\n",
    "    \"\"\"\n",
    "    if not ref:\n",
    "        return len(hyp)\n",
    "    if not hyp:\n",
    "        return len(ref)\n",
    "    return min(\n",
    "        edit_distance(ref[1:], hyp[1:]) + (ref[0] != hyp[0]), # Correct / Insertion\n",
    "        edit_distance(ref, hyp[1:]) + 1, # Deletion\n",
    "        edit_distance(ref[1:], hyp) + 1 # Substitution\n",
    "    )\n",
    "\n",
    "\n",
    "def edit_distance(ref: Iterable, hyp: Iterable, plot: bool=False) -> int:\n",
    "    \"\"\"\n",
    "    dynamic programming levenshtein implementation O(n^2)\n",
    "    \"\"\"\n",
    "    \n",
    "    dist = np.zeros((len(hyp) + 1, len(ref) + 1), dtype=np.int32)\n",
    "    \n",
    "    dist[:, 0] = np.arange(len(hyp) + 1)\n",
    "    dist[0, :] = np.arange(len(ref) + 1)\n",
    "\n",
    "    for i, r in enumerate(hyp, start=1):\n",
    "        for j, h in enumerate(ref, start=1):\n",
    "            dist[i, j] = min(\n",
    "                dist[i - 1, j - 1] + (r != h),\n",
    "                dist[i, j - 1] + 1,\n",
    "                dist[i - 1, j] + 1\n",
    "            )\n",
    "    if plot:\n",
    "        sns.heatmap(\n",
    "            pd.DataFrame(\n",
    "                dist,\n",
    "                index=[' '] + list(hyp),\n",
    "                columns=[' '] + list(ref)\n",
    "            ),\n",
    "            annot=True,\n",
    "            cmap='coolwarm_r',\n",
    "            linewidth=2\n",
    "        )\n",
    "        plt.tick_params(\n",
    "            axis='both', which='major', labelsize=14, left=False, labelbottom=False, \n",
    "            bottom=False, top=False, labeltop=True\n",
    "        )\n",
    "        plt.yticks(rotation=0)\n",
    "            \n",
    "    return dist[-1, -1]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb222326",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T22:39:31.487682Z",
     "start_time": "2022-05-10T22:39:30.858243Z"
    }
   },
   "source": [
    "edit_distance('мама мыла раму', 'мама раму', plot=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "7dcc7c05",
   "metadata": {},
   "source": [
    "* Подходит ли само по себе расстояние Левенштейна в качестве метрики? Почему?\n",
    "* __Это абсолютная метрика. Требуется введение отношения правильно распознанных к общему количеству__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41e7e0cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T22:39:32.221955Z",
     "start_time": "2022-05-10T22:39:32.215828Z"
    }
   },
   "source": [
    "def error_rate(refs: Iterable[Iterable], hyps: Iterable[Iterable]) -> float:\n",
    "    \"\"\"\n",
    "    ignoring hypotheses with empty references\n",
    "    \"\"\"\n",
    "    \n",
    "    wrong_words, all_words = 0, 0\n",
    "    \n",
    "    for ref, hyp in tqdm(zip(refs, hyps), total=len(refs)):\n",
    "        if len(ref) > 0:\n",
    "            wrong_words += edit_distance(ref, hyp)\n",
    "            all_words += len(ref)\n",
    "        else:\n",
    "            continue\n",
    "    return wrong_words / all_words\n",
    "\n",
    "\n",
    "def wer(refs: Iterable[str], hyps: Iterable[str]) -> float:\n",
    "    \"\"\"\n",
    "    Word Error Rate\n",
    "    \"\"\"\n",
    "    return error_rate(\n",
    "        [ref.split() for ref in refs],\n",
    "        [hyp.split() for hyp in hyps]\n",
    "    )\n",
    "\n",
    "\n",
    "def cer(refs: Iterable[str], hyps: Iterable[str]) -> float:\n",
    "    \"\"\"\n",
    "    Character Error Rate\n",
    "    \"\"\"\n",
    "    return error_rate(refs, hyps)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "915402ea",
   "metadata": {},
   "source": [
    "* Может ли Error Rate быть > 1 ?\n",
    "* __Может, если референсных слов меньше вводимых__\n",
    "\n",
    "  \n",
    "* Что дольше считать WER или CER ?\n",
    "* __CER считается дольше__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f92973ab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T22:39:35.543484Z",
     "start_time": "2022-05-10T22:39:33.252256Z"
    }
   },
   "source": [
    "method2wer = {model: wer(val_df[model], val_df['text']) for model in MODEL_LIST}"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "87fb8c50",
   "metadata": {},
   "source": [
    "# Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5237d67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T22:39:35.638049Z",
     "start_time": "2022-05-10T22:39:35.626539Z"
    }
   },
   "source": [
    "def align(ref: Iterable, hyp: Iterable) -> List[Tuple[str, str, str]]:\n",
    "    \n",
    "    dist = np.zeros((len(hyp) + 1, len(ref) + 1), dtype=np.int32)\n",
    "    \n",
    "    dist[:, 0] = np.arange(len(hyp) + 1)\n",
    "    dist[0, :] = np.arange(len(ref) + 1)\n",
    "    \n",
    "    cache = [[None] * (len(ref) + 1) for _ in range(len(hyp) + 1)]\n",
    "    \n",
    "    for i, h in enumerate(hyp, start=1):\n",
    "        cache[i][0] = ('I', '%', h)\n",
    "    \n",
    "    for i, r in enumerate(ref, start=1):\n",
    "        cache[0][i] = ('D', r, '#')\n",
    "        \n",
    "    for i, h in enumerate(hyp, start=1):\n",
    "        for j, r in enumerate(ref, start=1):\n",
    "        \n",
    "            cases = []\n",
    "            \n",
    "            if r == h:\n",
    "                cases.append((\n",
    "                    dist[i - 1, j - 1],\n",
    "                    ('C', r, h)\n",
    "                ))\n",
    "            else:\n",
    "                cases.append((\n",
    "                    dist[i - 1, j - 1] + 1,\n",
    "                    ('S', r, h)\n",
    "                ))\n",
    "            cases.append((\n",
    "                dist[i, j - 1] + 1,\n",
    "                ('D', r, '#')\n",
    "            ))\n",
    "            cases.append((\n",
    "                dist[i - 1, j] + 1,\n",
    "                ('I', '%', h)\n",
    "            ))\n",
    "            \n",
    "            dist[i, j], cache[i][j] = min(cases, key=lambda x: x[0])\n",
    "            \n",
    "    alignment = []\n",
    "    i, j = len(hyp), len(ref)\n",
    "    \n",
    "    while i != 0 or j != 0:\n",
    "        action, r, h = cache[i][j]\n",
    "        alignment.append((action, r, h))\n",
    "        if action in {'C', 'S'}:\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "        elif action == 'I':\n",
    "            i -= 1\n",
    "        else:\n",
    "            j -= 1\n",
    "\n",
    "    return alignment[::-1]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0eadbbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T22:39:36.375328Z",
     "start_time": "2022-05-10T22:39:36.354224Z"
    }
   },
   "source": [
    "align('мышиное обозначение', 'машинное обучение')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95fac17e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T22:39:37.031364Z",
     "start_time": "2022-05-10T22:39:37.025691Z"
    }
   },
   "source": [
    "align('мама мыла раму с мылом'.split(), 'мама мыла с млом'.split())"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "b4ab7ef6",
   "metadata": {},
   "source": [
    "# Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4dffe94e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T22:39:38.058979Z",
     "start_time": "2022-05-10T22:39:38.056358Z"
    }
   },
   "source": [
    "from crowdkit.aggregation import ROVER"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "4cc14dff",
   "metadata": {},
   "source": [
    "**R**ecognizer **O**utput **V**oting **E**rror **R**eduction\n",
    "\n",
    "https://ieeexplore.ieee.org/document/659110\n",
    "\n",
    "https://arxiv.org/pdf/2107.01091.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b97ef617",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T22:39:39.485855Z",
     "start_time": "2022-05-10T22:39:39.478060Z"
    }
   },
   "source": [
    "val_df.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f2dab3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T22:39:40.470346Z",
     "start_time": "2022-05-10T22:39:40.465762Z"
    }
   },
   "source": [
    "def get_rover_df(df: pd.DataFrame, model_cols: List[str], tmp_col: str=\"__tmp\") -> pd.DataFrame:\n",
    "\n",
    "    rover_df = df.copy()\n",
    "    \n",
    "    if \"text\" in rover_df.columns:\n",
    "        rover_df.drop(\"text\", axis=1, inplace=True)\n",
    "    \n",
    "    rover_df[tmp_col] = rover_df.apply(lambda row: [(model, row[model]) for model in model_cols], axis=1)\n",
    "    \n",
    "    rover_df = rover_df.drop(model_cols, axis=1).explode(tmp_col)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"task\": rover_df[\"task\"],\n",
    "        \"performer\": rover_df[tmp_col].apply(lambda x: x[0]),\n",
    "        \"text\": rover_df[tmp_col].apply(lambda x: x[1])\n",
    "    })"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c39d8e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T22:39:41.373237Z",
     "start_time": "2022-05-10T22:39:41.156442Z"
    }
   },
   "source": [
    "val_rover_df = get_rover_df(val_df, model_cols=MODEL_LIST)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e2882ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T22:39:42.239300Z",
     "start_time": "2022-05-10T22:39:42.232272Z"
    }
   },
   "source": [
    "val_rover_df.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a9b0159c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T22:40:57.102120Z",
     "start_time": "2022-05-10T22:39:43.078886Z"
    }
   },
   "source": [
    "rover_result = (\n",
    "    ROVER(\n",
    "        tokenizer=lambda x: list(x),\n",
    "        detokenizer=lambda s: \"\".join(s),\n",
    "        silent=False\n",
    "    )\n",
    "    .fit_predict(val_rover_df)\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6bded76e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T22:40:57.800096Z",
     "start_time": "2022-05-10T22:40:57.781306Z"
    }
   },
   "source": [
    "rover_result = pd.merge(\n",
    "    val_df,\n",
    "    rover_result.reset_index(),\n",
    "    on='task'\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4f4ecfbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T22:40:58.462074Z",
     "start_time": "2022-05-10T22:40:58.437515Z"
    }
   },
   "source": [
    "rover_result.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05615c1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T22:40:59.723367Z",
     "start_time": "2022-05-10T22:40:59.064086Z"
    }
   },
   "source": [
    "method2wer['ROVER'] = wer(rover_result['agg_text'], rover_result['text'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8a301cb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T22:41:02.100609Z",
     "start_time": "2022-05-10T22:41:02.094414Z"
    }
   },
   "source": [
    "method2wer"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "31b48213",
   "metadata": {},
   "source": [
    "Попробуем модернизировать наш Rover, используя BPE, unigram, char токенизаторы из библиотеки sentencepiece.\n",
    "Ссылка - [здесь](https://github.com/google/sentencepiece).\n",
    "Вначале обучим наш токенизатор, к примеру, на Войне и Мире.\n",
    "Исходный текст идет с пропущенными строчками, уберем их, запишем в новый файл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f5697c82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T09:02:06.305206Z",
     "start_time": "2022-05-11T09:02:06.292508Z"
    }
   },
   "source": [
    "with open('War&Peace.txt', 'r', encoding=\"latin-1\") as inf, open('War&Peace_cleaned.txt', 'w', encoding=\"latin-1\") as out:\n",
    "    for line in inf:\n",
    "        if line.strip():\n",
    "            out.write(line)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "53884545",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T09:02:07.137496Z",
     "start_time": "2022-05-11T09:02:06.784129Z"
    },
    "scrolled": true
   },
   "source": [
    "import sentencepiece as spm\n",
    "spm.SentencePieceTrainer.train('--input=War&Peace_cleaned.txt --model_prefix=m_bpe --vocab_size=2000 --model_type=bpe')\n",
    "sp_model = spm.SentencePieceProcessor()\n",
    "sp_model.load('m_bpe.model')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6e979ad2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T09:02:23.395877Z",
     "start_time": "2022-05-11T09:02:23.391202Z"
    }
   },
   "source": [
    "sp_model.encode_as_pieces('Съешь еще,дорогой,этих мягких французских булок и выпей чаю!')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4a5abfca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T09:02:39.872355Z",
     "start_time": "2022-05-11T09:02:29.240532Z"
    }
   },
   "source": [
    "rover_result = (\n",
    "    ROVER(\n",
    "        tokenizer=lambda x: sp_model.encode_as_pieces(x),\n",
    "        detokenizer=lambda s: \"\".join(s).replace('▁', ' '),\n",
    "        silent=False\n",
    "    )\n",
    "    .fit_predict(val_rover_df)\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3300ec72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T09:02:40.456140Z",
     "start_time": "2022-05-11T09:02:40.426377Z"
    }
   },
   "source": [
    "rover_result = pd.merge(\n",
    "    val_df,\n",
    "    rover_result.reset_index(),\n",
    "    on='task'\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e6ae415e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T09:02:41.903977Z",
     "start_time": "2022-05-11T09:02:41.230064Z"
    }
   },
   "source": [
    "method2wer['ROVER_BPE'] = wer(rover_result['agg_text'], rover_result['text'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "25024071",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T09:02:42.943571Z",
     "start_time": "2022-05-11T09:02:42.939420Z"
    }
   },
   "source": [
    "# Итоговое качество\n",
    "method2wer"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "e08763c0",
   "metadata": {},
   "source": [
    "Забавно, ну хуже, чем с наивным токенизатором"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "87f7c479",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T09:03:57.343747Z",
     "start_time": "2022-05-11T09:03:57.166924Z"
    }
   },
   "source": [
    "# Используем другой тип токенизатора\n",
    "spm.SentencePieceTrainer.train('--input=War&Peace_cleaned.txt --model_prefix=m_char --model_type=char --vocab_size=400')\n",
    "sp_char = spm.SentencePieceProcessor()\n",
    "sp_char.load('m_char.model')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cfc6974e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T09:04:07.365314Z",
     "start_time": "2022-05-11T09:04:07.359188Z"
    }
   },
   "source": [
    "# Проверим разбиение\n",
    "sp_model.encode_as_pieces('Съешь еще,дорогой,этих мягких французских булок и выпей чаю!')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0912150a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T09:04:32.086067Z",
     "start_time": "2022-05-11T09:04:21.426686Z"
    }
   },
   "source": [
    "rover_result = (\n",
    "    ROVER(\n",
    "        tokenizer=lambda x: sp_char.encode_as_pieces(x),\n",
    "        detokenizer=lambda s: \"\".join(s).replace('▁', ' '),\n",
    "        silent=False\n",
    "    )\n",
    "    .fit_predict(val_rover_df)\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "cabaa0c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T09:04:32.781338Z",
     "start_time": "2022-05-11T09:04:32.748308Z"
    }
   },
   "source": [
    "rover_result = pd.merge(\n",
    "    val_df,\n",
    "    rover_result.reset_index(),\n",
    "    on='task'\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1659099c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T09:04:33.747702Z",
     "start_time": "2022-05-11T09:04:33.075606Z"
    }
   },
   "source": [
    "method2wer['ROVER_CHAR'] = wer(rover_result['agg_text'], rover_result['text'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "32faf312",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T09:04:39.202892Z",
     "start_time": "2022-05-11T09:04:38.536341Z"
    },
    "scrolled": true
   },
   "source": [
    "# А также униграммный токенизатор\n",
    "spm.SentencePieceTrainer.train('--input=War&Peace_cleaned.txt --model_prefix=m_unigram --vocab_size=3000 --model_type=unigram')\n",
    "sp_unigram = spm.SentencePieceProcessor()\n",
    "sp_unigram.load('m_unigram.model')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c26b7195",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T09:04:51.437875Z",
     "start_time": "2022-05-11T09:04:40.978572Z"
    }
   },
   "source": [
    "rover_result = (\n",
    "    ROVER(\n",
    "        tokenizer=lambda x: sp_unigram.encode_as_pieces(x),\n",
    "        detokenizer=lambda s: \"\".join(s).replace('▁', ' '),\n",
    "        silent=False\n",
    "    )\n",
    "    .fit_predict(val_rover_df)\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "dca737a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T09:04:51.649259Z",
     "start_time": "2022-05-11T09:04:51.624768Z"
    }
   },
   "source": [
    "rover_result = pd.merge(\n",
    "    val_df,\n",
    "    rover_result.reset_index(),\n",
    "    on='task'\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "de1528af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T09:04:51.888122Z",
     "start_time": "2022-05-11T09:04:51.874818Z"
    }
   },
   "source": [
    "rover_result.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d9ec6f3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T09:04:52.861647Z",
     "start_time": "2022-05-11T09:04:52.114070Z"
    }
   },
   "source": [
    "method2wer['ROVER_UNIGRAM'] = wer(rover_result['agg_text'], rover_result['text'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ffe87d9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T09:04:53.101505Z",
     "start_time": "2022-05-11T09:04:53.096967Z"
    }
   },
   "source": [
    "method2wer"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "f24b992a",
   "metadata": {},
   "source": [
    "Качество ухудшилось, по всей видимости, не донца понял работу этих токенизаторов  \n",
    "Будем считать попытку неудачной"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d92463e",
   "metadata": {},
   "source": [
    "* Как можно улучшить ROVER ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ef1ade",
   "metadata": {},
   "source": [
    "# Error Correction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6154cb",
   "metadata": {},
   "source": [
    "https://norvig.com/spell-correct.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e5126bf5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T22:42:37.873823Z",
     "start_time": "2022-05-10T22:42:37.644038Z"
    }
   },
   "source": [
    "def one_edit_words(word: str) -> Set[str]:\n",
    "    \"\"\"\n",
    "    return list of candidates with one correction\n",
    "    \"\"\"\n",
    "    letters = 'абвгдежзийклмнопрстуфхцчшщъыьэюя'\n",
    "    splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "    deletions = [left + right[1:] for left, right in splits if right]\n",
    "    substitutions = [left + c + right[1:] for left, right in splits if right for c in letters]\n",
    "    insertions = [left + c + right for left, right in splits for c in letters]\n",
    "    return set(deletions + substitutions + insertions)\n",
    "\n",
    "\n",
    "word_counts = Counter([word for utterance in train_df['text'].str.split() for word in utterance])\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def correct_word(word: str) -> str:\n",
    "    if word in word_counts:\n",
    "        return word\n",
    "    \n",
    "    candidates = one_edit_words(word)\n",
    "    \n",
    "    candidates = sorted([\n",
    "            (word, word_counts[word])\n",
    "            for word in candidates if word_counts[word] > 0\n",
    "        ],\n",
    "        key=lambda x: -x[1]\n",
    "    )\n",
    "    \n",
    "    if candidates:\n",
    "        return max(candidates, key=lambda x: x[1])[0]\n",
    "    return word"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5dd24076",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T22:42:40.928556Z",
     "start_time": "2022-05-10T22:42:38.048712Z"
    }
   },
   "source": [
    "w2v_corrected = val_df['w2v'].apply(\n",
    "    lambda x: \" \".join([correct_word(w) for w in x.split()])\n",
    ")\n",
    "\n",
    "method2wer['w2v_corrected'] = wer(val_df['text'], w2v_corrected)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "abee71ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T09:05:11.251508Z",
     "start_time": "2022-05-11T09:05:11.244522Z"
    }
   },
   "source": [
    "method2wer"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "1cb0274d",
   "metadata": {},
   "source": [
    "# Rescoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b788c95d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T22:42:41.267504Z",
     "start_time": "2022-05-10T22:42:41.252948Z"
    }
   },
   "source": [
    "class LaplaceLanguageModel:\n",
    "    \n",
    "    def __init__(\n",
    "            self, \n",
    "            tokenized_texts: Iterable[Iterable[str]], \n",
    "            n: int, \n",
    "            delta: float = 0.0, \n",
    "            BOS: str='<BOS>',\n",
    "            EOS: str='<EOS>'\n",
    "        ):\n",
    "        self.n = n\n",
    "        self.BOS = BOS\n",
    "        self.EOS = EOS\n",
    "        ngram_counts: Dict[Tuple[str, ...], Dict[str, int]] = self.build_ngram_counts(\n",
    "            tokenized_texts, n, BOS, EOS\n",
    "        )\n",
    "        \n",
    "        self.vocab = {\n",
    "            token for distribution in ngram_counts.values() for token in distribution\n",
    "        }\n",
    "        \n",
    "        self.probs = defaultdict(Counter)\n",
    "\n",
    "        for prefix, distribution in ngram_counts.items():\n",
    "            norm: float = sum(distribution.values()) + delta * len(self.vocab)\n",
    "            self.probs[prefix] = {\n",
    "                token: (count + delta) / norm for token, count in distribution.items()\n",
    "            }\n",
    "            \n",
    "    @staticmethod\n",
    "    def build_ngram_counts(\n",
    "        tokenized_texts: Iterable[Iterable[str]], \n",
    "        n: int,\n",
    "        BOS: str,\n",
    "        EOS: str\n",
    "    ) -> Dict[Tuple[str, ...], Dict[str, int]]:\n",
    "        \n",
    "        counts = defaultdict(Counter)\n",
    "\n",
    "        for text in tokenized_texts:\n",
    "\n",
    "            ngrams = nltk.ngrams(\n",
    "                text, n=n, pad_left=True, pad_right=True, left_pad_symbol=BOS, right_pad_symbol=EOS\n",
    "            )\n",
    "\n",
    "            for ngram in ngrams:\n",
    "                prev, token = ngram[:-1], ngram[-1]\n",
    "                counts[prev][token] += 1\n",
    "\n",
    "        return counts\n",
    "    \n",
    "    \n",
    "    def __get_observed_token_distribution(self, prefix: List[str]) -> Dict[str, float]:\n",
    "        prefix = prefix[max(0, len(prefix) - self.n + 1):]\n",
    "        prefix = [self.BOS] * (self.n - 1 - len(prefix)) + prefix\n",
    "        return self.probs[tuple(prefix)]\n",
    "    \n",
    "    \n",
    "    def get_token_distribution(self, prefix: List[str]) -> Dict[str, float]:\n",
    "        \n",
    "        distribution: Dict[str, float] = self.__get_observed_token_distribution(prefix)\n",
    "        \n",
    "        missing_prob_total: float = 1.0 - sum(distribution.values())\n",
    "        \n",
    "        missing_prob = missing_prob_total / max(1, len(self.vocab) - len(distribution))\n",
    "        \n",
    "        return {token: distribution.get(token, missing_prob) for token in self.vocab}\n",
    "    \n",
    "    \n",
    "    def get_next_token_prob(self, prefix: List[str], next_token: str):\n",
    "        \n",
    "        distribution: Dict[str, float] = self.__get_observed_token_distribution(prefix)\n",
    "        \n",
    "        if next_token in distribution:\n",
    "            return distribution[next_token]\n",
    "        \n",
    "        else:\n",
    "            missing_prob_total = 1.0 - sum(distribution.values())\n",
    "            return max(0, missing_prob_total) / max(1, len(self.vocab) - len(distribution))\n",
    "    \n",
    "    \n",
    "    def score_sequence(self, tokens: List[str], min_logprob: float = np.log(10 ** -50.)) -> float:\n",
    "        prefix = [self.BOS] * (self.n - 1)\n",
    "        padded_tokens = tokens + [self.EOS]\n",
    "        logprobs_sum = 0.0\n",
    "        for token in padded_tokens:\n",
    "            logprob = np.log(self.get_next_token_prob(prefix, token))\n",
    "            prefix = prefix[1:] + [token]\n",
    "            logprobs_sum += max(logprob, min_logprob)\n",
    "        return logprobs_sum / len(tokens) if tokens else 0.0"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e1bd64ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T09:13:14.439417Z",
     "start_time": "2022-05-11T09:12:38.651932Z"
    }
   },
   "source": [
    "lm = LaplaceLanguageModel(\n",
    "    n=5,\n",
    "    tokenized_texts=text_data[0],\n",
    "    delta=1e-5\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "779cfe48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T09:13:14.653442Z",
     "start_time": "2022-05-11T09:13:14.649177Z"
    }
   },
   "source": [
    "for text in ('мама мыла раму', 'мамо мыла раму', 'машинное обучение', 'маинное обучение'):\n",
    "    score = lm.score_sequence(list(text))\n",
    "    print(f\"{text}\\t\\t{score:.2f}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c593b2be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T09:13:17.055545Z",
     "start_time": "2022-05-11T09:13:14.893332Z"
    }
   },
   "source": [
    "max_likelihood_utterances = val_df.apply(\n",
    "    lambda row: row[\n",
    "        np.array([\n",
    "            lm.score_sequence(tokens=list(row[model])) for model in MODEL_LIST\n",
    "        ]).argmax()\n",
    "    ], \n",
    "    axis=1\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "8dcfca99",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T09:13:18.079007Z",
     "start_time": "2022-05-11T09:13:17.278050Z"
    }
   },
   "source": [
    "method2wer['dummy_rescoring'] = wer(val_df['text'], max_likelihood_utterances)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "eb02a457",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T09:13:24.296481Z",
     "start_time": "2022-05-11T09:13:24.289615Z"
    }
   },
   "source": [
    "method2wer"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "f731f218",
   "metadata": {},
   "source": [
    "Попробуем перебрать по \"сетке\" параметры delta и n для сглаживания.\n",
    "Перебирается долго, ограничим n в пределах 7, а delta в 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "73eec374",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-10T23:09:03.956802Z",
     "start_time": "2022-05-10T22:43:16.730606Z"
    },
    "scrolled": true
   },
   "source": [
    "wers = []\n",
    "for n in range(1,7):\n",
    "    for delta in np.linspace(start=1e-6, stop=1e-2, num=10):\n",
    "        lm = LaplaceLanguageModel(n=n, tokenized_texts=text_data[0], delta=delta)\n",
    "        max_likelihood_utterances = val_df.apply(\n",
    "        lambda row: row[\n",
    "            np.array([\n",
    "                lm.score_sequence(tokens=list(row[model])) for model in MODEL_LIST\n",
    "            ]).argmax()\n",
    "        ], axis=1)\n",
    "        wer_score = wer(val_df['text'], max_likelihood_utterances)\n",
    "        print(f\"Iter n={n} with delta={delta} | Wer = {wer_score}\")\n",
    "        wers.append(wer_score)\n",
    "print(sorted(wers))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "9d74b1a0",
   "metadata": {},
   "source": [
    "Получаем лучшее решение при n = 5 и delta = 0,01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "678a9548",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T09:14:20.449497Z",
     "start_time": "2022-05-11T09:13:44.498090Z"
    }
   },
   "source": [
    "lm = LaplaceLanguageModel(\n",
    "    n=5,\n",
    "    tokenized_texts=text_data[0],\n",
    "    delta=1e-2\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5127695a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T09:14:22.698758Z",
     "start_time": "2022-05-11T09:14:20.653509Z"
    }
   },
   "source": [
    "max_likelihood_utterances = val_df.apply(\n",
    "    lambda row: row[\n",
    "        np.array([\n",
    "            lm.score_sequence(tokens=list(row[model])) for model in MODEL_LIST\n",
    "        ]).argmax()\n",
    "    ], \n",
    "    axis=1\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2b39d2c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T09:14:23.457031Z",
     "start_time": "2022-05-11T09:14:22.904756Z"
    }
   },
   "source": [
    "method2wer['rescoring_opt'] = wer(val_df['text'], max_likelihood_utterances)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "05137f2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T09:14:23.650719Z",
     "start_time": "2022-05-11T09:14:23.646125Z"
    }
   },
   "source": [
    "method2wer"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "7cbeba7f",
   "metadata": {},
   "source": [
    "# Oracle WER\n",
    "\n",
    "если представить, что мы идеально выбираем лучшую из трех гипотез (Оракул), каким будет Word Error Rate?\\\n",
    "таким образом оценим нижнюю границу Rescoring-системы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "cea40175",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T09:14:23.863982Z",
     "start_time": "2022-05-11T09:14:23.860441Z"
    }
   },
   "source": [
    "def get_best_transcription(ref: Iterable[str], hyps: Iterable[Iterable[str]]):\n",
    "    return hyps[\n",
    "        np.array([\n",
    "            edit_distance(ref, hyp) for hyp in hyps\n",
    "        ]).argmin()\n",
    "    ]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "baa6170d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T09:14:26.141277Z",
     "start_time": "2022-05-11T09:14:24.060802Z"
    }
   },
   "source": [
    "oracle_hyp = val_df.apply(\n",
    "    lambda row: \" \".join(\n",
    "        get_best_transcription(\n",
    "            ref=row['text'].split(),\n",
    "            hyps=[row[model].split() for model in MODEL_LIST]\n",
    "        )\n",
    "    ),\n",
    "    axis=1\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c1166a6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T09:14:27.003768Z",
     "start_time": "2022-05-11T09:14:26.343768Z"
    }
   },
   "source": [
    "method2wer['oracle_wer'] = wer(val_df['text'], oracle_hyp)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4d42bbdf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T09:14:27.202602Z",
     "start_time": "2022-05-11T09:14:27.198472Z"
    }
   },
   "source": [
    "method2wer"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "3501f9bf",
   "metadata": {},
   "source": [
    "Как вывод - с учетом \"оптимизации\" параметров мы не добились нижней оценки рескоринга при помощи оракула"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d9b785",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "40b68f6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T09:14:30.571950Z",
     "start_time": "2022-05-11T09:14:27.432314Z"
    }
   },
   "source": [
    "max_likelihood_utterances = test_df.apply(\n",
    "    lambda row: row[\n",
    "        np.array([\n",
    "            lm.score_sequence(tokens=list(row[model])) for model in MODEL_LIST\n",
    "        ]).argmax()\n",
    "    ], \n",
    "    axis=1\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "c4fed702",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T09:15:04.258758Z",
     "start_time": "2022-05-11T09:15:04.254408Z"
    }
   },
   "source": [
    "rescoring_result = pd.DataFrame(max_likelihood_utterances)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "06993abd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T09:21:02.629195Z",
     "start_time": "2022-05-11T09:21:02.617022Z"
    }
   },
   "source": [
    "rescoring_result['task'] = test_df['task']\n",
    "rescoring_result.rename(columns = {0 : 'prediction'}, inplace = True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c51f362c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T09:21:03.533175Z",
     "start_time": "2022-05-11T09:21:03.521785Z"
    }
   },
   "source": [
    "rescoring_result"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "1b7f53db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-11T09:21:45.354395Z",
     "start_time": "2022-05-11T09:21:45.307278Z"
    }
   },
   "source": [
    "username = \"Ustsov\"\n",
    "\n",
    "test_result.to_json(\n",
    "    f\"noisy_text_aggregation_test_prediction_{username}.jsonl\",\n",
    "    lines=True, orient=\"records\"\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "e462af93",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "* провести эксперименты с разными подходами\n",
    "* аккуратно валидироваться и тестироваться\n",
    "* сформировать файл с предсказаниями\n",
    "* <font color='red'>в переменную `username` указать фамилию <font> \n",
    "* прикрепить на портале jupyter-notebook / .py-file / colab-link и файл с предсказаниями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a47d7a1",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
