{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание №2\n",
    "Основы машинного обучения. А.Мамаев  \n",
    "Группа ML-11. __Студент - Усцов Артем Алексеевич__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:33:40.909954Z",
     "start_time": "2022-03-27T12:33:40.898614Z"
    }
   },
   "source": [
    "# Для функционирования watermark - раскомментируйте строку ниже, либо установите библиотеку в консоли вручную\n",
    "# !pip install watermark\n",
    "%load_ext watermark"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:33:42.311818Z",
     "start_time": "2022-03-27T12:33:41.557353Z"
    }
   },
   "source": [
    "%watermark -v -m -p numpy,scipy,matplotlib,seaborn,sklearn -g"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве домашнего задания вам предлагается поработать над предсказанием погоды. Файл с данными вы найдете в соответствующей директории. Вам будет доступен датасет weather.csv, ПЕРВЫЕ 75% (shuffle = False) которого нужно взять для обучения, последние 25% - для тестирования.\n",
    "\n",
    "__Требуется построить 4 модели которые будут предсказывать целевую переменную <b>RainTomorrow</b> с помощью:__\n",
    "\n",
    "   1. логистической регрессии [sklearn.linear_model.LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression)\n",
    "   \n",
    "   2. метода ближайших соседей [sklearn.neighbors](https://scikit-learn.org/stable/modules/neighbors.html)\n",
    " \n",
    "   3. Байесовского классификатора [sklearn.naive_bayes](https://scikit-learn.org/stable/modules/naive_bayes.html)\n",
    "   \n",
    "   4. логистической регрессии реализованной самостоятельно\n",
    "\n",
    "Затем следует сравнить результаты моделей (по качеству и времени выполнения) и сделать вывод о том, какая модель и с какими параметрами даёт лучшие результаты.  \n",
    "__(%timeit)__\n",
    "\n",
    "Не забывайте о том, что работа с признаками играет очень большую роль в построении хорошей модели.\n",
    "\n",
    "__Краткое описание данных:__\n",
    "\n",
    "    - Date - дата наблюдений, в формате год-месяц-день\n",
    "    - Location - название локации, в которой расположена метеорологическая станция\n",
    "    - MinTemp - минимальная температура в градусах Цельсия\n",
    "    - MaxTemp - максимальная температура в градусах Цельсия\n",
    "    - Rainfall - количество осадков, зафиксированных за день в мм\n",
    "    - Evaporation - так называемое \"pan evaporation\" класса А (мм) за 24 часа до 9:00\n",
    "    - Sunshine - число солнечных часов за день\n",
    "    - WindGustDir - направление самого сильного порыва ветра за последние 24 часа\n",
    "    - WindGustSpeed - скорость (км/ч) самого сильного порыва ветра за последние 24 часа\n",
    "    - WindDir9am - направление ветра (км/ч) в 9:00\n",
    "    - WindDir3pm - направление ветра (км/ч)в 15:00\n",
    "    - WindSpeed9am - скорость ветра в (км/ч) в 9:00\n",
    "    - WindSpeed3pm - скорость ветра в (км/ч) в 15:00\n",
    "    - Humidity9am - относительная влажность воздуха (%) в 9:00\n",
    "    - Humidity3pm - относительная влажность воздуха (%) в 15:00\n",
    "    - Cloud9am - класс облачности (от 0 до 9, где 0 - нет облаков, 9 - очень облачно) в 9:00\n",
    "    - Cloud3pm - класс облачности (от 0 до 9, где 0 - нет облаков, 9 - очень облачно) в 15:00\n",
    "    - Temp9am - температура воздуха в 9:00 в градусах Цельсия\n",
    "    - Temp3pm - температура воздуха в 15:00 в градусах Цельсия\n",
    "    - Pressure9am - атмосферное давление в Па в 9:00\n",
    "    - Pressure3pm - атмосферное давление в Па в 15:00\n",
    "    - RainToday - метка, показывающая будет ли дождь сегодня (Yes or No) \n",
    "    \n",
    "Целевая переменная - RainTommorow - состоит из меток Yes or Nо - будет дождь завтра или нет.\n",
    "Задача сводится к задаче бинарной классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executive Summary\n",
    "В ходе выполненной домашней работы были обучены 4 модели классификатора.  \n",
    "Краткая выдержка по результатам:  \n",
    " - 1) Подготовлен входящий датасет (пропуски заменены средним значением)\n",
    " - 2) Данные разделены на две группы (вещественные и категориальные+бинарные). Для категориальных данных прозведен one-hot encoding  \n",
    " - 3) Данные отмасштабированы (стандартизация). Полиномиализация данных не применялась в связи с трудностью интерпретации дальнейших результатов\n",
    " - 4) Стратификация не выполнялась в связи с наличием данных временной компаненты\n",
    " - 6) Осуществлена попытка сбалансировать признаки в датасете (найден большой перекос в сторону 0)\n",
    " - 5) Осуществлен синтез признаков при помощи kNN. Получена метрика качества для логит. регресии на новых признаках\n",
    " - 6) Реализована собственная модель логистической регрессии (логлосс оптимизирован при помощи SGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Показатели моделей:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CASE | 1\n",
    "\n",
    "- Примененная модель: логистическая регрессия\n",
    "- Кросс-валидация: на cv = 5 фолдов\n",
    "- Сплит данных: 25% тест, 75% трейн\n",
    "- Масштабирование признаков: стандартизация\n",
    "- Балансировка классов: применялась\n",
    "- Стратификация: не применялась\n",
    "- Полиномиализация: применялась, была отвергнута\n",
    "- Регуляризация: L1-lasso\n",
    "\n",
    "- Метрика качества: ROC-AUC, лучшее значение - 0.878\n",
    "- Метрика качества: F1-мера, лучшее значение - 0.637   \n",
    "    \n",
    "   \n",
    "## CASE | 2\n",
    "- Примененная модель: k-ближайших соседей\n",
    "- Количество соседей: k = 10 соседей\n",
    "- Кросс-валидация: на cv = 5 фолдов\n",
    "- Сплит данных: 25% тест, 75% трейн\n",
    "- Масштабирование признаков: стандартизация\n",
    "- Балансировка классов: применялась\n",
    "- Стратификация: не применялась\n",
    "- Стратегия изменения весов: не применялась\n",
    "\n",
    "- Метрика качества: ROC-AUC, лучшее значение - 0.878\n",
    "- Метрика качества: F1-мера, лучшее значение - 0.643\n",
    "    \n",
    "     \n",
    "## CASE | 3\n",
    "- Примененная модель: бернуллевский наивный баейсовский классификатор\n",
    "- Кросс-валидация: на cv = 5 фолдов\n",
    "- Сплит данных: 25% тест, 75% трейн\n",
    "- Масштабирование признаков: стандартизация\n",
    "- Балансировка классов: не применялась\n",
    "- Стратификация: не применялась\n",
    "\n",
    "- Метрика качества: ROC-AUC, лучшее значение - 0.764\n",
    "- Метрика качества: F1-мера, лучшее значение - 0.596  \n",
    "    \n",
    "    \n",
    "## CASE | 4 \n",
    "- Примененная модель: логистическая регрессия своими руками\n",
    "- Кросс-валидация: на cv = 5 фолдов\n",
    "- Сплит данных: 25% тест, 75% трейн\n",
    "- Масштабирование признаков: стандартизация\n",
    "- Балансировка классов: не применялась\n",
    "- Стратификация: не применялась\n",
    "- Полиномиализация: применялась, была отвергнута\n",
    "- Регуляризация: L1-lasso\n",
    "\n",
    "- Метрика качества: ROC-AUC, лучшее значение - 0.780\n",
    "- Метрика качества: F1-мера, лучшее значение - 0.617"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как итог лучшая модель классификации на данном датасете по качеству - логистическая регрессия с регуляризацией"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Service function declaration\n",
    "\n",
    "Connecting all the libraries necessary for work and declaring functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:33:49.258872Z",
     "start_time": "2022-03-27T12:33:49.126025Z"
    },
    "scrolled": true
   },
   "source": [
    "# For compatibility with future Python versions\n",
    "from __future__ import division\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# System libraries\n",
    "import os\n",
    "\n",
    "# Object libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "# Ml libraries\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier\n",
    "\n",
    "\n",
    "from sklearn import naive_bayes, model_selection\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "import sklearn.neighbors\n",
    "import sklearn.naive_bayes\n",
    "\n",
    "\n",
    "# Visualize libraries\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:33:49.937936Z",
     "start_time": "2022-03-27T12:33:49.934569Z"
    }
   },
   "source": [
    "def model_comparator(model_new, model_old):\n",
    "    print(f\"Результат новой модели: {np.round(model_old, 3)}\")\n",
    "    print(f\"Результат предыдущей модели: {np.round(model_new, 3)}\")\n",
    "    print(f\"Разница абсолютная: {np.round(model_new - model_old, 3)}\")\n",
    "    print(f\"Прирост составил: {np.round((model_new - model_old) * 100 / model_new, 2)} %\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:33:50.786740Z",
     "start_time": "2022-03-27T12:33:50.782522Z"
    }
   },
   "source": [
    "# Missing values detection function\n",
    "def missing_values_table(df):\n",
    "    mis_val = df.isnull().sum()\n",
    "    mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "    mis_val_table_ren_columns = mis_val_table.rename(\n",
    "    columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "    mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "        mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "    '% of Total Values', ascending=False).round(1)\n",
    "\n",
    "    print (\"Your selected dataframe has \" + str(df.shape[1]) + \" features.\\n\"      \n",
    "        \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "            \" features that have missing values.\")\n",
    "\n",
    "    return mis_val_table_ren_columns"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:33:51.614307Z",
     "start_time": "2022-03-27T12:33:51.610275Z"
    }
   },
   "source": [
    "# To plot an error graph and draw its confidence interval\n",
    "def plot_scores(optimizer):\n",
    "    scores=[]\n",
    "    for i in range(len(optimizer.cv_results_['params'])):\n",
    "        scores.append([optimizer.cv_results_['params'][i]['C'], \n",
    "                optimizer.cv_results_['mean_test_score'][i],\n",
    "                optimizer.cv_results_['std_test_score'][i]])\n",
    "    scores = np.array(scores)\n",
    "    plt.semilogx(scores[:,0], scores[:,1])\n",
    "    plt.fill_between(scores[:,0], scores[:,1]-scores[:,2], \n",
    "                                  scores[:,1]+scores[:,2], alpha=0.3)\n",
    "    plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing\n",
    "Checking input data for integrity. Definition of the target variable. Preparing data for cleaning, replacement or modification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:33:53.962926Z",
     "start_time": "2022-03-27T12:33:53.959900Z"
    }
   },
   "source": [
    "# Checking working directory\n",
    "os.chdir(os.getcwd())\n",
    "print(os.getcwd())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:36:45.865095Z",
     "start_time": "2022-03-27T13:36:45.501020Z"
    }
   },
   "source": [
    "# Main dataframe\n",
    "X = pd.read_csv('data/weather.csv')\n",
    "X.head(10)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:36:46.195260Z",
     "start_time": "2022-03-27T13:36:46.144769Z"
    }
   },
   "source": [
    "X.info()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:36:46.306887Z",
     "start_time": "2022-03-27T13:36:46.196722Z"
    }
   },
   "source": [
    "# Feature matrix\n",
    "X.describe()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:36:46.373201Z",
     "start_time": "2022-03-27T13:36:46.368191Z"
    }
   },
   "source": [
    "X.columns"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очевидно, что столбец \"Unnamed: 0\" - индексация данных в таблице. Уберем его за ненадобностью, так как в pandas DataFrame уже встроена индексация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:36:47.717009Z",
     "start_time": "2022-03-27T13:36:47.710223Z"
    }
   },
   "source": [
    "pd.unique(X['Unnamed: 0'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:36:47.816933Z",
     "start_time": "2022-03-27T13:36:47.813758Z"
    }
   },
   "source": [
    "del X['Unnamed: 0']"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:36:49.555927Z",
     "start_time": "2022-03-27T13:36:49.510419Z"
    }
   },
   "source": [
    "# Predictor vector\n",
    "y = X.RainTomorrow.replace({'No':0, 'Yes': 1})\n",
    "y.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:36:50.743413Z",
     "start_time": "2022-03-27T13:36:50.738146Z"
    }
   },
   "source": [
    "# Удалим целевую переменную из основного датафрейма\n",
    "del X['RainTomorrow']"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:36:50.940553Z",
     "start_time": "2022-03-27T13:36:50.917762Z"
    }
   },
   "source": [
    "# Итоговый датафрейм с признаками\n",
    "X.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:36:52.686243Z",
     "start_time": "2022-03-27T13:36:52.609276Z"
    }
   },
   "source": [
    "missing_values_table(X)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, в подавляющем большинстве признаков исходного датафрейма существуют пропуски, которые требуют отдельной обработки.  \n",
    "Также отметим, что стратегия удаления пустых значений для Sunshine, Evaporation, Cloud3pm и Cloud9am приведет к сильному ухудшению прогнозной способности, в связи с тем, что придется удалить почти половину данных датафрейма, помимо этого наши данные упорядочены во времени и удаление какого-либо объекта приведет к нарушению непрерывного временного ряда"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:36:54.313421Z",
     "start_time": "2022-03-27T13:36:54.309072Z"
    }
   },
   "source": [
    "# Итоговый вектор ответов\n",
    "y.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:34:10.496733Z",
     "start_time": "2022-03-27T12:34:10.493066Z"
    }
   },
   "source": [
    "y.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering\n",
    "Изучим природу входных признаков и попробуем их классифицировать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По описанию данных и анализу датасета можно тематически разделить переменные на категориальные, вещественные и категориальные с двумя категориями (бинарные)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:34:14.313440Z",
     "start_time": "2022-03-27T12:34:14.306028Z"
    }
   },
   "source": [
    "date_cols = [\"Date\"]\n",
    "X[date_cols].head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:34:15.152838Z",
     "start_time": "2022-03-27T12:34:15.141760Z"
    }
   },
   "source": [
    "X[date_cols].isnull().any()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:34:16.149997Z",
     "start_time": "2022-03-27T12:34:16.144633Z"
    }
   },
   "source": [
    "X[date_cols].shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно временной ряд непрерывен в своих значениях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:34:28.072687Z",
     "start_time": "2022-03-27T12:34:17.655197Z"
    }
   },
   "source": [
    "# Временная составляющая. Переведем даты в формат datetime64\n",
    "X[\"Date\"] = X[\"Date\"].apply(pd.to_datetime)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:34:28.197904Z",
     "start_time": "2022-03-27T12:34:28.177647Z"
    }
   },
   "source": [
    "categorical_cols = [\"Location\", \"WindGustDir\", \"WindDir9am\", \"WindDir3pm\", \"Cloud9am\", \"Cloud3pm\"]\n",
    "X[categorical_cols].head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:34:28.321281Z",
     "start_time": "2022-03-27T12:34:28.307672Z"
    }
   },
   "source": [
    "X[[\"Location\"]].isnull().any()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:34:28.442626Z",
     "start_time": "2022-03-27T12:34:28.436384Z"
    }
   },
   "source": [
    "X[[\"Location\"]].shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также имеется полная информация о населенных пунктах, в которых производились измерения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:34:30.353991Z",
     "start_time": "2022-03-27T12:34:30.345927Z"
    }
   },
   "source": [
    "binary_cols = [\"RainToday\"]\n",
    "X[binary_cols].head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:34:30.479823Z",
     "start_time": "2022-03-27T12:34:30.447995Z"
    }
   },
   "source": [
    "numberical_cols = list(set(X.columns.values.tolist()) - set(categorical_cols) - set(binary_cols) - set(date_cols))\n",
    "X[numberical_cols].head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:34:32.585626Z",
     "start_time": "2022-03-27T12:34:32.581951Z"
    }
   },
   "source": [
    "numberical_cols"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:34:34.588061Z",
     "start_time": "2022-03-27T12:34:34.585000Z"
    }
   },
   "source": [
    "# Провера на корректную декомпозицию по признакам\n",
    "assert(len(list(X.columns)) == len(categorical_cols) + len(binary_cols) + \n",
    "                               len(numberical_cols) + len(date_cols))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empty values replacement\n",
    "В связи с ограничением на удаление данных из датафрейма примем во внимание другие стратегии.\n",
    "\n",
    "Для вещественных признаков:\n",
    "- заменить на 0 (данный признак давать вклад в предсказание для данного объекта не будет)\n",
    "- заменить на среднее (каждый пропущенный признак будет давать такой же вклад, как и среднее значение признака на датасете)\n",
    "\n",
    "Для категориальных:\n",
    "- интерпретировать пропущенное значение, как ещё одну категорию (данный способ является самым естественным, так как в случае категорий у нас есть уникальная возможность не потерять информацию о наличии пропущенных значений; в случае вещественных признаков данная информация неизбежно теряется)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical data empty values replacement\n",
    "Заполним пропущенные вещественные значения в X нулями и средними по столбцам, назовем полученные датафреймы X_real_zeros и X_real_mean соответственно.\n",
    "\n",
    "__Примечание__  \n",
    "Признаки WindGustSpeed, WindSpeed9am, WindSpeed3pm, Humidity9am, Humidity3pm хоть и имеют тип вещественных в датафрейме, однако на самом деле они представляют собой десятичные числа, с точностью до нуля знаков после запятой. После вычисления средних значений при помощи функции, далее требуется округлить их до ближайшего целого числа; осуществлять округление будет по правилам математики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:34:38.251516Z",
     "start_time": "2022-03-27T12:34:38.247841Z"
    }
   },
   "source": [
    "decimal_cols = [\"WindGustSpeed\", \"WindSpeed9am\", \"WindSpeed3pm\", \"Humidity3pm\", \"Humidity9am\"]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:34:42.477661Z",
     "start_time": "2022-03-27T12:34:38.675546Z"
    }
   },
   "source": [
    "X_real_zeros = X[numberical_cols].fillna(0)\n",
    "X_real_mean = X[numberical_cols].fillna(X.mean(axis=0)).round(1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:34:42.613536Z",
     "start_time": "2022-03-27T12:34:42.597360Z"
    }
   },
   "source": [
    "X_real_zeros.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:34:42.640609Z",
     "start_time": "2022-03-27T12:34:42.614828Z"
    }
   },
   "source": [
    "X_real_mean[decimal_cols] = X_real_mean[decimal_cols].round()\n",
    "X_real_mean.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical data empty values replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:34:44.807830Z",
     "start_time": "2022-03-27T12:34:44.615972Z"
    }
   },
   "source": [
    "X_cat = X[categorical_cols].fillna('NA', axis=0).applymap(str)\n",
    "X_cat.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binary data empty values replacement\n",
    "Бинарную метку о том, был в конкретный день дождь или нет, в первом приближении заполним 0.  \n",
    "Предполагается, что это не сместит сильно прогноз в ту или иную сторону, так как пропусков по данной метке всего 1% от общих данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:34:49.483172Z",
     "start_time": "2022-03-27T12:34:49.423510Z"
    },
    "scrolled": true
   },
   "source": [
    "X[binary_cols] = X[binary_cols].replace({'No':0, 'Yes': 1})\n",
    "X_binary = X[binary_cols].fillna(0)\n",
    "\n",
    "assert X_binary.isnull().sum().values[0] == 0, 'Пропуски существуют'\n",
    "X_binary.head(20)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:34:50.570805Z",
     "start_time": "2022-03-27T12:34:50.557803Z"
    }
   },
   "source": [
    "# Объединим бинарные и категориальные признаки одним скопом\n",
    "X_cat_bin = pd.concat([X_cat, X_binary], axis=1, ignore_index=True)\n",
    "X_cat_bin.columns = categorical_cols + binary_cols\n",
    "X_cat_bin.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical data one-hote-encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для использования модели регрессии требуется преобразовать категориальные признаки в вещественные. Рассмотрим основной способ преоборазования категориальных признаков в вещественные: one-hot encoding. Его идея заключается в том, что мы преобразуем категориальный признак при помощи бинарного кода: каждой категории ставим в соответствие набор из нулей и единиц."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:35:06.577930Z",
     "start_time": "2022-03-27T12:34:56.857373Z"
    }
   },
   "source": [
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.feature_extraction import DictVectorizer as DV\n",
    "\n",
    "encoder = DV(sparse = False)\n",
    "X_cat_bin_oh_encoded = encoder.fit_transform(X_cat_bin.T.to_dict().values())"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CASE 1. Classification by LogisticRegression from scklearn\n",
    "## Data splitting\n",
    "Произведем разбиение данных на тестовую и обучающую выборку при помощи trans_test_split.  \n",
    "Долю данных примем согласно заданию - в 25% на тестовую и 75% на обучающую.\n",
    "Исключим перемешивание данных из-за того, что у нас присутствует временная компонента в данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:37:08.492010Z",
     "start_time": "2022-03-27T13:37:08.431679Z"
    }
   },
   "source": [
    "(X_train_real_zeros, \n",
    " X_test_real_zeros, \n",
    " y_train, y_test) = train_test_split(X_real_zeros, y, \n",
    "                                     test_size=0.25, \n",
    "                                     random_state=42, shuffle=False)\n",
    "(X_train_real_mean, \n",
    " X_test_real_mean) = train_test_split(X_real_mean, \n",
    "                                      test_size=0.25,\n",
    "                                      random_state=42, shuffle=False)\n",
    "(X_train_cat_oh,\n",
    " X_test_cat_oh) = train_test_split(X_cat_bin_oh_encoded, \n",
    "                                   test_size=0.25, \n",
    "                                   random_state=42, shuffle=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:35:10.239756Z",
     "start_time": "2022-03-27T12:35:10.223386Z"
    }
   },
   "source": [
    "X_train_real_zeros.head(3)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:35:11.027346Z",
     "start_time": "2022-03-27T12:35:11.000340Z"
    }
   },
   "source": [
    "X_test_real_zeros.head(3)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:35:11.358700Z",
     "start_time": "2022-03-27T12:35:11.342362Z"
    }
   },
   "source": [
    "X_train_real_mean.head(3)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:35:11.741138Z",
     "start_time": "2022-03-27T12:35:11.723674Z"
    }
   },
   "source": [
    "X_test_real_mean.head(3)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим два графика оценок точности +- их стандратного отклонения в зависимости от гиперпараметра."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:37:13.287522Z",
     "start_time": "2022-03-27T13:37:13.195962Z"
    }
   },
   "source": [
    "X_train_zeros = np.concatenate((X_train_real_zeros, X_train_cat_oh), axis = 1)\n",
    "X_train_mean = np.concatenate((X_train_real_mean, X_train_cat_oh), axis = 1)\n",
    "X_test_zeros = np.concatenate((X_test_real_zeros, X_test_cat_oh), axis = 1)\n",
    "X_test_mean = np.concatenate((X_test_real_mean, X_test_cat_oh), axis = 1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:37:45.483436Z",
     "start_time": "2022-03-27T12:35:18.078797Z"
    }
   },
   "source": [
    "param_grid = {'C': [0.01, 0.05, 0.1, 0.5, 1, 5, 10]}\n",
    "\n",
    "\n",
    "estimator = LogisticRegression()\n",
    "clf_zeros = GridSearchCV(estimator, param_grid, cv = 5)\n",
    "clf_zeros.fit(X_train_zeros, y_train)\n",
    "clf_zeros.best_estimator_\n",
    "\n",
    "plot_scores(clf_zeros)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:40:02.927909Z",
     "start_time": "2022-03-27T12:37:45.730228Z"
    }
   },
   "source": [
    "param_grid = {'C': [0.01, 0.05, 0.1, 0.5, 1, 5, 10]}\n",
    "\n",
    "estimator = LogisticRegression()\n",
    "clf_mean = GridSearchCV(estimator, param_grid, cv = 5)\n",
    "clf_mean.fit(X_train_mean, y_train)\n",
    "clf_mean.best_estimator_\n",
    "\n",
    "plot_scores(clf_mean)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:40:03.189934Z",
     "start_time": "2022-03-27T12:40:03.153361Z"
    }
   },
   "source": [
    "y_zeros = clf_zeros.predict_proba(X_test_zeros)[:, 1]\n",
    "roc_auc_zeros = roc_auc_score(y_test, y_zeros)\n",
    "roc_auc_zeros"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:40:03.481415Z",
     "start_time": "2022-03-27T12:40:03.465924Z"
    }
   },
   "source": [
    "f1_score(y_test, np.where(y_zeros <= 0.5, 0, 1))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:40:03.730608Z",
     "start_time": "2022-03-27T12:40:03.701180Z"
    }
   },
   "source": [
    "y_mean = clf_mean.predict_proba(X_test_mean)[:, 1]\n",
    "roc_auc_mean = roc_auc_score(y_test, y_mean)\n",
    "roc_auc_mean"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:40:04.013459Z",
     "start_time": "2022-03-27T12:40:03.997384Z"
    }
   },
   "source": [
    "f1_score(y_test, np.where(y_mean <= 0.5, 0, 1))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отметим, что оценка точности на усредненных значениях выше. Для дальйнейшего обучения будем  \n",
    "будем использовать заполнение пропущенных признаков средним значением.  \n",
    "Большую дисперсию возможно устранить увеличением cv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:44:06.108015Z",
     "start_time": "2022-03-27T12:44:05.872766Z"
    }
   },
   "source": [
    "fpr_mean, tpr_mean, _ = roc_curve(y_test, y_mean)\n",
    "fpr_zeros, tpr_zeros, _ = roc_curve(y_test, y_zeros)\n",
    "\n",
    "\n",
    "plt.plot(fpr_mean, tpr_mean, label=\"Mean case\")\n",
    "plt.plot(fpr_zeros, tpr_zeros, label=\"Zeros case\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title('ROC curve')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data scailing\n",
    "Проверим данные на различие в масштабах. При необходимости проведем стандартизацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:44:14.114664Z",
     "start_time": "2022-03-27T12:44:09.621750Z"
    }
   },
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "data_numeric = pd.DataFrame(X_train_real_mean, columns=numberical_cols)\n",
    "list_cols = ['Evaporation', 'Sunshine', 'Pressure9am', 'Pressure3pm']\n",
    "scatter_matrix(data_numeric[list_cols], alpha=0.5, figsize=(10, 10))\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стандартизация осуществляется посредством вычета из каждого признака среднего значения и нормировки на выборочное стандартное отклонение:\n",
    "\n",
    "$$ x^{scaled}_{id} = \\dfrac{x_{id} - \\mu_d}{\\sigma_d}, \\quad \\mu_d = \\frac{1}{N} \\sum_{i=1}^l x_{id}, \\quad \\sigma_d = \\sqrt{\\frac{1}{N-1} \\sum_{i=1}^l (x_{id} - \\mu_d)^2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно из графиков, разные признаки очень сильно отличаются друг от друга по модулю значений (обратите внимание на диапазоны значений осей x и y). В случае обычной регрессии это никак не влияет на качество обучаемой модели, т.к. у меньших по модулю признаков будут большие веса, но при использовании регуляризации, которая штрафует модель за большие веса, регрессия, как правило, начинает работать хуже.  \n",
    "Также между некоторыми признаками визуально присуствует достаточно сильная корелляция, что требует их отсеиваения, данные намекают на использование Lasso регуляризации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:37:23.366135Z",
     "start_time": "2022-03-27T13:37:23.327058Z"
    }
   },
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_real_scaled = scaler.fit_transform(X_train_real_mean)\n",
    "X_test_real_scaled = scaler.transform(X_test_real_mean)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим такие же графики для преобразованных данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:44:31.268070Z",
     "start_time": "2022-03-27T12:44:26.849863Z"
    }
   },
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "data_numeric = pd.DataFrame(X_train_real_scaled, columns=numberical_cols)\n",
    "list_cols = ['Evaporation', 'Sunshine', 'Pressure9am', 'Pressure3pm']\n",
    "scatter_matrix(data_numeric[list_cols], alpha=0.5, figsize=(10, 10))\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно из графиков, мы не поменяли свойства признакового пространства: гистограммы распределений значений признаков, как и их scatter-plots, выглядят так же, как и до нормировки, но при этом все значения теперь находятся примерно в одном диапазоне, тем самым повышая интерпретабельность результатов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, изменилось ли качество логистической регрессии после стандартизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:37:28.243857Z",
     "start_time": "2022-03-27T13:37:28.197630Z"
    }
   },
   "source": [
    "X_train_scaled = np.concatenate((X_train_real_scaled, X_train_cat_oh), axis = 1)\n",
    "X_test_scaled = np.concatenate((X_test_real_scaled, X_test_cat_oh), axis = 1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:46:14.118374Z",
     "start_time": "2022-03-27T12:44:38.817257Z"
    }
   },
   "source": [
    "estimator = LogisticRegression()\n",
    "clf_scaled = GridSearchCV(estimator, param_grid, cv = 5)\n",
    "clf_scaled.fit(X_train_scaled, y_train)\n",
    "clf_scaled.best_estimator_"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:46:14.815474Z",
     "start_time": "2022-03-27T12:46:14.502494Z"
    }
   },
   "source": [
    "plot_scores(clf_scaled)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:46:15.152258Z",
     "start_time": "2022-03-27T12:46:15.115407Z"
    }
   },
   "source": [
    "y_scaled = clf_scaled.predict_proba(X_test_scaled)[:, 1]\n",
    "roc_auc_scaled = roc_auc_score(y_test, y_scaled)\n",
    "roc_auc_scaled"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:46:15.178069Z",
     "start_time": "2022-03-27T12:46:15.153987Z"
    }
   },
   "source": [
    "f1_score(y_test, np.where(y_scaled <= 0.5, 0, 1))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:46:15.184319Z",
     "start_time": "2022-03-27T12:46:15.180027Z"
    }
   },
   "source": [
    "model_comparator(roc_auc_scaled, roc_auc_mean)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, результат действительно увеличился"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data aligning\n",
    "Проверим, сбалансированы ли классы, при необходимости выполним балансировку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:48:39.532668Z",
     "start_time": "2022-03-27T12:48:39.527206Z"
    }
   },
   "source": [
    "zeros_count = np.sum(y_train==0)\n",
    "ones_count = np.sum(y_train==1)\n",
    "\n",
    "print(f\"Количество меток с индексом 0: {zeros_count}\")\n",
    "print(f\"Количество меток с индексом 1: {ones_count}\")\n",
    "print(f\"Абсолютная разница: {ones_count - zeros_count}\")\n",
    "print(f\"Смещение в сторону {str(0) if zeros_count > ones_count else str(1)}: в {np.round(zeros_count / ones_count, 2)} раза\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имеем сильное смещение в сторону одной из меток. Требуется балансировка меток.  \n",
    "Стратегия: будем давать объектам миноритарного класса больший вес при обучении классификатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:50:20.347258Z",
     "start_time": "2022-03-27T12:48:47.393742Z"
    }
   },
   "source": [
    "estimator = LogisticRegression(class_weight = 'balanced')\n",
    "clf_balance = GridSearchCV(estimator, param_grid, cv = 5)\n",
    "clf_balance.fit(X_train_scaled, y_train)\n",
    "clf_balance.best_estimator_"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:50:21.081739Z",
     "start_time": "2022-03-27T12:50:20.712554Z"
    }
   },
   "source": [
    "plot_scores(clf_balance)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:50:21.425608Z",
     "start_time": "2022-03-27T12:50:21.381566Z"
    }
   },
   "source": [
    "y_balance = clf_balance.predict_proba(X_test_scaled)[:, 1]\n",
    "roc_auc_balance = roc_auc_score(y_test, y_balance)\n",
    "roc_auc_balance"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:50:21.454621Z",
     "start_time": "2022-03-27T12:50:21.427536Z"
    }
   },
   "source": [
    "f1_score(y_test, np.where(y_balance <= 0.5, 0, 1))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:50:22.054439Z",
     "start_time": "2022-03-27T12:50:22.051238Z"
    }
   },
   "source": [
    "model_comparator(roc_auc_balance, roc_auc_scaled)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Балансировка выборки путем взвешивания __не принесла особых результатов__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Так как мы работаем над выборкой, в которой нельзя имеет место временная компонента и нельзя перемешивать данные, то стратификация выборки нас не интересует по определению__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data polynaminising\n",
    "Произведем базовое преобразование - полинамиальное преобразование вещественных признаков модели при помощи полиномиальных признаков степени 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:53:11.552524Z",
     "start_time": "2022-03-27T12:53:11.110024Z"
    }
   },
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "transform = PolynomialFeatures(2)\n",
    "X_train_real_poly = transform.fit_transform(X_train_real_mean)\n",
    "X_test_real_poly = transform.transform(X_test_real_mean)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_real_poly_scaled = scaler.fit_transform(X_train_real_poly)\n",
    "X_test_real_poly_scaled = scaler.transform(X_test_real_poly)\n",
    "\n",
    "X_train_poly = np.concatenate([X_train_real_poly_scaled, X_train_cat_oh], axis = 1)\n",
    "X_test_poly = np.concatenate([X_test_real_poly_scaled, X_test_cat_oh], axis = 1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:55:42.064404Z",
     "start_time": "2022-03-27T12:53:11.554467Z"
    }
   },
   "source": [
    "estimator = LogisticRegression(fit_intercept = False)\n",
    "clf_poly = GridSearchCV(estimator, param_grid, cv = 5)\n",
    "clf_poly.fit(X_train_poly, y_train)\n",
    "clf_poly.best_estimator_"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:55:43.044875Z",
     "start_time": "2022-03-27T12:55:42.755749Z"
    }
   },
   "source": [
    "plot_scores(clf_poly)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:55:43.084791Z",
     "start_time": "2022-03-27T12:55:43.046337Z"
    }
   },
   "source": [
    "y_poly = clf_poly.predict_proba(X_test_poly)[:, 1]\n",
    "roc_auc_poly = roc_auc_score(y_test, y_poly)\n",
    "roc_auc_poly"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:55:43.113023Z",
     "start_time": "2022-03-27T12:55:43.086640Z"
    }
   },
   "source": [
    "f1_score(y_test, np.where(y_poly <= 0.5, 0, 1))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:55:44.006378Z",
     "start_time": "2022-03-27T12:55:44.003149Z"
    }
   },
   "source": [
    "model_comparator(roc_auc_poly, roc_auc_scaled)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили прирост метрики на полиномиальных признаках. Далее будем использовать данную модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Regularisation\n",
    "К логистической регрессии также можно применить L1-регуляризацию (Lasso), вместо регуляризации L2, которая будет приводить к отбору признаков. Применим L1-регуляцию к исходным признакам (применение отбора признаков к полиномиальным так же можно успешно применять, но в нём уже будет отсутствовать компонента интерпретации, т.к. смысловое значение оригинальных признаков известно, а полиномиальных - уже может быть достаточно нетривиально). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:59:00.548468Z",
     "start_time": "2022-03-27T12:55:51.483380Z"
    }
   },
   "source": [
    "estimator = LogisticRegression(penalty = 'l1', class_weight = 'balanced', solver='liblinear')\n",
    "clf_lasso = GridSearchCV(estimator, param_grid, cv = 5)\n",
    "clf_lasso.fit(X_train_scaled, y_train)\n",
    "clf_lasso.best_estimator_"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:59:01.490564Z",
     "start_time": "2022-03-27T12:59:00.865144Z"
    }
   },
   "source": [
    "plot_scores(clf_lasso)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:59:01.848223Z",
     "start_time": "2022-03-27T12:59:01.811229Z"
    }
   },
   "source": [
    "y_lasso = clf_lasso.predict_proba(X_test_scaled)[:, 1]\n",
    "roc_auc_lasso = roc_auc_score(y_test, y_lasso)\n",
    "roc_auc_lasso"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:59:01.883974Z",
     "start_time": "2022-03-27T12:59:01.852690Z"
    }
   },
   "source": [
    "f1_score(y_test, np.where(y_lasso <= 0.5, 0, 1))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:59:01.891329Z",
     "start_time": "2022-03-27T12:59:01.886468Z"
    }
   },
   "source": [
    "model_comparator(roc_auc_lasso, roc_auc_scaled)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model | LR from scikit-learn\n",
    "Замерим ее время работы и выведем все метрики классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Примененная модель: логистическая регрессия\n",
    "- Кросс-валидация: на k=5 фолдов\n",
    "- Сплит данных: 25% тест, 75% трейн\n",
    "- Масштабирование признаков: стандартизация\n",
    "- Балансировка классов: применялась\n",
    "- Стратификация: не применялась\n",
    "- Полиномиализация: применялась, была отвергнута\n",
    "- Регуляризация: L1-lasso\n",
    "\n",
    "- Метрика качества: ROC-AUC, лучшее значение - 0.878\n",
    "- Метрика качества: F1-мера, лучшее значение - 0.637"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T12:59:12.903532Z",
     "start_time": "2022-03-27T12:59:12.774637Z"
    }
   },
   "source": [
    "fpr_own, tpr_fpr_own, _ = roc_curve(y_test, y_lasso)\n",
    "plt.plot(fpr_mean, tpr_mean, label=\"Lasso case\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title('ROC curve')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CASE 2. Classification by KMeans from sklearn\n",
    "## Model description\n",
    "В данном блоке работа построена следующим образом:\n",
    "- 1) Построим алгоритм классификации c KNeighborsClassifier (algorithm=auto)\n",
    "- 2) Оценим качество модели метрикой ROC-AUC\n",
    "- 3) Произведем синтез признаков, а затем передадим их нашей логистической модели и посмотрим на качество"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T14:07:57.963932Z",
     "start_time": "2022-03-27T14:07:57.959038Z"
    }
   },
   "source": [
    "# Существующие доступные параметры для перебора по сетке\n",
    "estimator.get_params().keys()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T15:31:05.429281Z",
     "start_time": "2022-03-27T15:31:05.425952Z"
    }
   },
   "source": [
    "param_grid = {'n_neighbors': [5, 10, 15, 25, 50]}"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T15:48:35.992367Z",
     "start_time": "2022-03-27T15:31:07.446360Z"
    }
   },
   "source": [
    "estimator = sklearn.neighbors.KNeighborsClassifier()\n",
    "clf_kNeighbors = GridSearchCV(estimator, param_grid, cv = 5)\n",
    "clf_kNeighbors.fit(X_train_scaled, y_train)\n",
    "clf_kNeighbors.best_estimator_"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T15:50:27.164215Z",
     "start_time": "2022-03-27T15:48:36.400556Z"
    }
   },
   "source": [
    "y_kNeighbors = clf_kNeighbors.predict_proba(X_test_scaled)[:, 1]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T15:50:27.624468Z",
     "start_time": "2022-03-27T15:50:27.608586Z"
    }
   },
   "source": [
    "roc_auc_kNeighbors = roc_auc_score(y_test, y_kNeighbors)\n",
    "roc_auc_kNeighbors"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T15:50:28.082011Z",
     "start_time": "2022-03-27T15:50:28.063415Z"
    }
   },
   "source": [
    "f1_score(y_test, np.where(y_kNeighbors <= 0.5, 0, 1))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, модель уступает по качеству модели логистической регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T15:51:17.208177Z",
     "start_time": "2022-03-27T15:51:17.204107Z"
    }
   },
   "source": [
    "model_comparator(roc_auc_kNeighbors, roc_auc_scaled)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature generation\n",
    "Теперь применим метод k-ближайших соседей для генерации новых признаков. Добавим их к существующему датасету и затем вновь обучим на новом датасете логистическую регрессию из CASE 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T14:45:07.274928Z",
     "start_time": "2022-03-27T14:45:07.262677Z"
    }
   },
   "source": [
    "# Взято из Семинара 2.\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "class NearestNeighborsFeats(BaseEstimator, ClassifierMixin):\n",
    "    ''' \n",
    "        Этот класс реализует создание KNN признаков.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, k_list, metric, n_jobs = 4,  n_classes=None, n_neighbors=None, eps=1e-10):\n",
    "        self.n_jobs = n_jobs\n",
    "        self.k_list = k_list\n",
    "        self.metric = metric\n",
    "        self.n_neighbors = n_neighbors or max(k_list)\n",
    "        self.eps = eps\n",
    "        self.n_classes_ = n_classes\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Создание объекта-классификатора  \n",
    "        self.NN = NearestNeighbors(n_neighbors=max(self.k_list),\n",
    "                                   metric=self.metric,\n",
    "                                   n_jobs=-1,\n",
    "                                   algorithm='brute' if self.metric == 'cosine' else 'auto')\n",
    "        self.NN.fit(X)\n",
    "\n",
    "        # Сохраниение меток \n",
    "        self.y_train = y.values\n",
    "\n",
    "        # Определение количества классов \n",
    "        self.n_classes = len(np.unique(y)) if self.n_classes_ is None else self.n_classes_\n",
    "\n",
    "    def predict(self, X):\n",
    "        '''\n",
    "            Создание признаков для каждого объекта в наборе данных\n",
    "        '''\n",
    "        result = []\n",
    "        for k in self.k_list:\n",
    "            \n",
    "            neighs_dist, neighs = self.NN.kneighbors(X)\n",
    "            neighs_dist, neighs = neighs_dist[:, :k], neighs[:, :k] \n",
    "\n",
    "            neighs_y = self.y_train[neighs]\n",
    "\n",
    "            # 1. Доля объектов каждого класса среди ближайших соседей\n",
    "            fraction = np.mean(neighs_y, axis = 1)\n",
    "\n",
    "            # 2. Минимальная дистанция до объектов каждого из классов\n",
    "\n",
    "            # где y=1  не трогаем значение дистанции, где y=0 прибалвяем к дистанции np.inf\n",
    "            ones = np.min(neighs_dist + np.where(neighs_y, 0, np.inf), axis =1)\n",
    "            zeros = np.min(neighs_dist + np.where(neighs_y, np.inf, 0), axis =1)\n",
    "\n",
    "            # 3. Средняя дистанция \n",
    "\n",
    "            mean_distance = np.median(neighs_dist, axis=1)\n",
    "\n",
    "            # 4. Минимальная дистанция до объектов каждого класса деленная на расстояние до среднего объекта\n",
    "\n",
    "            norm_ones = ones/(mean_distance + self.eps)\n",
    "\n",
    "            norm_zeros = zeros/(mean_distance + self.eps)\n",
    "\n",
    "            # 6. Средняя дистанция до объекта каждого класса из k ближайших соседей\n",
    "\n",
    "            ones_mean = (np.sum(neighs_dist*neighs_y, axis=1) + self.eps) / np.sum(neighs_y, axis=1)\n",
    "\n",
    "            mask = 1 * ~neighs_y.astype(bool)\n",
    "\n",
    "            zeros_mean = (np.sum(neighs_dist*mask, axis=1) + self.eps) / np.sum(mask, axis=1)\n",
    "            \n",
    "            column_names = ['fraction_ones', 'min_distance_one', 'min_distance_zero',\n",
    "                            'mean_distance', 'norm_min_distance_one', 'norm_min_distance_zero',\n",
    "                            'mean_distance_one', 'min_distance_zero']\n",
    "            \n",
    "            result.append(pd.DataFrame(data = np.c_[[fraction, ones, zeros, mean_distance,\n",
    "                                                      norm_ones, norm_zeros, ones_mean, zeros_mean]].T, \n",
    "                                        columns = column_names).add_suffix(f'_{k}'))\n",
    "\n",
    "        return pd.concat(result, axis=1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T14:45:08.711112Z",
     "start_time": "2022-03-27T14:45:08.679398Z"
    }
   },
   "source": [
    "X_train_scaled_, X_valid_scaled_, y_train_, y_valid_ = train_test_split(X_train_scaled, y_train, \n",
    "                                                         test_size=0.1, \n",
    "                                                         random_state=42,\n",
    "                                                         shuffle=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T14:45:09.375406Z",
     "start_time": "2022-03-27T14:45:09.372030Z"
    }
   },
   "source": [
    "nnf = NearestNeighborsFeats([10], 'minkowski')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T14:45:10.113652Z",
     "start_time": "2022-03-27T14:45:10.109467Z"
    }
   },
   "source": [
    "nnf.fit(X_valid_scaled_, y_valid_)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T14:45:48.690362Z",
     "start_time": "2022-03-27T14:45:10.978849Z"
    }
   },
   "source": [
    "train_features = nnf.predict(X_train_scaled)\n",
    "test_features = nnf.predict(X_test_scaled)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T14:45:50.068519Z",
     "start_time": "2022-03-27T14:45:50.060332Z"
    }
   },
   "source": [
    "train_features.replace({np.inf: 0}, inplace=True)\n",
    "test_features.replace({np.inf: 0}, inplace=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T14:45:51.676510Z",
     "start_time": "2022-03-27T14:45:51.670917Z"
    }
   },
   "source": [
    "X_train_with_kNN_features = np.concatenate((X_train_real_scaled, train_features), axis = 1)\n",
    "X_test_with_kNN_features = np.concatenate((X_test_real_scaled, test_features), axis = 1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T15:16:42.537254Z",
     "start_time": "2022-03-27T14:46:02.898035Z"
    }
   },
   "source": [
    "param_grid = {'C': [0.01, 0.05, 0.1, 0.5, 1, 5, 10]}\n",
    "\n",
    "estimator = LogisticRegression(penalty = 'l1', class_weight = 'balanced', solver='liblinear')\n",
    "clf_lasso = GridSearchCV(estimator, param_grid, cv = 5)\n",
    "clf_lasso.fit(X_train_with_kNN_features, y_train)\n",
    "clf_lasso.best_estimator_"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T15:16:51.006184Z",
     "start_time": "2022-03-27T15:16:50.969322Z"
    }
   },
   "source": [
    "y_LR_with_kNN = clf_lasso.predict_proba(X_test_with_kNN_features)[:, 1]\n",
    "roc_auc_with_kNN = roc_auc_score(y_test, y_LR_with_kNN)\n",
    "roc_auc_with_kNN"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T15:16:52.148920Z",
     "start_time": "2022-03-27T15:16:52.003520Z"
    }
   },
   "source": [
    "fpr_LR_with_kNN, tpr_fpr_LR_with_kNN, _ = roc_curve(y_test, y_LR_with_kNN)\n",
    "plt.plot(fpr_LR_with_kNN, tpr_fpr_LR_with_kNN, label=\"Lasso case\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title('ROC curve')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T15:16:52.701391Z",
     "start_time": "2022-03-27T15:16:52.683901Z"
    }
   },
   "source": [
    "f1_score(y_test, np.where(y_LR_with_kNN <= 0.5, 0, 1))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T15:16:53.342074Z",
     "start_time": "2022-03-27T15:16:53.338016Z"
    }
   },
   "source": [
    "model_comparator(roc_auc_with_kNN, roc_auc_scaled)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Синтезированные признаки не дали существенного прироста в качестве модели. Однако достаточно сильно увеличили время на обучение. Откуда делаем вывод, что синтезирование данных признаков - не рационально"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model | kNN from scikit-learn\n",
    "Замерим ее время работы и выведем все метрики классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Примененная модель: k-ближайших соседей\n",
    "- Количество соседей: k = 10 соседей\n",
    "- Кросс-валидация: на cv = 5 фолдов\n",
    "- Сплит данных: 25% тест, 75% трейн\n",
    "- Масштабирование признаков: стандартизация\n",
    "- Балансировка классов: применялась\n",
    "- Стратификация: не применялась\n",
    "- Стратегия изменения весов: не применялась\n",
    "\n",
    "- Метрика качества: ROC-AUC, лучшее значение - 0.878\n",
    "- Метрика качества: F1-мера, лучшее значение - 0.643"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T15:51:26.456426Z",
     "start_time": "2022-03-27T15:51:26.320108Z"
    }
   },
   "source": [
    "fpr_own_kNN, tpr_fpr_kNN, _ = roc_curve(y_test, y_kNeighbors)\n",
    "plt.plot(fpr_own_kNN, tpr_fpr_kNN, label=\"kNN case\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title('ROC curve')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CASE 3. Classification by NaiveBayes from sklearn\n",
    "## Model description\n",
    "В наивных баесовских классификаторах принимается достаточно грубое допущение о независимости данных, а также о том, что данные получены из того или иного параметрического распределения. Рассмотрим работу 3-х классификаторов на наших входных данных.  \n",
    "\n",
    "  \n",
    "Все процедуры выполним по аналогии с __CASE 1__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:26:22.746284Z",
     "start_time": "2022-03-27T13:26:22.695953Z"
    }
   },
   "source": [
    "(X_train_real_zeros, \n",
    " X_test_real_zeros, \n",
    " y_train, y_test) = train_test_split(X_real_zeros, y, \n",
    "                                     test_size=0.25, \n",
    "                                     random_state=42, shuffle=False)\n",
    "(X_train_real_mean, \n",
    " X_test_real_mean) = train_test_split(X_real_mean, \n",
    "                                      test_size=0.25,\n",
    "                                      random_state=42, shuffle=False)\n",
    "(X_train_cat_oh,\n",
    " X_test_cat_oh) = train_test_split(X_cat_bin_oh_encoded, \n",
    "                                   test_size=0.25, \n",
    "                                   random_state=42, shuffle=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, какая стратегия заполнения пустых данных лучше воспринимается классификаторами.\n",
    "Для проверки будем использовать cross_val_score c количеством фолдов равным 5. Функция возвращает значение ROC-AUC метрики."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:26:24.412838Z",
     "start_time": "2022-03-27T13:26:24.409986Z"
    }
   },
   "source": [
    "clfs = {\n",
    "    'bernoulli': naive_bayes.BernoulliNB(),\n",
    "    'multinomial': naive_bayes.MultinomialNB(),\n",
    "    'gaussian': naive_bayes.GaussianNB()\n",
    "}"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:26:31.049869Z",
     "start_time": "2022-03-27T13:26:30.366721Z"
    }
   },
   "source": [
    "zero_scores = {}\n",
    "for clf_type in clfs:\n",
    "    zero_scores[clf_type] = model_selection.cross_val_score(clfs[clf_type],\n",
    "                                                            X_train_real_zeros, y_train, cv=5).mean()\n",
    "zero_scores"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:26:32.333644Z",
     "start_time": "2022-03-27T13:26:31.728754Z"
    }
   },
   "source": [
    "mean_scores = {}\n",
    "for clf_type in clfs:\n",
    "    mean_scores[clf_type] = model_selection.cross_val_score(clfs[clf_type],\n",
    "                                                            X_train_real_mean, y_train, cv=5).mean()\n",
    "mean_scores"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и в CASE 1 лучшие значения метрики получаются на датасете с замененными пропусками в качестве среднего значения.\n",
    "Стоит отметить тот факт, что MultinomialNB дает значение nan. Как оказалось, ошибка связана с тем, что данный классификатор не умеет работать с отрициательными значениями.   \n",
    "\n",
    "Данный инсайд потребовал проверить, есть ли в данных отрицательные значения и почему они там могли оказаться.\n",
    "После небольшого ресерча оказалось, что в датасейте действительно имеются отрицательные значения - значения температуры воздуха в 9:00, 15:00 и максимальная температура воздуха"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:26:34.176500Z",
     "start_time": "2022-03-27T13:26:34.172867Z"
    }
   },
   "source": [
    "any(X[\"Temp3pm\"])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:26:34.721443Z",
     "start_time": "2022-03-27T13:26:34.717953Z"
    }
   },
   "source": [
    "any(X[\"Temp9am\"])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:26:35.122379Z",
     "start_time": "2022-03-27T13:26:35.118458Z"
    }
   },
   "source": [
    "any(X[\"MaxTemp\"])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:26:35.664508Z",
     "start_time": "2022-03-27T13:26:35.659378Z"
    }
   },
   "source": [
    "pd.unique(X[\"Temp3pm\"])[-40:]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:26:35.780762Z",
     "start_time": "2022-03-27T13:26:35.774949Z"
    }
   },
   "source": [
    "pd.unique(X[\"Temp9am\"])[-40:]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:26:35.928730Z",
     "start_time": "2022-03-27T13:26:35.923315Z"
    }
   },
   "source": [
    "pd.unique(X[\"MaxTemp\"])[-40:]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Откуда делаем вывод, что мультиномиальные баейсовский классификатор использовать нельзя"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:26:39.958188Z",
     "start_time": "2022-03-27T13:26:39.886982Z"
    }
   },
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_real_scaled = scaler.fit_transform(X_train_real_mean)\n",
    "X_test_real_scaled = scaler.transform(X_test_real_mean)\n",
    "\n",
    "X_train = np.concatenate([X_train_real_scaled, X_train_cat_oh], axis = 1)\n",
    "X_test = np.concatenate([X_test_real_scaled, X_test_cat_oh], axis = 1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:26:42.920000Z",
     "start_time": "2022-03-27T13:26:42.917024Z"
    }
   },
   "source": [
    "clfs = {\n",
    "    'bernoulli': naive_bayes.BernoulliNB(),\n",
    "    'gaussian': naive_bayes.GaussianNB()\n",
    "}"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:26:45.391972Z",
     "start_time": "2022-03-27T13:26:43.148749Z"
    }
   },
   "source": [
    "# Качество на обучающей выборке\n",
    "scores_NB = {}\n",
    "for clf_type in clfs:\n",
    "    scores_NB[clf_type] = model_selection.cross_val_score(clfs[clf_type], X_train, y_train, cv=5).mean()\n",
    "scores_NB"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:26:49.420202Z",
     "start_time": "2022-03-27T13:26:48.908906Z"
    }
   },
   "source": [
    "bnb = naive_bayes.BernoulliNB()\n",
    "gnb = naive_bayes.GaussianNB()\n",
    "y_pred_bnb = bnb.fit(X_train, y_train).predict(X_test)\n",
    "y_pred_gnb = gnb.fit(X_train, y_train).predict(X_test)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:26:49.766837Z",
     "start_time": "2022-03-27T13:26:49.755566Z"
    }
   },
   "source": [
    "roc_auc_score(y_test, y_pred_bnb)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:26:50.163212Z",
     "start_time": "2022-03-27T13:26:50.142201Z"
    }
   },
   "source": [
    "f1_score(y_test, np.where(y_pred_bnb <= 0.5, 0, 1))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:26:50.738810Z",
     "start_time": "2022-03-27T13:26:50.722662Z"
    }
   },
   "source": [
    "roc_auc_score(y_test, y_pred_gnb)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:26:51.155207Z",
     "start_time": "2022-03-27T13:26:51.137574Z"
    }
   },
   "source": [
    "f1_score(y_test, np.where(y_pred_gnb <= 0.5, 0, 1))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшим алгоритмом на предоставленных данных оказался бернуллевский наивный баейсовский классификатор.\n",
    "Также отметитм быстроту обучения данного алгоритма по сравнению с логистической регрессией. В то же время мы расплачиваемся достоверностью предсказания.   \n",
    "\n",
    "__Вывод:__ использовать наивный байес в качестве модели \"на коленке\", если результаты удовлетворяют, то можно использовать данную модель, если нет - всегда можно использовать что-то посложнее"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model of CASE 3 | NaiveBayes from scikit-learn\n",
    "Замерим ее время работы и выведем все метрики классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Примененная модель: бернуллевский наивный баейсовский классификатор\n",
    "- Кросс-валидация: на k=5 фолдов\n",
    "- Сплит данных: 25% тест, 75% трейн\n",
    "- Масштабирование признаков: стандартизация\n",
    "- Балансировка классов: не применялась\n",
    "- Стратификация: не применялась\n",
    "\n",
    "- Метрика качества: ROC-AUC, лучшее значение - 0.764\n",
    "- Метрика качества: F1-мера, лучшее значение - 0.596"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:27:01.445636Z",
     "start_time": "2022-03-27T13:27:01.331130Z"
    }
   },
   "source": [
    "fpr_Bernouilli_NB, tpr_Bernouilli_NB, _ = roc_curve(y_test, y_pred_bnb)\n",
    "plt.plot(fpr_Bernouilli_NB, tpr_Bernouilli_NB, label=\"Bernoille case\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title('ROC curve')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CASE 4. Classfication by LogisticRegression made byself\n",
    "## Model description\n",
    "Логистическая регрессия - метод построения линейного классификатора, позволяющий оценивать __апостериорные вероятности__ принадлежности объектов классам\n",
    "\n",
    "$$p(y|x) = a(x, \\theta) = \\sigma(\\langle x, \\theta \\rangle) = \\frac{1}{1 + \\exp(-\\langle \\theta, x_i \\rangle)}$$ \n",
    "\n",
    "$\\langle \\theta, x_i \\rangle$ - вектор из чисел - результатов скалярного перемножения вектор-строки матрицы на вектор столбец"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:27:12.097356Z",
     "start_time": "2022-03-27T13:27:12.092729Z"
    }
   },
   "source": [
    "theta = np.array([1, 2, 3])\n",
    "\n",
    "X =  np.array([[ 1,  1, 1],\n",
    "               [-1, -2, 1],\n",
    "               [-1, -2, 2],\n",
    "               [-2, -2, -3]\n",
    "              ])\n",
    "\n",
    "y = np.array([1, 1, 0, 0])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:27:12.199056Z",
     "start_time": "2022-03-27T13:27:12.196107Z"
    }
   },
   "source": [
    "def probability(theta, X):\n",
    "    result = 1 / (1 + np.exp(-np.dot(X, theta)))\n",
    "    return result"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:27:14.171969Z",
     "start_time": "2022-03-27T13:27:14.168378Z"
    }
   },
   "source": [
    "prob = probability(theta, X)\n",
    "\n",
    "\n",
    "assert type(prob) == np.ndarray, 'Возвращается неверный тип'\n",
    "assert prob.shape == (X.shape[0],), 'Неверный размер массива'\n",
    "assert (prob.round(3) == [0.998, 0.119, 0.731, 0.]).all(), 'Функция считается неверно'"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция предсказания метки класса, получает на вход вероятности принадлежности к классу 1 и выдает метки классов __(используется пороговое значение 0,5 в качестве критерия отсева)__ $y \\in \\{0, 1\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:27:17.784347Z",
     "start_time": "2022-03-27T13:27:17.780221Z"
    },
    "scrolled": true
   },
   "source": [
    "def binary_class_prediction(theta, X, threshold =.5):\n",
    "    # вектор вероятностей принадлежности к классу 1\n",
    "    prob =  probability(theta, X)\n",
    "    # метки классов\n",
    "    result = np.where(prob <= threshold, 0, 1)\n",
    "    return result"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:27:18.568173Z",
     "start_time": "2022-03-27T13:27:18.564440Z"
    }
   },
   "source": [
    "y_pred = binary_class_prediction(theta, X)\n",
    "\n",
    "assert type(y_pred) == np.ndarray, 'Возвращается неверный тип'\n",
    "assert y_pred.shape == (X.shape[0],), 'Неверный размер массива'\n",
    "assert min(y_pred) == 0, 'Функция считается неверно'\n",
    "assert max(y_pred) == 1, 'Функция считается неверно'"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Функционал качества логистической регрессии__\n",
    "\n",
    "Запишем правдободовие выборки для меток класса $y \\in \\{+1, -1\\}$ \n",
    "\n",
    "$$Likelihood(a, X^\\ell) = \\prod_{i = 1}^{\\ell} a(x_i,\\theta)^{[y_i = +1]} (1 - a(x_i, \\theta))^{[y_i = -1]} → \\operatorname*{max}_{\\theta}$$ \n",
    "\n",
    "Прологарифмируем правдоподобие выборки и перейдем к задаче минимизации:\n",
    "\n",
    "$$Q(a, X^\\ell) =     -\\sum_{i = 1}^{\\ell} \n",
    "        [y_i = +1] \\log a(x_i, \\theta)\n",
    "        +\n",
    "        [y_i = -1] \\log (1 - a(x_i, \\theta)) \\to \\operatorname*{min}_{\\theta}$$ \n",
    "        \n",
    "Подставим $a(x, \\theta)$ в функцинал качества:\n",
    "\n",
    "$$ Q(a, X^\\ell) = -\\sum_{i = 1}^{\\ell} \\left(\n",
    "    [y_i = +1]\n",
    "    \\log \\frac{1}{1 + \\exp(-\\langle \\theta, x_i \\rangle)}\n",
    "    +\n",
    "    [y_i = -1]\n",
    "    \\log \\frac{\\exp(-\\langle \\theta, x_i \\rangle)}{1 + \\exp(-\\langle \\theta, x_i \\rangle)}\n",
    "\\right)\n",
    "=\\\\\n",
    "=\n",
    "-\\sum_{i = 1}^{\\ell} \\left(\n",
    "    [y_i = +1]\n",
    "    \\log \\frac{1}{1 + \\exp(-\\langle \\theta, x_i \\rangle)}\n",
    "    +\n",
    "    [y_i = -1]\n",
    "    \\log \\frac{1}{1 + \\exp(\\langle \\theta, x_i \\rangle)}\n",
    "\\right)\n",
    "=\\\\\n",
    "=\n",
    "\\sum_{i = 1}^{\\ell}\n",
    "    \\log \\left(\n",
    "        1 + \\exp(-y_i \\langle \\theta, x_i \\rangle)\n",
    "    \\right) $$\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итоговый оптимизируемый функционал качества (logloss), записанный для меток классов $y \\in \\{+1, -1\\}$ и усредненный по выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Q(a, X^\\ell) = \\frac{1}{\\ell}\\sum_{i = 1}^{\\ell}\n",
    "    \\log \\left(\n",
    "        1 + \\exp(-y_i \\langle \\theta, x_i \\rangle)\n",
    "    \\right) \\to \\operatorname*{min}_{\\theta}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем его в функции logloss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:27:23.775647Z",
     "start_time": "2022-03-27T13:27:23.773033Z"
    }
   },
   "source": [
    "# Переведем метки в -1 и +1 в связи с выведенным уравнением (6)\n",
    "y = np.where(y == 0, -1, 1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:27:26.223850Z",
     "start_time": "2022-03-27T13:27:26.220742Z"
    }
   },
   "source": [
    "def logloss(theta, X, y): \n",
    "    result = np.average(\n",
    "                    np.log(\n",
    "                            1 + np.exp((-y) * np.dot(X, theta))\n",
    "                           )\n",
    "                       )\n",
    "    return result"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:27:27.202178Z",
     "start_time": "2022-03-27T13:27:27.199201Z"
    }
   },
   "source": [
    "assert logloss(theta, X, y).round(3) == 0.861, 'Функция считается неверно'"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Алгоритм оптимизации функционала качества. Стохастический градиентный спуск__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Вход: </b> Выборка $X^\\ell$, темп обучения $h$\n",
    "\n",
    "<b>Выход: </b> оптимальный вектор весов $\\theta$\n",
    "\n",
    "1.  Инициализировать веса $\\theta$\n",
    "2.  Инициализировать оценку функционала качества: $Q(a, X^\\ell)$\n",
    "3.  <b>Повторять</b>: \n",
    "\n",
    "    Выбрать случайным образом подвыборку объектов $X^{batch} =\\{x_1, \\dots,x_n \\}$ из $X^{\\ell}$\n",
    "    \n",
    "    Рассчитать градиент функционала качества: $\\nabla Q(X^{batch}, \\theta)$\n",
    "    \n",
    "    Обновить веса: $\\theta := \\theta - h\\cdot \\nabla Q(X^{batch}, \\theta)$\n",
    "       \n",
    "    <b>Пока</b> значение $Q$ и/или веса $\\theta$ не сойдутся   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуем функцию рассчета градиента функционала качества"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial Q(a, X^{batch}) }{\\partial \\theta_j}   = \\frac{\\partial \\frac{1}{n}\\sum_{i = 1}^{n}\n",
    "    \\log \\left(\n",
    "        1 + \\exp(- y_i \\langle \\theta, x_i \\rangle)\n",
    "    \\right)} {\\partial \\theta_j}  = \\frac{1}{n}\\sum_{i = 1}^{n}\n",
    "     \\frac {1}{\n",
    "        1 + \\exp(- y_i \\langle \\theta, x_i \\rangle)} \\cdot  \\exp(- y_i \\langle \\theta, x_i \\rangle) \\cdot -y_i x_{ij}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте рассчет градиента в матричном виде:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:27:52.088009Z",
     "start_time": "2022-03-27T13:27:52.084485Z"
    }
   },
   "source": [
    "# Функция градиента\n",
    "def gradient(theta, X, y):\n",
    "    margin = (-y) * np.dot(X, theta)\n",
    "    result = np.average((1 / (1 + np.exp(margin))) * np.exp(margin)) * (-np.dot(y, X))\n",
    "    return result\n",
    "\n",
    "assert gradient(theta, X, y).shape == theta.shape, 'Неверный размер массива'"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:27:53.413978Z",
     "start_time": "2022-03-27T13:27:53.404114Z"
    }
   },
   "source": [
    "# Функция обучения\n",
    "def fit(X, y, batch_size=10, h=0.05, iters=100, plot=True):\n",
    "\n",
    "    # получаем размерности матрицы\n",
    "    size, dim = X.shape\n",
    "\n",
    "    # случайная начальная инициализация\n",
    "    theta = np.random.uniform(size=dim)\n",
    "    # Вектор ошибок\n",
    "    errors = []\n",
    "    \n",
    "    theta_history = theta\n",
    "    colors = [plt.get_cmap('gist_rainbow')(i) for i in np.linspace(0,1,dim)]\n",
    "\n",
    "    \n",
    "    # plt \n",
    "    if plot:\n",
    "        fig = plt.figure(figsize=(15, 10))\n",
    "        ax1 = fig.add_subplot(221)\n",
    "        ax2 = fig.add_subplot(222)\n",
    "        ax3 = fig.add_subplot(212)\n",
    "        fig.suptitle('Gradient descent')\n",
    "        \n",
    "        \n",
    "    for _ in range(iters):  \n",
    "        \n",
    "        # берём случайный набор элементов, разбитый на батчи\n",
    "        # на батче и будет реализовываться стохастическая версия градиентного бустинга\n",
    "        batch = np.random.choice(size, batch_size, replace=False)\n",
    "        X_batch = X[batch]\n",
    "        y_batch = y[batch]\n",
    "\n",
    "        # считаем производные\n",
    "        grad = gradient(theta, X_batch, y_batch)\n",
    "        \n",
    "        assert type(grad) == np.ndarray, 'Wrong type'\n",
    "        assert len(grad.shape) == 1, 'Необходимо вернуть одномерный вектор'\n",
    "        assert grad.shape[0] == len(theta), 'Длина вектора должна быть равной количеству весов'\n",
    "        \n",
    "        \n",
    "        # Обновляем веса\n",
    "        theta -= grad * h\n",
    "        # Вектор исторических значений весов\n",
    "        theta_history = np.vstack((theta_history, theta))\n",
    "        \n",
    "        # Накапливаемая ошибка\n",
    "        loss = logloss(theta, X, y)\n",
    "        errors.append(loss)\n",
    "        \n",
    "        if plot:\n",
    "            ax1.clear()            \n",
    "            ax1.scatter(range(0, dim, 1), theta, label='Gradient solution')\n",
    "            ax1.legend(loc=\"upper left\")\n",
    "            ax1.grid()\n",
    "            ax1.set_title('Weight')\n",
    "            ax1.set_ylabel(r'$\\bar \\beta$')\n",
    "            ax1.set_xlabel('Weight ID')\n",
    "            ax1.set_xticks(range(0, dim, 1))\n",
    "            \n",
    "            \n",
    "            ax2.plot(range(_+1), errors, 'g-')\n",
    "            ax2.set_title('Logloss function')\n",
    "            ax2.grid()\n",
    "            ax2.set_xlabel('Number of iterations')\n",
    "            ax2.set_ylabel('Error value')\n",
    "            \n",
    "            ax3.plot(theta_history)\n",
    "            ax3.set_title(\"Weights evolutions history\")\n",
    "            ax3.set_ylabel('Values')\n",
    "            ax3.set_xlabel('Number of iterations')\n",
    "            ax3.grid()\n",
    "            time.sleep(0.05)\n",
    "            fig.canvas.draw()\n",
    "            \n",
    "    return theta"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:27:55.295530Z",
     "start_time": "2022-03-27T13:27:55.291289Z"
    }
   },
   "source": [
    "X, y = make_classification(n_samples=200)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:28:29.272595Z",
     "start_time": "2022-03-27T13:27:56.647894Z"
    },
    "scrolled": false
   },
   "source": [
    "optimal_theta = fit(X, y)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Оно живое, и кажется, работает!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:28:34.678643Z",
     "start_time": "2022-03-27T13:28:34.674084Z"
    }
   },
   "source": [
    "optimal_theta"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:28:35.537829Z",
     "start_time": "2022-03-27T13:28:35.530506Z"
    }
   },
   "source": [
    "y_pred = binary_class_prediction(optimal_theta, X)\n",
    "y_pred"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fitting with preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:28:38.279502Z",
     "start_time": "2022-03-27T13:28:38.274228Z"
    }
   },
   "source": [
    "y_train"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:32:58.143743Z",
     "start_time": "2022-03-27T13:28:39.990616Z"
    }
   },
   "source": [
    "# Не забудем произвести перевод меток\n",
    "y_train = np.where(y_train == 0, -1, 1)\n",
    "\n",
    "fit(X_train_scaled, y_train)\n",
    "optimal_theta = fit(X_train_scaled, y_train)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:33:44.057086Z",
     "start_time": "2022-03-27T13:33:44.047757Z"
    }
   },
   "source": [
    "y_pred = binary_class_prediction(optimal_theta, X_test_scaled)\n",
    "y_pred"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:33:45.083519Z",
     "start_time": "2022-03-27T13:33:45.069670Z"
    }
   },
   "source": [
    "roc_auc_own = roc_auc_score(y_test, y_pred)\n",
    "roc_auc_own"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:33:46.278162Z",
     "start_time": "2022-03-27T13:33:46.141367Z"
    }
   },
   "source": [
    "fpr_own, tpr_fpr_own, _ = roc_curve(y_test, y_pred)\n",
    "\n",
    "plt.plot(fpr_mean, tpr_mean, label=\"Own case\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title('ROC curve')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-27T13:33:50.550871Z",
     "start_time": "2022-03-27T13:33:50.522868Z"
    }
   },
   "source": [
    "f1_score(y_test, np.where(y_pred <= 0.5, 0, 1))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model of CASE 4 | LogisticRegression made byself\n",
    "Замерим ее время работы и выведем все метрики классификации\n",
    "Как видно, модель реализованная своими руками дает показатели хуже, чем дефолтная модель логистической регресии \"из коробки\" scklearn (как минимум из-за того, что здесь мы не использовали регуляризацию) Также она работает много медленнее уже реализованного варианта. Итог - не нужно делать велосипед, используй то, что уже реализовано."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Примененная модель: логистическая регрессия своими руками\n",
    "- Кросс-валидация: на k=5 фолдов\n",
    "- Сплит данных: 25% тест, 75% трейн\n",
    "- Масштабирование признаков: стандартизация\n",
    "- Балансировка классов: не применялась\n",
    "- Стратификация: не применялась\n",
    "- Полиномиализация: применялась, была отвергнута\n",
    "- Регуляризация: L1-lasso\n",
    "\n",
    "- Метрика качества: ROC-AUC, лучшее значение - 0.780\n",
    "- Метрика качества: F1-мера, лучшее значение - 0.617"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "436.424px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "894.983px",
    "left": "1623.32px",
    "right": "20px",
    "top": "134.979px",
    "width": "409.549px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
